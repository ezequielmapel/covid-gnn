{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQKflKlwU-Da"
      },
      "source": [
        "#Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G1QX8Qm1v2gG"
      },
      "outputs": [],
      "source": [
        "#!pip -q install torch torchvision torchaudio\n",
        "#!pip -q install torch_geometric\n",
        "#!pip -q install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cpu.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FgmvE0mpVD3B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Tratar dados\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "\n",
        "import re\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Importando CSV\n",
        "#from google.colab import drive\n",
        "\n",
        "# PyG\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import remove_isolated_nodes\n",
        "from torch_geometric.utils import contains_isolated_nodes\n",
        "from torch_geometric.transforms import LargestConnectedComponents\n",
        "import torch_geometric.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y8rcZmOVmsm"
      },
      "source": [
        "### Lendo CSV do Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OXOAEvgVl9t",
        "outputId": "7c8cc1be-90bd-4b35-bc00-e4b3498e35af"
      },
      "outputs": [],
      "source": [
        "filename = \"./data/covid_mexico.csv\"\n",
        "covid_df = pd.read_csv(filename, sep=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXbrGCOlb1Lo",
        "outputId": "88269849-51b3-42e6-a12a-94eca34beb99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1048575, 21)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "qCqczYx-wduO",
        "outputId": "f67f3027-98af-4956-bdab-0b9abb7742a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USMER</th>\n",
              "      <th>MEDICAL_UNIT</th>\n",
              "      <th>SEX</th>\n",
              "      <th>PATIENT_TYPE</th>\n",
              "      <th>DATE_DIED</th>\n",
              "      <th>INTUBED</th>\n",
              "      <th>PNEUMONIA</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PREGNANT</th>\n",
              "      <th>DIABETES</th>\n",
              "      <th>...</th>\n",
              "      <th>ASTHMA</th>\n",
              "      <th>INMSUPR</th>\n",
              "      <th>HIPERTENSION</th>\n",
              "      <th>OTHER_DISEASE</th>\n",
              "      <th>CARDIOVASCULAR</th>\n",
              "      <th>OBESITY</th>\n",
              "      <th>RENAL_CHRONIC</th>\n",
              "      <th>TOBACCO</th>\n",
              "      <th>CLASIFFICATION_FINAL</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>03/05/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>03/06/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>97</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>09/06/2020</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12/06/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>21/06/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
              "0      2             1    1             1  03/05/2020       97          1   \n",
              "1      2             1    2             1  03/06/2020       97          1   \n",
              "2      2             1    2             2  09/06/2020        1          2   \n",
              "3      2             1    1             1  12/06/2020       97          2   \n",
              "4      2             1    2             1  21/06/2020       97          2   \n",
              "\n",
              "   AGE  PREGNANT  DIABETES  ...  ASTHMA  INMSUPR  HIPERTENSION  OTHER_DISEASE  \\\n",
              "0   65         2         2  ...       2        2             1              2   \n",
              "1   72        97         2  ...       2        2             1              2   \n",
              "2   55        97         1  ...       2        2             2              2   \n",
              "3   53         2         2  ...       2        2             2              2   \n",
              "4   68        97         1  ...       2        2             1              2   \n",
              "\n",
              "   CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  CLASIFFICATION_FINAL  ICU  \n",
              "0               2        2              2        2                     3   97  \n",
              "1               2        1              1        2                     5   97  \n",
              "2               2        2              2        2                     3    2  \n",
              "3               2        2              2        2                     7   97  \n",
              "4               2        2              2        2                     3   97  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "XwfEwtrYbzl-",
        "outputId": "303a06ef-0969-498a-8218-70d6bd46c413"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USMER</th>\n",
              "      <th>MEDICAL_UNIT</th>\n",
              "      <th>SEX</th>\n",
              "      <th>PATIENT_TYPE</th>\n",
              "      <th>INTUBED</th>\n",
              "      <th>PNEUMONIA</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PREGNANT</th>\n",
              "      <th>DIABETES</th>\n",
              "      <th>COPD</th>\n",
              "      <th>ASTHMA</th>\n",
              "      <th>INMSUPR</th>\n",
              "      <th>HIPERTENSION</th>\n",
              "      <th>OTHER_DISEASE</th>\n",
              "      <th>CARDIOVASCULAR</th>\n",
              "      <th>OBESITY</th>\n",
              "      <th>RENAL_CHRONIC</th>\n",
              "      <th>TOBACCO</th>\n",
              "      <th>CLASIFFICATION_FINAL</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.632194e+00</td>\n",
              "      <td>8.980565e+00</td>\n",
              "      <td>1.499259e+00</td>\n",
              "      <td>1.190765e+00</td>\n",
              "      <td>7.952288e+01</td>\n",
              "      <td>3.346831e+00</td>\n",
              "      <td>4.179410e+01</td>\n",
              "      <td>4.976558e+01</td>\n",
              "      <td>2.186404e+00</td>\n",
              "      <td>2.260569e+00</td>\n",
              "      <td>2.242626e+00</td>\n",
              "      <td>2.298132e+00</td>\n",
              "      <td>2.128989e+00</td>\n",
              "      <td>2.435143e+00</td>\n",
              "      <td>2.261810e+00</td>\n",
              "      <td>2.125176e+00</td>\n",
              "      <td>2.257180e+00</td>\n",
              "      <td>2.214333e+00</td>\n",
              "      <td>5.305653e+00</td>\n",
              "      <td>7.955397e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.822084e-01</td>\n",
              "      <td>3.723278e+00</td>\n",
              "      <td>4.999997e-01</td>\n",
              "      <td>3.929041e-01</td>\n",
              "      <td>3.686889e+01</td>\n",
              "      <td>1.191288e+01</td>\n",
              "      <td>1.690739e+01</td>\n",
              "      <td>4.751073e+01</td>\n",
              "      <td>5.424242e+00</td>\n",
              "      <td>5.132258e+00</td>\n",
              "      <td>5.114089e+00</td>\n",
              "      <td>5.462843e+00</td>\n",
              "      <td>5.236397e+00</td>\n",
              "      <td>6.646676e+00</td>\n",
              "      <td>5.194850e+00</td>\n",
              "      <td>5.175445e+00</td>\n",
              "      <td>5.135354e+00</td>\n",
              "      <td>5.323097e+00</td>\n",
              "      <td>1.881165e+00</td>\n",
              "      <td>3.682307e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>3.000000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>5.300000e+01</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.300000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>9.900000e+01</td>\n",
              "      <td>9.900000e+01</td>\n",
              "      <td>1.210000e+02</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>9.900000e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              USMER  MEDICAL_UNIT           SEX  PATIENT_TYPE       INTUBED  \\\n",
              "count  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06   \n",
              "mean   1.632194e+00  8.980565e+00  1.499259e+00  1.190765e+00  7.952288e+01   \n",
              "std    4.822084e-01  3.723278e+00  4.999997e-01  3.929041e-01  3.686889e+01   \n",
              "min    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
              "25%    1.000000e+00  4.000000e+00  1.000000e+00  1.000000e+00  9.700000e+01   \n",
              "50%    2.000000e+00  1.200000e+01  1.000000e+00  1.000000e+00  9.700000e+01   \n",
              "75%    2.000000e+00  1.200000e+01  2.000000e+00  1.000000e+00  9.700000e+01   \n",
              "max    2.000000e+00  1.300000e+01  2.000000e+00  2.000000e+00  9.900000e+01   \n",
              "\n",
              "          PNEUMONIA           AGE      PREGNANT      DIABETES          COPD  \\\n",
              "count  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06   \n",
              "mean   3.346831e+00  4.179410e+01  4.976558e+01  2.186404e+00  2.260569e+00   \n",
              "std    1.191288e+01  1.690739e+01  4.751073e+01  5.424242e+00  5.132258e+00   \n",
              "min    1.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
              "25%    2.000000e+00  3.000000e+01  2.000000e+00  2.000000e+00  2.000000e+00   \n",
              "50%    2.000000e+00  4.000000e+01  9.700000e+01  2.000000e+00  2.000000e+00   \n",
              "75%    2.000000e+00  5.300000e+01  9.700000e+01  2.000000e+00  2.000000e+00   \n",
              "max    9.900000e+01  1.210000e+02  9.800000e+01  9.800000e+01  9.800000e+01   \n",
              "\n",
              "             ASTHMA       INMSUPR  HIPERTENSION  OTHER_DISEASE  \\\n",
              "count  1.048575e+06  1.048575e+06  1.048575e+06   1.048575e+06   \n",
              "mean   2.242626e+00  2.298132e+00  2.128989e+00   2.435143e+00   \n",
              "std    5.114089e+00  5.462843e+00  5.236397e+00   6.646676e+00   \n",
              "min    1.000000e+00  1.000000e+00  1.000000e+00   1.000000e+00   \n",
              "25%    2.000000e+00  2.000000e+00  2.000000e+00   2.000000e+00   \n",
              "50%    2.000000e+00  2.000000e+00  2.000000e+00   2.000000e+00   \n",
              "75%    2.000000e+00  2.000000e+00  2.000000e+00   2.000000e+00   \n",
              "max    9.800000e+01  9.800000e+01  9.800000e+01   9.800000e+01   \n",
              "\n",
              "       CARDIOVASCULAR       OBESITY  RENAL_CHRONIC       TOBACCO  \\\n",
              "count    1.048575e+06  1.048575e+06   1.048575e+06  1.048575e+06   \n",
              "mean     2.261810e+00  2.125176e+00   2.257180e+00  2.214333e+00   \n",
              "std      5.194850e+00  5.175445e+00   5.135354e+00  5.323097e+00   \n",
              "min      1.000000e+00  1.000000e+00   1.000000e+00  1.000000e+00   \n",
              "25%      2.000000e+00  2.000000e+00   2.000000e+00  2.000000e+00   \n",
              "50%      2.000000e+00  2.000000e+00   2.000000e+00  2.000000e+00   \n",
              "75%      2.000000e+00  2.000000e+00   2.000000e+00  2.000000e+00   \n",
              "max      9.800000e+01  9.800000e+01   9.800000e+01  9.800000e+01   \n",
              "\n",
              "       CLASIFFICATION_FINAL           ICU  \n",
              "count          1.048575e+06  1.048575e+06  \n",
              "mean           5.305653e+00  7.955397e+01  \n",
              "std            1.881165e+00  3.682307e+01  \n",
              "min            1.000000e+00  1.000000e+00  \n",
              "25%            3.000000e+00  9.700000e+01  \n",
              "50%            6.000000e+00  9.700000e+01  \n",
              "75%            7.000000e+00  9.700000e+01  \n",
              "max            7.000000e+00  9.900000e+01  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IasZkO-CwgZs",
        "outputId": "91daf048-98ab-4c54-c4eb-b8703f51b02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count    Dtype \n",
            "---  ------                --------------    ----- \n",
            " 0   USMER                 1048575 non-null  int64 \n",
            " 1   MEDICAL_UNIT          1048575 non-null  int64 \n",
            " 2   SEX                   1048575 non-null  int64 \n",
            " 3   PATIENT_TYPE          1048575 non-null  int64 \n",
            " 4   DATE_DIED             1048575 non-null  object\n",
            " 5   INTUBED               1048575 non-null  int64 \n",
            " 6   PNEUMONIA             1048575 non-null  int64 \n",
            " 7   AGE                   1048575 non-null  int64 \n",
            " 8   PREGNANT              1048575 non-null  int64 \n",
            " 9   DIABETES              1048575 non-null  int64 \n",
            " 10  COPD                  1048575 non-null  int64 \n",
            " 11  ASTHMA                1048575 non-null  int64 \n",
            " 12  INMSUPR               1048575 non-null  int64 \n",
            " 13  HIPERTENSION          1048575 non-null  int64 \n",
            " 14  OTHER_DISEASE         1048575 non-null  int64 \n",
            " 15  CARDIOVASCULAR        1048575 non-null  int64 \n",
            " 16  OBESITY               1048575 non-null  int64 \n",
            " 17  RENAL_CHRONIC         1048575 non-null  int64 \n",
            " 18  TOBACCO               1048575 non-null  int64 \n",
            " 19  CLASIFFICATION_FINAL  1048575 non-null  int64 \n",
            " 20  ICU                   1048575 non-null  int64 \n",
            "dtypes: int64(20), object(1)\n",
            "memory usage: 168.0+ MB\n"
          ]
        }
      ],
      "source": [
        "covid_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-38SUv5pV67F"
      },
      "source": [
        "# Pré Tratamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysi62eEJWKHa"
      },
      "source": [
        "### Tratando DATE_DIED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dKoX0lNWoM3",
        "outputId": "087a5361-2bc7-4ce8-e5e7-a4ce6c4db881"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DATE_DIED\n",
              "9999-99-99    971633\n",
              "06/07/2020      1000\n",
              "07/07/2020       996\n",
              "13/07/2020       990\n",
              "16/06/2020       979\n",
              "               ...  \n",
              "24/11/2020         1\n",
              "17/12/2020         1\n",
              "08/12/2020         1\n",
              "16/03/2021         1\n",
              "22/04/2021         1\n",
              "Name: count, Length: 401, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#A Data \"9999-99-99\" significa que o paciente sobreviveu\n",
        "covid_df['DATE_DIED'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ee83IqFWlWJ",
        "outputId": "db8e56ce-29e4-47df-eb76-0a9ac38154a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PASSED\n",
              "0    971633\n",
              "1     76942\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Cria nova coluna binaria e preenche com os valores baseando na coluna DATE_DIED\n",
        "covid_df['PASSED'] = [0 if l == '9999-99-99' else 1 for l in covid_df.DATE_DIED]\n",
        "\n",
        "#Remove coluna denecessária\n",
        "covid_df.drop(columns=[\"DATE_DIED\"], inplace=True)\n",
        "\n",
        "covid_df.PASSED.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtOrU68QVzLE"
      },
      "source": [
        "# Explorando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBojdC--V9m4"
      },
      "source": [
        "### Descrevendo dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USMER -----> 2\n",
            "MEDICAL_UNIT -----> 13\n",
            "SEX -----> 2\n",
            "PATIENT_TYPE -----> 2\n",
            "INTUBED -----> 4\n",
            "PNEUMONIA -----> 3\n",
            "AGE -----> 121\n",
            "PREGNANT -----> 4\n",
            "DIABETES -----> 3\n",
            "COPD -----> 3\n",
            "ASTHMA -----> 3\n",
            "INMSUPR -----> 3\n",
            "HIPERTENSION -----> 3\n",
            "OTHER_DISEASE -----> 3\n",
            "CARDIOVASCULAR -----> 3\n",
            "OBESITY -----> 3\n",
            "RENAL_CHRONIC -----> 3\n",
            "TOBACCO -----> 3\n",
            "CLASIFFICATION_FINAL -----> 7\n",
            "ICU -----> 4\n",
            "PASSED -----> 2\n"
          ]
        }
      ],
      "source": [
        "for i in covid_df.columns:\n",
        "    print(i,\"----->\", len(covid_df[i].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Percentual de mortes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6p14IJJo3jNr"
      },
      "outputs": [],
      "source": [
        "def plot_percentual_deads(df):\n",
        "    percentual_deads = round(df.PASSED.mean() * 100, 2)\n",
        "    print(f\"Percentural of deads {percentual_deads}]\\n\")\n",
        "\n",
        "    ax = df.PASSED.value_counts(dropna=False).plot(kind=\"bar\", title=f\"Pacientes x Óbitos -> ({percentual_deads}%)\", color=[\"blue\", \"red\"], ylabel=\"Qtd. Pacientes\")\n",
        "\n",
        "    container = ax.containers[0]\n",
        "    ax.bar_label(container)\n",
        "    ax.set_xticklabels([\"Recuperados\", \"Óbitos\"], rotation=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentural of deads 7.34]\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABN50lEQVR4nO3deXxM5/4H8M9km0QiIYssREItSWgtiSU0Yg2hvZReUWsUpYKitpTSqIq2KNqSIpbammu9tYvGvlWRai2xBLEkIkESQkLy/f3hZn4dk0QmwnDyeb9e83rdec5znvM90zuZj3Oec45KRARERERECmFk6AKIiIiIShLDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERnc4cOHYW1tjZ07dxq6FCJSAIYbIjKopKQkdO3aFYsWLULr1q0NXQ4RKYCKz5YiIiIiJeGRG1K8JUuWQKVSaV4mJiaoVKkS+vbti+vXr7+QbQYHB8Pd3f2FjJ3nxo0b+OKLLxAbG/tCt/OiXL16FUOGDMEbb7wBc3NzlC9fHs2bN8eKFSvw9L+5du/eDZVKhTVr1jxz3C+++AIqlUqrbe7cuViyZElJlv9KatWqFQYNGqR5n/dZFPT65ZdfCh0vNjYWHTp0QOXKlWFhYQFbW1v4+vpi+fLlha4nImjWrBlUKhWGDBmitezhw4cICQmBg4MDKlWqhMmTJ+v8975y5QqsrKzw22+/6YwdGRmJihUr4v79+8/6OKg0EyKFW7x4sQCQxYsXy6FDhyQmJka++OILUavVUqVKFbl3716Jb/PChQty/PjxEh/3n44eParZr9fN/v37pVy5clKpUiWZPXu27Nq1SzZs2CDdu3cXABIUFCQ5OTma/rt27RIAsnr16meOffXqVTl06JBWW61atcTf37+kd+OVsmHDBlGr1XLt2jVNW95n8fSrdu3aYmFhIXfu3Cl0zF27dsnAgQNl2bJlEhMTIxs3bpRu3boJAPnyyy8LXO/7778XZ2dnASAhISFay8LCwsTJyUlWr14tkZGRUqZMGVm2bJlWn8DAQOndu3e+Yz969EiqV68uEydOfMYnQqUZww0pXl64OXr0qFb7559/LgBk+fLlBqrs+byu4ebOnTtSoUIFcXNzk6SkJJ3l06ZNEwASHh6uadMn3OTnVQw3586dk9zc3BIbr2HDhtKtW7dn9rt06ZKoVCrp2bNnsbfVqFEjcXV1LXB8KysrWbduXb7hpmHDhjJ16lTN+wEDBkhQUJDm/apVq8TOzk5u3bpV4PanT58uNjY2cv/+/WLvAykbT0tRqdW4cWMATw6BA0BYWBgaNWoEW1tbWFtbo379+oiMjNQ5ZA4AK1euhK+vL6ysrGBlZYW6desiMjJSszy/01Iigrlz56Ju3bqwsLBA+fLl8f777yM+Pl6rX/PmzVG7dm0cPXoUfn5+KFOmDKpWrYpp06YhNzcXwJPTNA0aNAAA9O3bV3Oa4YsvvtCM88cff+Bf//oXbG1tYW5ujnr16uE///mP1rYyMzMxatQoVKlSBebm5rC1tYWPjw9WrVpV4OcmImjfvj3s7OyQkJCgNVatWrXg6elZ6CmDhQsXIjk5GdOmTYOjo6PO8jFjxsDDwwPffvstHj16pLXs4cOHGDlyJJycnGBhYQF/f3+cOHFCq8/Tp6Xc3d1x6tQp7NmzR/M5/fO/TUJCAnr27IkKFSpArVbD09MTM2bM0HzWeebNm4c6derAysoKZcuWhYeHBz777LMC9/NZBgwYADc3N4wZM0ZnH/R14sQJ/P777+jVq9cz+y5atAgigv79+xd7e/b29jAxMcl32UcffYQ2bdrgvffey3f5w4cPYWlpqXlvZWWFhw8fAgDu3r2L4cOHY+bMmbC3ty9w+z169EB6evozT6tRKWbYbEX04hV05Gb27NkCQObPny8iIsHBwRIZGSnR0dESHR0tX375pVhYWEhYWJjWenlHfDp37iyrV6+WHTt2yMyZM+Xzzz/X9OnTp4+4ublprTdgwAAxNTWVTz/9VLZt2yYrV64UDw8PcXR01DqC4e/vL3Z2dlK9enWJiIiQ6OhoGTx4sACQpUuXiohIWlqaZr8mTJigOd1w9epVERGJiYkRMzMz8fPzk6ioKNm2bZsEBwfrHOkZOHCglClTRmbOnCm7du2STZs2ybRp0+T7778v9DNNSUmRSpUqSaNGjSQ7O1uzzxYWFnLy5MlC1w0ICBBjY+NCTweOGTNGAGhOL+UduXF1dZWOHTvKxo0bZfny5VKtWjWxtraWixcvatadNGmS/PNP2/Hjx6Vq1apSr149zeeUd8owOTlZKlasKA4ODhIRESHbtm2TIUOGCAD5+OOPNWOsWrVKAMjQoUNlx44dsnPnTomIiJBhw4YVuq+FOXXqlISGhkrVqlUFgHh4eEhYWJicO3dO77EmT54sxsbGkpGRUWi/nJwccXV1lWrVquk1fk5Ojjx69EiSk5Plxx9/FBMTE4mIiNDpt2DBArGxsZHr16+LiOR75GbQoEFSp04duXz5svz999/i4uIiX3/9tYg8+Y60bNmySDV5enpK586d9doPKj0Ybkjx8kLA4cOH5dGjR5KRkSGbNm0SBwcHKVu2bL6nRvL+mE+ePFns7Ow0pw/i4+PF2NhYevToUeg2nw43hw4dEgAyY8YMrX5Xr14VCwsLGTNmjKbN399fAMiRI0e0+np5eUnbtm017ws7LeXh4SH16tWTR48eabW/88474uzsrJnPUrt2benUqVOh+1KQ/fv3i4mJiQwfPlwWLVokAGThwoXPXM/Dw0OcnJwK7TNv3jwBIFFRUSLy/+Gmfv36WqdyLl++LKamptK/f39N29PhRqTg01Ljxo3L97P++OOPRaVSSVxcnIiIDBkyRMqVK/fMfSuu33//XUaOHCmVKlUSAOLt7S0zZszQmj9TmMDAQPHw8Hhmv61bt+qc8iuKgQMHCgABIGZmZjJ37lydPteuXRMbGxv56aefNG35hZukpCRp0KCBZrz27dtLZmam7N27VywsLIoc7nr06CGOjo567QeVHqX6tNTevXvx7rvvwsXFBSqVChs2bNB7DBHB9OnTUaNGDajVari6umLq1KklXyw9t8aNG8PU1BRly5bFO++8AycnJ2zdulVzaiQmJgatW7eGjY0NjI2NYWpqiokTJyI1NRXJyckAgOjoaOTk5CAkJESvbW/atAkqlQo9e/bE48ePNS8nJyfUqVMHu3fv1urv5OSEhg0barW99dZbmlNohblw4QLOnj2LHj16AIDW9tq3b4/ExETExcUBABo2bIitW7di3Lhx2L17Nx48eFDkfWratCm++uorzJo1Cx9//DF69uyJfv36FXn9wsj/TgU+fdVT9+7dtdrc3NzQpEkT7Nq1q1jbiYmJgZeXl85nHRwcDBFBTEwMgCef0927d/HBBx/gv//9L1JSUoo0fk5Ojtbn//SprjwNGjTAjBkzkJCQgL1796Jx48b4+uuvUblyZXz66afP3M6NGzdQoUKFZ/aLjIyEiYkJgoODi1R/ns8++wxHjx7F5s2b8eGHH2LIkCGYPn26Vp9BgwahTp06GDBgQKFjOTo64siRI7h06RKuX7+OzZs3w9jYGAMHDsSECRNQvXp1rF27FrVq1YKtrS3eeecdXL16VWecChUqIDk5GY8fP9ZrX6h0KNXh5v79+6hTpw5++OGHYo/xySefYOHChZg+fTrOnj2LjRs36vyhpFfDzz//jKNHj+LEiRO4ceMGTp48iaZNmwIAfv/9dwQEBAAAFixYgAMHDuDo0aMYP348AGh+9G/dugUAqFSpkl7bvnnzJkQEjo6OMDU11XodPnxY58fSzs5OZwy1Wl2k8HHz5k0AwKhRo3S2NXjwYADQbG/OnDkYO3YsNmzYgBYtWsDW1hadOnXC+fPni7RfPXr0gJmZGbKysjB69OgirVO5cmXcunWr0Hk5ly9fBgC4urpqtTs5Oen0dXJyQmpqapG2/bTU1FQ4OzvrtLu4uGiWA0CvXr2waNEiXLlyBV26dEGFChXQqFEjREdHFzp+q1attD7/Dz/8sND+jx49QlpaGu7evYsHDx7AzMwMZcuWfeZ+PHjwAObm5oX2SUlJwa+//ooOHTrk+zkWpnLlyvDx8UH79u0xb948fPTRRwgNDdV8H9asWYNt27bhm2++0dR/9+5dAEB2djbu3r2rNX8qb95T3uc8bdo0GBkZYfTo0ZpgPmPGDFy7dg329vbo2bOnTk3m5uYQEc18HaJ/yn9GWCkRGBiIwMDAApdnZ2djwoQJWLFiBe7evYvatWvj66+/RvPmzQEAZ86cwbx58/D333+jZs2aL6lqKi5PT0/4+Pjku+yXX36BqakpNm3apPUj8fTRPAcHBwDAtWvXdH54C2Nvbw+VSoV9+/ZBrVbrLM+vrbjyJmKGhoaic+fO+fbJ+/+rpaUlwsLCEBYWhps3b2qO4rz77rs4e/ZsodvJyclBjx49UL58eajVavTr1w8HDhyAmZlZoeu1adMGO3bswMaNG9GtWzed5SKCX3/9Fba2tvD29tZalpSUpNM/KSkp3zBYFHZ2dkhMTNRpv3HjBgBoTWrt27cv+vbti/v372Pv3r2YNGkS3nnnHZw7dw5ubm75jv/TTz8hIyND8z6/SbKPHz/Gb7/9hqioKKxfvx4ZGRlo2bIlZs+ejS5dusDa2vqZ+2Fvb4/bt28X2mfZsmXIzs5+ronEeRo2bIiIiAjEx8fDwcEBf//9Nx4/fqyZpP9PCxYswIIFC7B+/Xp06tRJZ3lcXBymTZuGnTt3wtTUFDt37kStWrXQrl07AMDIkSNRp04d3Lt3D1ZWVpr1bt++DbVardVGpGHIc2KvEgCyfv16rbbu3btLkyZNZO/evXLhwgX59ttvRa1Wa84Jf/3111KjRg2ZPn26uLu7i5ubm/Tr109SU1MNsAdUkIImFP/TyJEjxcrKSjM5VkQkMzNTKleuLADk0qVLIvLkMldjY2Pp1atXodt8es7N/v37teaQFMbf319q1ar1zDFPnjwpAPKd/1C9enVp3779M7eVn+HDhwuAZ15mO378eDEyMpKdO3fKoUOHxNTUtEgTbPMuBXd3d5ebN2/qLM+7FHzatGmatrw5N97e3vnOuenXr5+mLb85N/Xr15eGDRvqbCs0NFQAyLFjx7TaQ0JCtObc5GfDhg0CQDZv3vzMfc7PwYMHZeDAgWJvby8ApHHjxjJ79ux854A9y4cffii2traF9qlVq5a4uLjI48ePi1XvP/Xq1UuMjIwkOTlZRJ58L3bt2qXzAiCdOnWSXbt2FXhpt7+/v9bk7Tlz5kjNmjU17w8cOCAAJD09XWu9Nm3aSL169Z57X0iZGG7+5+lwc+HCBVGpVJpZ/3latWoloaGhIvJkkp1arZZGjRrJ3r17ZdeuXVK3bl1p0aLFyyydnqEo4ea3334TAPL+++/Ljh07ZNWqVeLt7S3Vq1fXCjci/3+11Pvvvy9r166VnTt3ypw5c7RuKpbf1VIfffSRlClTRkaPHi0bN26UmJgYWbFihXz88cdaAaWo4eb+/ftiYWEhTZs2lV27dsnRo0c1/3+NiYkRtVotAQEBsnLlStmzZ4+sX79epk6dKu+//75mjIYNG8rkyZNlw4YNsmfPHomIiBA7Ozvx9fUt9DPdsWOHGBkZyaRJkzRt06dPFwCybt26QtcV0b2J3+7du+XXX3+VHj16FHoTv7yrpTZt2iQrVqyQatWqSdmyZeXChQuavvmFmz59+oharZZffvlFfv/9d80VXXlXSzk5Ocn8+fNl+/btMmzYMFGpVDJ48GDN+v3795ehQ4fKL7/8Inv27JGoqCipW7eu2NjYaH7g9ZX333nKlCkSHx9frDHy/PzzzwKgwDB2+PBhASCfffZZgWOEhYWJsbGx7N69W9M2YMAA+fTTTyUqKkp2794ta9askaCgIAEgo0ePfmZdyGdC8T9FRkaKs7Oz3L17V9N26tQpMTY2ls8//1x27Nghvr6+0rRpU631cnJyxMbGRkaOHPnMGqh0Yrj5n6fDzX/+8x8BIJaWllovExMT6dq1q4g8+eI//Qfl2LFjAkDOnj37sneBClCUcCMismjRIqlZs6ao1WqpWrWqhIeHS2RkpE64EXnyY9KgQQMxNzcXKysrqVevntZVS/mFm7xtNGrUSCwtLcXCwkLeeOMN6d27t/zxxx+aPkUNNyJPLlH28PAQU1NTAaAVNv7880/p2rWrVKhQQUxNTcXJyUlatmypdQnvuHHjxMfHR8qXL6/Z7xEjRkhKSkqBn9ONGzekQoUK0rJlS60AkpubK++++66UK1dO5/PKT0JCgoSEhEjVqlXFzMxMbGxspFmzZrJ8+XKdm9vlhZtly5bJsGHDxMHBQdRqtfj5+Wl9diL5h5vLly9LQECAlC1bVgBofY5XrlyR7t27i52dnZiamkrNmjXl22+/1dq3pUuXSosWLcTR0VHMzMzExcVFunbt+szL3gtz48aNYq/7tLS0NLGyspJvvvkm3+UDBgwQlUqldcn80/I+t127dmnaFi1aJH5+fmJvby8mJiZSrlw58ff317mjcEEKCzfJyclia2ub740ZV6xYIdWrVxcrKytp06aNTvjL+8fI00fciPLwwZn/o1KptM4JR0VFoUePHjh16hSMjY21+lpZWcHJyQmTJk3C1KlTtSbKPXjwAGXKlMGOHTvQpk2bl7kLRFSKDR06FL/99htOnTqlc5WZ0vTq1Qvx8fE4cOCAoUuhV1SpvlqqMPXq1UNOTg6Sk5NRrVo1rVfelQZNmzbF48ePcfHiRc16586dA4ACJxgSEb0IEyZMwPXr17F27VpDl/JCXbx4EVFRUfj6668NXQq9wkr1kZt79+7hwoULAJ6EmZkzZ2ouh61cuTJ69uyJAwcOYMaMGahXrx5SUlIQExODN998E+3bt0dubi4aNGgAKysrzJo1C7m5uQgJCYG1tTV27Nhh4L0jotJm06ZNuHPnTpEew/C62rVrF86fP4+PPvrI0KXQK6xUh5vdu3ejRYsWOu19+vTBkiVL8OjRI0yZMgU///wzrl+/Djs7O/j6+iIsLAxvvvkmgCeXjA4dOhQ7duyApaUlAgMDMWPGDNja2r7s3SEiIiKU8nBDREREysM5N0RERKQope4Oxbm5ubhx4wbKli2r+CsKiIiIlEJEkJGRARcXFxgZFX5sptSFmxs3buh123wiIiJ6dVy9evWZz/crdeEm7yF0V69eLdIzW4iIiMjw0tPT4erqWqSHyZa6cJN3Ksra2prhhoiI6DVTlCklnFBMREREimLQcLN37168++67cHFxgUqlwoYNG565zp49e+Dt7Q1zc3NUrVoVERERL75QIiIiem0YNNzcv38fderUwQ8//FCk/pcuXUL79u3h5+eHEydO4LPPPsOwYcMUf7txpcvIyMDw4cPh5uYGCwsLNGnSBEePHtUsV6lU+b6+/fZbTZ/58+ejefPmsLa2hkqlwt27d/Pd1ubNm9GoUSNYWFjA3t4enTt31ixLTU1Fu3bt4OLiArVaDVdXVwwZMgTp6emaPnFxcWjRogUcHR01AXvChAlazxcjIiLDMuicm8DAQAQGBha5f0REBCpXroxZs2YBADw9PfHHH39g+vTp6NKlS77rZGVlISsrS/P+nz9U9Gro378//v77byxbtgwuLi5Yvnw5WrdujdOnT6NixYpITEzU6r9161b069dP6795ZmYm2rVrh3bt2iE0NDTf7axduxYDBgzA1KlT0bJlS4gI/vrrL81yIyMjdOzYEVOmTIGDgwMuXLiAkJAQ3L59GytXrgQAmJqaonfv3qhfvz7KlSuHP//8EwMGDEBubi6mTp36Aj4dIiLSm6EeR/40ALJ+/fpC+/j5+cmwYcO02tatWycmJiaSnZ2d7zqTJk0SADqvtLS0kiqdnkNmZqYYGxvLpk2btNrr1Kkj48ePz3edjh07SsuWLfNdtmvXLgEgd+7c0Wp/9OiRVKxYURYuXKhXfbNnz5ZKlSoV2mfEiBHy9ttv6zUuERHpJy0trci/36/VhOKkpCQ4OjpqtTk6OuLx48dISUnJd53Q0FCkpaVpXlevXn0ZpVIRPX78GDk5OTA3N9dqt7CwwP79+3X637x5E5s3b0a/fv302s7x48dx/fp1GBkZoV69enB2dkZgYCBOnTpV4Do3btzAunXr4O/vX2CfCxcuYNu2bYX2ISKil+u1CjeA7iVg8r9HYxV0aZhardZc9s3Lv189ZcuWha+vL7788kvcuHEDOTk5WL58OY4cOaJzOgoAli5dirJly2rNlSmK+Ph4AMAXX3yBCRMmYNOmTShfvjz8/f1x+/Ztrb4ffPABypQpg4oVK8La2hoLFy7UGa9JkyYwNzdH9erV4efnh8mTJ+tVDxERvTivVbhxcnJCUlKSVltycjJMTExgZ2dnoKroeS1btgwigooVK0KtVmPOnDno3r07jI2NdfouWrQIPXr00DnS8yy5ubkAgPHjx6NLly7w9vbG4sWLoVKpsHr1aq2+3333HY4fP44NGzbg4sWLGDlypM54UVFROH78OFauXInNmzdj+vTpetVDREQvzmt1Ez9fX19s3LhRq23Hjh3w8fGBqampgaqi5/XGG29gz549uH//PtLT0+Hs7IygoCBUqVJFq9++ffsQFxeHqKgovbfh7OwMAPDy8tK0qdVqVK1aFQkJCVp9nZyc4OTkBA8PD9jZ2cHPzw+ff/65ZgwAmkd4eHl5IScnBx999BE+/fTTfAMZERG9XAY9cnPv3j3ExsYiNjYWwJNLvWNjYzU/NqGhoejdu7em/6BBg3DlyhWMHDkSZ86cwaJFixAZGYlRo0YZonwqYZaWlnB2dsadO3ewfft2dOzYUWt5ZGQkvL29UadOHb3H9vb2hlqtRlxcnKbt0aNHuHz5Mtzc3ApcL++05z+vuMuvz6NHjzR9iYjIsAx65OaPP/5AixYtNO/zDv/36dMHS5YsQWJiota/qqtUqYItW7ZgxIgR+PHHH+Hi4oI5c+YUeBk4vR62b98OEUHNmjVx4cIFjB49GjVr1kTfvn01fdLT07F69WrMmDEj3zGSkpKQlJSECxcuAAD++usvlC1bFpUrV4atrS2sra0xaNAgTJo0Ca6urnBzc9PcJ+ff//43AGDLli24efMmGjRoACsrK5w+fRpjxoxB06ZN4e7uDgBYsWIFTE1N8eabb0KtVuPYsWMIDQ1FUFAQTExeqwOhRETK9UKv23oF6XMpGb0cUVFRUrVqVTEzMxMnJycJCQmRu3fvavX56aefxMLCQqc9T0GX/C9evFjTJzs7Wz799FOpUKGClC1bVlq3bi1///23ZnlMTIz4+vqKjY2NmJubS/Xq1WXs2LFal5X/8ssvUr9+fbGyshJLS0vx8vKSqVOnyoMHD0r0MyEiIm36/H6rRErXsfT09HTY2NggLS2NV04RERG9JvT5/X6trpYiIiIiehaGGyIiIlIUzoAsRQq4zyEpVOk64UxE9P945IaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBTF4OFm7ty5qFKlCszNzeHt7Y19+/YV2n/FihWoU6cOypQpA2dnZ/Tt2xepqakvqVoiIiJ61Rk03ERFRWH48OEYP348Tpw4AT8/PwQGBiIhISHf/vv370fv3r3Rr18/nDp1CqtXr8bRo0fRv3//l1w5ERERvaoMGm5mzpyJfv36oX///vD09MSsWbPg6uqKefPm5dv/8OHDcHd3x7Bhw1ClShW8/fbbGDhwIP7444+XXDkRERG9qgwWbrKzs3Hs2DEEBARotQcEBODgwYP5rtOkSRNcu3YNW7ZsgYjg5s2bWLNmDTp06FDgdrKyspCenq71IiIiIuUyWLhJSUlBTk4OHB0dtdodHR2RlJSU7zpNmjTBihUrEBQUBDMzMzg5OaFcuXL4/vvvC9xOeHg4bGxsNC9XV9cS3Q8iIiJ6tRh8QrFKpdJ6LyI6bXlOnz6NYcOGYeLEiTh27Bi2bduGS5cuYdCgQQWOHxoairS0NM3r6tWrJVo/ERERvVpMDLVhe3t7GBsb6xylSU5O1jmakyc8PBxNmzbF6NGjAQBvvfUWLC0t4efnhylTpsDZ2VlnHbVaDbVaXfI7QERERK8kgx25MTMzg7e3N6Kjo7Xao6Oj0aRJk3zXyczMhJGRdsnGxsYAnhzxISIiIjLoaamRI0di4cKFWLRoEc6cOYMRI0YgISFBc5opNDQUvXv31vR/9913sW7dOsybNw/x8fE4cOAAhg0bhoYNG8LFxcVQu0FERESvEIOdlgKAoKAgpKamYvLkyUhMTETt2rWxZcsWuLm5AQASExO17nkTHByMjIwM/PDDD/j0009Rrlw5tGzZEl9//bWhdoGIiIheMSopZedz0tPTYWNjg7S0NFhbWxu6nJeqgHnapFCl65tNREqnz++3wa+WIiIiIipJDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKMUKN8ePH8dff/2lef/f//4XnTp1wmeffYbs7OwSK46IiIhIX8UKNwMHDsS5c+cAAPHx8ejWrRvKlCmD1atXY8yYMSVaIBEREZE+ihVuzp07h7p16wIAVq9ejWbNmmHlypVYsmQJ1q5dW5L1EREREemlWOFGRJCbmwsA2LlzJ9q3bw8AcHV1RUpKSslVR0RERKSnYoUbHx8fTJkyBcuWLcOePXvQoUMHAMClS5fg6OhYogUSERER6aNY4WbWrFk4fvw4hgwZgvHjx6NatWoAgDVr1qBJkyYlWiARERGRPlQiIiU12MOHD2FsbAxTU9OSGrLEpaenw8bGBmlpabC2tjZ0OS+VSmXoCuhlKrlvNhGR4enz+13s+9zcvXsXCxcuRGhoKG7fvg0AOH36NJKTk4s7JBEREdFzMynOSidPnkSrVq1Qrlw5XL58GQMGDICtrS3Wr1+PK1eu4Oeffy7pOomIiIiKpFhHbkaOHIm+ffvi/PnzMDc317QHBgZi7969JVYcERERkb6KFW6OHj2KgQMH6rRXrFgRSUlJz10UERERUXEVK9yYm5sjPT1dpz0uLg4ODg7PXRQRERFRcRUr3HTs2BGTJ0/Go0ePAAAqlQoJCQkYN24cunTpotdYc+fORZUqVWBubg5vb2/s27ev0P5ZWVkYP3483NzcoFar8cYbb2DRokXF2Q0iIiJSoGKFm+nTp+PWrVuoUKECHjx4AH9/f1SrVg1ly5bFV199VeRxoqKiMHz4cIwfPx4nTpyAn58fAgMDkZCQUOA6Xbt2xW+//YbIyEjExcVh1apV8PDwKM5uEBERkQI9131uYmJicPz4ceTm5qJ+/fpo3bq1Xus3atQI9evXx7x58zRtnp6e6NSpE8LDw3X6b9u2Dd26dUN8fDxsbW2LtI2srCxkZWVp3qenp8PV1ZX3uSHF431uiEhJXvh9bn7++WdkZWWhZcuWGDVqFMaMGYPWrVsjOzu7yJeBZ2dn49ixYwgICNBqDwgIwMGDB/Nd59dff4WPjw+++eYbVKxYETVq1MCoUaPw4MGDArcTHh4OGxsbzcvV1bXoO0pERESvnWKFm759+yItLU2nPSMjA3379i3SGCkpKcjJydF5FpWjo2OBV1zFx8dj//79+Pvvv7F+/XrMmjULa9asQUhISIHbCQ0NRVpamuZ19erVItVHREREr6di3cRPRKDK5xzHtWvXYGNjo9dYT49T0NgAkJubC5VKhRUrVmi2M3PmTLz//vv48ccfYWFhobOOWq2GWq3WqyYiIiJ6fekVburVqweVSgWVSoVWrVrBxOT/V8/JycGlS5fQrl27Io1lb28PY2NjnaM0ycnJBT5Z3NnZGRUrVtQKUJ6enhARXLt2DdWrV9dnd4iIiEiB9Ao3nTp1AgDExsaibdu2sLKy0iwzMzODu7t7kS8FNzMzg7e3N6Kjo/Hee+9p2qOjo9GxY8d812natClWr16Ne/fuabZ97tw5GBkZoVKlSvrsChERESlUsa6WWrp0KYKCgrQevVAcUVFR6NWrFyIiIuDr64v58+djwYIFOHXqFNzc3BAaGorr169rJinfu3cPnp6eaNy4McLCwpCSkoL+/fvD398fCxYsKNI2+VRwKi14tRQRKYk+v9/FmnPTp08fAE+ueEpOTkZubq7W8sqVKxdpnKCgIKSmpmLy5MlITExE7dq1sWXLFri5uQEAEhMTte55Y2VlhejoaAwdOhQ+Pj6ws7ND165dMWXKlOLsBhERESlQsY7cnD9/Hh9++KHOJdt5k4FzcnJKrMCSxiM3VFrwyA0RKckLP3ITHBwMExMTbNq0Cc7OzgVe3URERET0shUr3MTGxuLYsWN87AERERG9cop1Ez8vLy+kpKSUdC1EREREz61Y4ebrr7/GmDFjsHv3bqSmpiI9PV3rRURERGQoxZpQbGT0JBMVdHdhTih+NXFqVOnCCcVEpCQvfELxrl27ilUYERER0YtWrHDj7+9f0nUQERERlYhizbkBgH379qFnz55o0qQJrl+/DgBYtmwZ9u/fX2LFEREREemrWOFm7dq1aNu2LSwsLHD8+HFkZWUBADIyMjB16tQSLZCIiIhIH8UKN1OmTEFERAQWLFgAU1NTTXuTJk1w/PjxEiuOiIiISF/FCjdxcXFo1qyZTru1tTXu3r37vDURERERFVuxwo2zszMuXLig075//35UrVr1uYsiIiIiKq5ihZuBAwfik08+wZEjR6BSqXDjxg2sWLECo0aNwuDBg0u6RiIiIqIiK9al4GPGjEFaWhpatGiBhw8folmzZlCr1Rg1ahSGDBlS0jUSERERFVmx7lCcJzMzE6dPn0Zubi68vLxgZWVVkrW9ELxDMZUWvEMxESnJC79DcZ4yZcrAx8fneYYgIiIiKlFFDjedO3fGkiVLYG1tjc6dOxfad926dc9dGBEREVFxFDnc2NjYaB6UaWNj88IKIiIiInoezzXn5nXEOTdUWpSubzYRKZ0+v9/FuhT80qVLOH/+vE77+fPncfny5eIMSURERFQiihVugoODcfDgQZ32I0eOIDg4+HlrIiIiIiq2YoWbEydOoGnTpjrtjRs3Rmxs7PPWRERERFRsxQo3KpUKGRkZOu1paWnIycl57qKIiIiIiqtY4cbPzw/h4eFaQSYnJwfh4eF4++23S6w4IiIiIn0V6yZ+33zzDZo1a4aaNWvCz88PALBv3z6kp6cjJiamRAskIiIi0kexjtx4eXnh5MmT6Nq1K5KTk5GRkYHevXvj7NmzqF27dknXSERERFRkvM9NKcL73JQupeubTURK99KeLZWZmYmEhARkZ2drtb/11lvPMywRERFRsRUr3Ny6dQt9+/bF1q1b813OK6aIiIjIUIo152b48OG4c+cODh8+DAsLC2zbtg1Lly5F9erV8euvv5Z0jURERERFVqwjNzExMfjvf/+LBg0awMjICG5ubmjTpg2sra0RHh6ODh06lHSdREREREVSrCM39+/fR4UKFQAAtra2uHXrFgDgzTffxPHjx0uuOiIiIiI9FSvc1KxZE3FxcQCAunXr4qeffsL169cREREBZ2fnEi2QiIiISB/FOi01fPhw3LhxAwAwadIktG3bFitWrICZmRmWLFlSkvURERER6aVE7nOTmZmJs2fPonLlyrC3ty+Jul4Y3ueGSgve54aIlESf32+9TktlZmYiJCQEFStWRIUKFdC9e3ekpKSgTJkyqF+//isfbIiIiEj59Ao3kyZNwpIlS9ChQwd069YN0dHR+Pjjj19UbURERER602vOzbp16xAZGYlu3boBAHr27ImmTZsiJycHxsbGL6RAIiIiIn3odeTm6tWrmqeAA0DDhg1hYmKimVxMREREZGh6hZucnByYmZlptZmYmODx48clWhQRERFRcel1WkpEEBwcDLVarWl7+PAhBg0aBEtLS03bunXrSq5CIiIiIj3oFW769Omj09azZ88SK4aIiIjoeekVbhYvXvyi6iAiIiIqEcV6/AIRERHRq4rhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSlRMNNYmIiEhISSnJIIiIiIr2UaLhp2bIlqlSpUpJDEhEREelFr/vcPMvPP/+MzMzMkhySiIiISC8lGm4aNGhQksMRERER6Y0TiomIiEhRinzkpnz58lCpVEXqe/v27WIXRERERPQ8ihxuZs2apfnfqampmDJlCtq2bQtfX18AwKFDh7B9+3Z8/vnnJV4kERERUVGpRET0XalLly5o0aIFhgwZotX+ww8/YOfOndiwYUNJ1Vfi0tPTYWNjg7S0NFhbWxu6nJeqiAfeSCH0/2YTEb269Pn9Ltacm+3bt6Ndu3Y67W3btsXOnTuLMyQRERFRiShWuLGzs8P69et12jds2AA7O7vnLoqIiIiouIp1KXhYWBj69euH3bt3a+bcHD58GNu2bcPChQtLtEAiIiIifRQr3AQHB8PT0xNz5szBunXrICLw8vLCgQMH0KhRo5KukYiIiKjIijWh+HXGCcVUWpSubzYRKd0Ln1BsbGyM5ORknfbU1FQYGxvrNdbcuXNRpUoVmJubw9vbG/v27SvSegcOHICJiQnq1q2r1/aIiIhI2YoVbgo62JOVlQUzM7MijxMVFYXhw4dj/PjxOHHiBPz8/BAYGPjMJ4unpaWhd+/eaNWqlV51ExERkfLpNedmzpw5AACVSoWFCxfCyspKsywnJwd79+6Fh4dHkcebOXMm+vXrh/79+wN4cqPA7du3Y968eQgPDy9wvYEDB6J79+4wNjZ+pe+pQ0RERC+fXuHmu+++A/DkyE1ERITWKSgzMzO4u7sjIiKiSGNlZ2fj2LFjGDdunFZ7QEAADh48WOB6ixcvxsWLF7F8+XJMmTLlmdvJyspCVlaW5n16enqR6iMiIqLXk17h5tKlSwCAFi1aYN26dShfvnyxN5ySkoKcnBw4OjpqtTs6OiIpKSnfdc6fP49x48Zh3759MDEpWunh4eEICwsrdp1ERET0einWnJtdu3ahfPnySElJee4jIU8/jFNE8n1AZ05ODrp3746wsDDUqFGjyOOHhoYiLS1N87p69epz1UtERESvNr3Dzd27dxESEgJ7e3s4OjqifPnycHJyQmhoKDIzM4s8jr29PYyNjXWO0iQnJ+sczQGAjIwM/PHHHxgyZAhMTExgYmKCyZMn488//4SJiQliYmLy3Y5arYa1tbXWi4iIiJRLr9NSt2/fhq+vL65fv44ePXrA09MTIoIzZ87g+++/R3R0NPbv348///wTR44cwbBhwwocy8zMDN7e3oiOjsZ7772naY+OjkbHjh11+ltbW+Ovv/7Saps7dy5iYmKwZs0aVKlSRZ9dISIiIoXSK9xMnjwZZmZmuHjxos7RlcmTJyMgIAC9evXCjh07NFdWFWbkyJHo1asXfHx84Ovri/nz5yMhIQGDBg0C8OSU0vXr1/Hzzz/DyMgItWvX1lq/QoUKMDc312knIiKi0kuvcLNhwwb89NNP+Z42cnJywjfffIP27dtj0qRJ6NOnzzPHCwoKQmpqKiZPnozExETUrl0bW7ZsgZubGwAgMTHxmfe8ISIiIvonvR6/oFarcfHiRVSqVCnf5deuXYO7uzseP35cYgWWND5+gUoLPn6BiJTkhT1+wd7eHpcvXy5w+aVLl1ChQgV9hiQiIiIqUXqFm3bt2mH8+PHIzs7WWZaVlYXPP/8c7dq1K7HiiIiIiPSl12mpa9euwcfHB2q1GiEhIZpHLZw+fRpz585FVlYWjh49isqVK7+wgp8XT0tRacHTUkSkJPr8fus1obhSpUo4dOgQBg8ejNDQUM0DNFUqFdq0aYMffvjhlQ42REREpHx6hRsAqFKlCrZu3Yo7d+7g/PnzAIBq1arB1ta2xIsjIiIi0pfe4SZP+fLl0bBhw5KshYiIiOi5FevZUkRERESvKoYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIOHm7lz56JKlSowNzeHt7c39u3bV2DfdevWoU2bNnBwcIC1tTV8fX2xffv2l1gtERERveoMGm6ioqIwfPhwjB8/HidOnICfnx8CAwORkJCQb/+9e/eiTZs22LJlC44dO4YWLVrg3XffxYkTJ15y5URERPSqUomIGGrjjRo1Qv369TFv3jxNm6enJzp16oTw8PAijVGrVi0EBQVh4sSJReqfnp4OGxsbpKWlwdraulh1v65UKkNXQC+T4b7ZREQlT5/fb4MducnOzsaxY8cQEBCg1R4QEICDBw8WaYzc3FxkZGTA1ta2wD5ZWVlIT0/XehEREZFyGSzcpKSkICcnB46Ojlrtjo6OSEpKKtIYM2bMwP3799G1a9cC+4SHh8PGxkbzcnV1fa66iYiI6NVm8AnFqqfOlYiITlt+Vq1ahS+++AJRUVGoUKFCgf1CQ0ORlpameV29evW5ayYiIqJXl4mhNmxvbw9jY2OdozTJyck6R3OeFhUVhX79+mH16tVo3bp1oX3VajXUavVz10tERESvB4MduTEzM4O3tzeio6O12qOjo9GkSZMC11u1ahWCg4OxcuVKdOjQ4UWXSURERK8Zgx25AYCRI0eiV69e8PHxga+vL+bPn4+EhAQMGjQIwJNTStevX8fPP/8M4Emw6d27N2bPno3GjRtrjvpYWFjAxsbGYPtBRERErw6DhpugoCCkpqZi8uTJSExMRO3atbFlyxa4ubkBABITE7XuefPTTz/h8ePHCAkJQUhIiKa9T58+WLJkycsun4iIiF5BBr3PjSHwPjdUWpSubzYRKd1rcZ8bIiIioheB4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIheCnd3d6hUKp1XSEiIps+ZM2fwr3/9CzY2NihbtiwaN26MhIQEzfKLFy/ivffeg4ODA6ytrdG1a1fcvHkz3+1lZWWhbt26UKlUiI2N1bT/+eef+OCDD+Dq6goLCwt4enpi9uzZL2y/6eVjuCEiopfi6NGjSExM1Lyio6MBAP/+978BPAkub7/9Njw8PLB79278+eef+Pzzz2Fubg4AuH//PgICAqBSqRATE4MDBw4gOzsb7777LnJzc3W2N2bMGLi4uOi0Hzt2DA4ODli+fDlOnTqF8ePHIzQ0FD/88MML3Ht6mVQiIoYu4mVKT0+HjY0N0tLSYG1tbehyXiqVytAV0MtUur7Z9DoaPnw4Nm3ahPPnz0OlUqFbt24wNTXFsmXL8u2/Y8cOBAYG4s6dO5q/33fu3IGtrS2io6PRunVrTd+tW7di5MiRWLt2LWrVqoUTJ06gbt26BdYSEhKCM2fOICYmpkT3kUqOPr/fPHJDREQvXXZ2NpYvX44PP/wQKpUKubm52Lx5M2rUqIG2bduiQoUKaNSoETZs2KBZJysrCyqVCmq1WtNmbm4OIyMj7N+/X9N28+ZNDBgwAMuWLUOZMmWKVE9aWhpsbW1LbP/IsBhuiIjopduwYQPu3r2L4OBgAEBycjLu3buHadOmoV27dtixYwfee+89dO7cGXv27AEANG7cGJaWlhg7diwyMzNx//59jB49Grm5uUhMTAQAiAiCg4MxaNAg+Pj4FKmWQ4cO4T//+Q8GDhz4QvaVXj6GGyIieukiIyMRGBiomROTN2emY8eOGDFiBOrWrYtx48bhnXfeQUREBADAwcEBq1evxsaNG2FlZaU5RVG/fn0YGxsDAL7//nukp6cjNDS0SHWcOnUKHTt2xMSJE9GmTZsXsKdkCCaGLoCIiEqXK1euYOfOnVi3bp2mzd7eHiYmJvDy8tLq6+npqXXKKSAgABcvXkRKSgpMTExQrlw5ODk5oUqVKgCAmJgYHD58WOvUFQD4+PigR48eWLp0qabt9OnTaNmyJQYMGIAJEya8iF0lA2G4ISKil2rx4sWoUKECOnTooGkzMzNDgwYNEBcXp9X33LlzcHNz0xnD3t4ewJMwk5ycjH/9618AgDlz5mDKlCmafjdu3EDbtm0RFRWFRo0aadpPnTqFli1bok+fPvjqq69KdP/I8BhuiIjopcnNzcXixYvRp08fmJho/wSNHj0aQUFBaNasGVq0aIFt27Zh48aN2L17t6bP4sWL4enpCQcHBxw6dAiffPIJRowYgZo1awIAKleurDWmlZUVAOCNN95ApUqVADwJNi1atEBAQABGjhyJpKQkAICxsTEcHBxe1K7TS8RwQ0REL83OnTuRkJCADz/8UGfZe++9h4iICISHh2PYsGGoWbMm1q5di7ffflvTJy4uDqGhobh9+zbc3d0xfvx4jBgxQq8aVq9ejVu3bmHFihVYsWKFpt3NzQ2XL18u9r7Rq4P3uSlFeJ+b0qV0fbOJSOl4nxsiIiIqtXhaiohICXhotnThodlC8cgNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESmKwcPN3LlzUaVKFZibm8Pb2xv79u0rtP+ePXvg7e0Nc3NzVK1aFRERES+pUiIiInodGDTcREVFYfjw4Rg/fjxOnDgBPz8/BAYGIiEhId/+ly5dQvv27eHn54cTJ07gs88+w7Bhw7B27dqXXDkRERG9qlQiIobaeKNGjVC/fn3MmzdP0+bp6YlOnTohPDxcp//YsWPx66+/4syZM5q2QYMG4c8//8ShQ4eKtM309HTY2NggLS0N1tbWz78TrxGVytAV0MtkuG82GQS/4KVLKfyC6/P7bfKSatKRnZ2NY8eOYdy4cVrtAQEBOHjwYL7rHDp0CAEBAVptbdu2RWRkJB49egRTU1OddbKyspCVlaV5n5aWBuDJh0SkZPy/OJGClcIveN7vdlGOyRgs3KSkpCAnJweOjo5a7Y6OjkhKSsp3naSkpHz7P378GCkpKXB2dtZZJzw8HGFhYTrtrq6uz1E90avPxsbQFRDRC1OKv+AZGRmwecb+Gyzc5FE9dShVRHTantU/v/Y8oaGhGDlypOZ9bm4ubt++DTs7u0K3Q8qQnp4OV1dXXL16tdSdhiRSOn6/SxcRQUZGBlxcXJ7Z12Dhxt7eHsbGxjpHaZKTk3WOzuRxcnLKt7+JiQns7OzyXUetVkOtVmu1lStXrviF02vJ2tqaf/yIFIrf79LjWUds8hjsaikzMzN4e3sjOjpaqz06OhpNmjTJdx1fX1+d/jt27ICPj0++822IiIio9DHopeAjR47EwoULsWjRIpw5cwYjRoxAQkICBg0aBODJKaXevXtr+g8aNAhXrlzByJEjcebMGSxatAiRkZEYNWqUoXaBiIiIXjEGnXMTFBSE1NRUTJ48GYmJiahduza2bNkCNzc3AEBiYqLWPW+qVKmCLVu2YMSIEfjxxx/h4uKCOXPmoEuXLobaBXrFqdVqTJo0SefUJBG9/vj9poIY9D43RERERCXN4I9fICKi0uuvv/7C999/b+gySGEYboiIyCAePXqEnj17omrVqoYuhRSGp6WIiMggTp06hRMnTqBnz56GLoUUhkduiEqQSqXChg0bDF0G0WuhVq1aBQYbd3d3zJo1q9D1+X2jgjDcULEEBwdDpVJBpVLBxMQElStXxscff4w7d+4YujQiesVdvXoV/fr1g4uLC8zMzODm5oZPPvkEqampeo2TmJiIwMBAAMDly5ehUqkQGxv7Aiqm1w3DDRVbu3btkJiYiMuXL2PhwoXYuHEjBg8ebOiynktOTg5yc3MNXQaRYsXHx8PHxwfnzp3DqlWrcOHCBUREROC3336Dr68vbt++XeSxnJyceBk45YvhhopNrVbDyckJlSpVQkBAAIKCgrBjxw7N8sWLF8PT0xPm5ubw8PDA3Llztda/du0aunXrBltbW1haWsLHxwdHjhwB8OTIUKdOnbT6Dx8+HM2bN9e8b968OYYMGYIhQ4agXLlysLOzw4QJE7SeGJudnY0xY8agYsWKsLS0RKNGjbB7927N8iVLlqBcuXLYtGkTvLy8oFarceXKFRw9ehRt2rSBvb09bGxs4O/vj+PHj2vVc/78eTRr1gzm5ubw8vLSuXs28ORKkJYtW8LCwgJ2dnb46KOPcO/ePc3y3bt3o2HDhrC0tES5cuXQtGlTXLlypcj/DYheNyEhITAzM8OOHTvg7++PypUrIzAwEDt37sT169cxfvx4Td+MjAx0794dVlZWcHFx0bmq6p+npapUqQIAqFevHlQqleZvRW5uLiZPnoxKlSpBrVajbt262LZtm2aM7OxsDBkyBM7OzjA3N4e7uzvCw8Nf7IdALxzDDZWI+Ph4bNu2TfMYjAULFmD8+PH46quvcObMGUydOhWff/45li5dCgC4d+8e/P39cePGDfz666/4888/MWbMGL2PmixduhQmJiY4cuQI5syZg++++w4LFy7ULO/bty8OHDiAX375BSdPnsS///1vtGvXDufPn9f0yczMRHh4OBYuXIhTp06hQoUKyMjIQJ8+fbBv3z4cPnwY1atXR/v27ZGRkQHgyR/Mzp07w9jYGIcPH0ZERATGjh2rVVtmZibatWuH8uXL4+jRo1i9ejV27tyJIUOGAAAeP36MTp06wd/fHydPnsShQ4fw0Ucf8YGupFi3b9/G9u3bMXjwYFhYWGgtc3JyQo8ePRAVFaX5B8q3336Lt956C8ePH0doaChGjBiR7z8iAOD3338HAOzcuROJiYlYt24dAGD27NmYMWMGpk+fjpMnT6Jt27b417/+pfkbMGfOHPz666/4z3/+g7i4OCxfvhzu7u4v6BOgl0aIiqFPnz5ibGwslpaWYm5uLgAEgMycOVNERFxdXWXlypVa63z55Zfi6+srIiI//fSTlC1bVlJTUwscv2PHjlptn3zyifj7+2ve+/v7i6enp+Tm5mraxo4dK56eniIicuHCBVGpVHL9+nWtcVq1aiWhoaEiIrJ48WIBILGxsYXu7+PHj6Vs2bKyceNGERHZvn27GBsby9WrVzV9tm7dKgBk/fr1IiIyf/58KV++vNy7d0/TZ/PmzWJkZCRJSUmSmpoqAGT37t2FbptIKQ4fPqz1HXnazJkzBYDcvHlT3NzcpF27dlrLg4KCJDAwUPP+n2NdunRJAMiJEye01nFxcZGvvvpKq61BgwYyePBgEREZOnSotGzZUuvvCL3+eOSGiq1FixaIjY3FkSNHMHToULRt2xZDhw7FrVu3NBMGraysNK8pU6bg4sWLAIDY2FjUq1cPtra2z1VD48aNtY50+Pr64vz588jJycHx48chIqhRo4ZWHXv27NHUATx5iOtbb72lNW5ycjIGDRqEGjVqwMbGBjY2Nrh3757mcSBnzpxB5cqVUalSJa1t/9OZM2dQp04dWFpaatqaNm2K3NxcxMXFwdbWFsHBwWjbti3effddzJ49G4mJic/1eRC9zuR/R2zyvtNPf6d8fX1x5syZIo+Xnp6OGzduoGnTplrtTZs21YwTHByM2NhY1KxZE8OGDdM6tU6vL4M+W4peb5aWlqhWrRqAJ4d2W7RogbCwMM1plwULFqBRo0Za6xgbGwOAziHppxkZGWnNnQGe3PBLH7m5uTA2NsaxY8c0281jZWWl+d8WFhY6p4KCg4Nx69YtzJo1C25ublCr1fD19UV2djYA6NQGQGcMESnwFFNe++LFizFs2DBs27YNUVFRmDBhAqKjo9G4cWO99pXodVCtWjWoVCqcPn1aZ04dAJw9exbly5eHvb19gWMU57RtYd/N+vXr49KlS9i6dSt27tyJrl27onXr1lizZo3e26FXB4/cUImZNGkSpk+fjpycHFSsWBHx8fGoVq2a1itv0t9bb72F2NjYAq+McHBw0DmKkd8lnocPH9Z5X716dRgbG6NevXrIyclBcnKyTh1OTk6F7su+ffswbNgwtG/fHrVq1YJarUZKSopmuZeXFxISEnDjxg1N26FDh7TG8PLyQmxsLO7fv69pO3DgAIyMjFCjRg1NW7169RAaGoqDBw+idu3aWLlyZaG1Eb2u7Ozs0KZNG8ydOxcPHjzQWpaUlIQVK1YgKChIEzzy+357eHjkO7aZmRmAJ1c85rG2toaLiwv279+v1ffgwYPw9PTU6hcUFIQFCxYgKioKa9eu1euqLXoFGfKcGL2+8psTIyLi7e0tISEhsmDBArGwsJBZs2ZJXFycnDx5UhYtWiQzZswQEZGsrCypUaOG+Pn5yf79++XixYuyZs0aOXjwoIiIbNu2TVQqlSxdulTOnTsnEydOFGtra505N1ZWVjJixAg5e/asrFy5UiwtLSUiIkLTp0ePHuLu7i5r166V+Ph4+f3332XatGmyefNmEXky58bGxkZnP+rWrStt2rSR06dPy+HDh8XPz08sLCzku+++ExGRnJwc8fLyklatWklsbKzs3btXvL29teYA3L9/X5ydnaVLly7y119/SUxMjFStWlX69OkjIiLx8fEybtw4OXjwoFy+fFm2b98utra2Mnfu3Of7j0P0Cjt37pzY29uLn5+f7NmzRxISEmTr1q1Su3ZtqV69umYenpubm1hbW8vXX38tcXFx8sMPP4ixsbFs27ZNM9Y/v2+PHj0SCwsLmTJliiQlJcndu3dFROS7774Ta2tr+eWXX+Ts2bMyduxYMTU1lXPnzonIk3k+q1atkjNnzkhcXJz069dPnJycJCcn5+V+MFSiGG6oWAoKNytWrBAzMzNJSEiQFStWSN26dcXMzEzKly8vzZo1k3Xr1mn6Xr58Wbp06SLW1tZSpkwZ8fHxkSNHjmiWT5w4URwdHcXGxkZGjBghQ4YM0Qk3gwcPlkGDBom1tbWUL19exo0bpzUxMDs7WyZOnCju7u5iamoqTk5O8t5778nJkydFpOBwc/z4cfHx8RG1Wi3Vq1eX1atXi5ubmybciIjExcXJ22+/LWZmZlKjRg3Ztm2bzmTJkydPSosWLcTc3FxsbW1lwIABkpGRISIiSUlJ0qlTJ3F2dhYzMzNxc3OTiRMn8o8qKd7ly5clODhYnJycxNTUVFxdXWXo0KGSkpKi6ePm5iZhYWHStWtXKVOmjDg6OsqsWbO0xnn6+7ZgwQJxdXUVIyMjzd+KnJwcCQsLk4oVK4qpqanUqVNHtm7dqlln/vz5UrduXbG0tBRra2tp1aqVHD9+/IXuP714fLYUvbaaN2+OunXrPvMW7UREVLpwzg0REREpCsMNERERKQpPSxEREZGi8MgNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNEb00wcHBUKlUUKlUMDU1RdWqVTFq1Cith4t+9NFHMDY2xi+//KKz/v379zF27FhUrVoV5ubmcHBwQPPmzbFp0yZNn/j4eHzwwQdwcXGBubk5KlWqhI4dO+LcuXOaPnk1PP3K2+bu3bs1bUZGRrCxsUG9evUwZswYnQe6EtGrx8TQBRBR6dKuXTssXrwYjx49wr59+9C/f3/cv38f8+bNQ2ZmJqKiojB69GhERkaiW7duWusOGjQIv//+O3744Qd4eXkhNTUVBw8eRGpqKgAgOzsbbdq0gYeHB9atWwdnZ2dcu3YNW7ZsQVpamtZYixcvRrt27bTaypUrp/U+Li4O1tbWSE9Px/Hjx/HNN98gMjISu3fvxptvvlnyHw4RlQjexI+IXprg4GDcvXsXGzZs0LQNGDAAmzZtQmJiIpYuXYqIiAhs27YNzs7OOH36NNzd3TV9y5Urh9mzZ6NPnz75jh8bG4t69erh8uXLcHNzK7AOlUqF9evXo1OnTvku3717N1q0aIE7d+5oBZ4HDx6gXr16sLe3x/79+/XZdSJ6iXhaiogMysLCAo8ePQIAREZGomfPnrCxsUH79u2xePFirb5OTk7YsmULMjIy8h3LwcEBRkZGWLNmDXJycl5IrYMGDcKBAweQnJxc4uMTUclguCEig/n999+xcuVKtGrVCufPn8fhw4cRFBQEAOjZsycWL16M3NxcTf/58+fj4MGDsLOzQ4MGDTBixAgcOHBAs7xixYqYM2cOJk6ciPLly6Nly5b48ssvER8fr7PtDz74AFZWVlqv/Po9zcPDAwBw+fLl59x7InpRGG6I6KXatGkTrKysYG5uDl9fXzRr1gzff/89IiMj0bZtW9jb2wMA2rdvj/v372Pnzp2adZs1a4b4+Hj89ttv6NKlC06dOgU/Pz98+eWXmj4hISFISkrC8uXL4evri9WrV6NWrVqIjo7WquO7775DbGys1svV1fWZ9eedyVepVCXxcRDRC8A5N0T00gQHB+P69euYN28eTE1N4eLiAlNTU+Tk5MDV1RVJSUkwMvr/f3Pl5OSga9euiIqKKnDMKVOmYPLkybh37x7MzMx0losI2rZti6ysLOzZswdA8efcAMDMmTPx6aefIjk5GQ4ODvp/CET0wvFqKSJ6qSwtLVGtWjWttrx5NCdOnICxsbGm/ezZs+jRowdSU1NhZ2eX73heXl54/PgxHj58mG+4UalU8PDwwMGDB5+79gcPHmD+/Plo1qwZgw3RK4zhhogMLjIyEh06dECdOnW02mvVqoXhw4dj+fLl+OSTT9C8eXN88MEH8PHxgZ2dHU6fPo3PPvsMLVq0gLW1NWJjYzFp0iT06tULXl5eMDMzw549e7Bo0SKMHTtWa+y7d+8iKSlJq61s2bKwtLTUvE9OTsbDhw+RkZGBY8eO4ZtvvkFKSgrWrVv34j4MInpuDDdEZFA3b97E5s2bsXLlSp1lKpUKnTt3RmRkJD755BO0bdsWS5cuxWeffYbMzEy4uLjgnXfewcSJEwEAlSpVgru7O8LCwnD58mWoVCrN+xEjRmiN3bdvX53thYeHY9y4cZr3NWvWhEqlgpWVFapWrYqAgACMHDkSTk5OJfwpEFFJ4pwbIiIiUhReLUVERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREivJ/rpwDyP+TcxYAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_percentual_deads(covid_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvK8ds_UuR4E",
        "outputId": "a2da688e-e74e-44e4-a4f6-87060814929c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1048575, 21)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th5dFn3rV5iq"
      },
      "source": [
        "# Tratando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N7dQsvSiaGU"
      },
      "source": [
        "### Coluna PREGNANT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rzrtly8idui",
        "outputId": "7ed9e956-64aa-4279-a31d-50815cbb94aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PREGNANT\n",
              "97    523511\n",
              "2     513179\n",
              "1       8131\n",
              "98      3754\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df['PREGNANT'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwzVvlkDX8tS",
        "outputId": "ddef3c44-3e4c-4938-db99-4ff52e3c51e1"
      },
      "outputs": [],
      "source": [
        "#Altera os valores para Homens, para sem gravidez\n",
        "covid_df['PREGNANT'] = covid_df['PREGNANT'].replace(97, 2)\n",
        "\n",
        "#Remove linhas com valores ausentes\n",
        "covid_df = covid_df.drop(covid_df[covid_df.PREGNANT == 98].index)\n",
        "covid_df = covid_df[(covid_df.PREGNANT == 1) | (covid_df.PREGNANT == 2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PREGNANT\n",
              "2    1036690\n",
              "1       8131\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Resultado apos tratamento\n",
        "# Como há poucas linhas com mulheres grávidas,\n",
        "# essa coluna se torna uma constante, com isso, não necessita deste atributo\n",
        "# e será removido mais a frente.\n",
        "covid_df.PREGNANT.value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlF5JmB1_9gs"
      },
      "source": [
        "### Coluna INTUBED\n",
        "Para casos em que INTUBED é nulo e o paciente hospitalizado, receberá o valor NaN. De outra forma, recebe 2 [Não], quando o paciente foi para casa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VctLlemQtz7r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "INTUBED\n",
              "97.0    845277\n",
              "2.0     158768\n",
              "1.0      33609\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [2] hospitalizado\n",
        "filter_intubed_1 = (covid_df[\"INTUBED\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 2)\n",
        "covid_df.loc[filter_intubed_1, \"INTUBED\"] = np.nan\n",
        "covid_df[\"INTUBED\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvzUomVlW3GD",
        "outputId": "3344cba5-1374-4465-8745-a7ee55027f56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "INTUBED\n",
              "2.0    1004045\n",
              "1.0      33609\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [1] para casa\n",
        "filter_intubed_2 = (covid_df[\"INTUBED\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 1)\n",
        "covid_df.loc[filter_intubed_2, \"INTUBED\"] = 2\n",
        "covid_df[\"INTUBED\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEa71c636bhX"
      },
      "source": [
        "### Coluna ICU\n",
        "Se ICU nulo e foi hospitalizado, então recebe NaN. Se não, recebe 2 [Não]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae76vj7v6e18",
        "outputId": "d55adbfa-c1b2-4fc7-b1c1-133cb0a9db22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ICU\n",
              "97.0    845277\n",
              "2.0     175386\n",
              "1.0      16830\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [2] hospitalizado\n",
        "filter_icu_1 = (covid_df[\"ICU\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 2)\n",
        "covid_df.loc[filter_icu_1, \"ICU\"] = np.nan\n",
        "covid_df[\"ICU\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9ylD_Ae932rt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ICU\n",
              "2.0    1020663\n",
              "1.0      16830\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [1] para casa\n",
        "filter_icu_2 = (covid_df[\"ICU\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 1)\n",
        "covid_df.loc[filter_icu_2, \"ICU\"] = 2\n",
        "covid_df[\"ICU\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX-oviAT5nZe",
        "outputId": "92d742c1-2453-4d89-cb8f-3af617dd4426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "USMER                      0\n",
              "MEDICAL_UNIT               0\n",
              "SEX                        0\n",
              "PATIENT_TYPE               0\n",
              "INTUBED                 7167\n",
              "PNEUMONIA                  0\n",
              "AGE                        0\n",
              "PREGNANT                   0\n",
              "DIABETES                   0\n",
              "COPD                       0\n",
              "ASTHMA                     0\n",
              "INMSUPR                    0\n",
              "HIPERTENSION               0\n",
              "OTHER_DISEASE              0\n",
              "CARDIOVASCULAR             0\n",
              "OBESITY                    0\n",
              "RENAL_CHRONIC              0\n",
              "TOBACCO                    0\n",
              "CLASIFFICATION_FINAL       0\n",
              "ICU                     7328\n",
              "PASSED                     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QksaAzLyXhSn"
      },
      "source": [
        "### Colunas NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ywAVj9KuvI13"
      },
      "outputs": [],
      "source": [
        "def verify_num_cols(df):\n",
        "    # Média ordenada e colunas com valor vazio\n",
        "    mean_na = df.isna().mean().sort_values(ascending=False)\n",
        "\n",
        "    # Cria DF de colunas nulas\n",
        "    df_na = pd.DataFrame({\"percentual\": mean_na})\n",
        "\n",
        "    return df_na\n",
        "\n",
        "def remove_nan_cols_above_limit(df, cols_to_ignore, limit=0.30):\n",
        "    # Obtém colunas nulas e seu percentual\n",
        "    df_na = verify_num_cols(df)\n",
        "\n",
        "    # Ignora colunas\n",
        "    df_na.drop(cols_to_ignore, inplace=True)\n",
        "\n",
        "    # Filtra colunas pelo limite\n",
        "    df_na_above_limit = df_na[df_na.percentual >= limit]\n",
        "\n",
        "    # Obtém as colunas a serem dropadas\n",
        "    columns_to_drop = df_na_above_limit.index\n",
        "\n",
        "    # Dropa colunas\n",
        "    df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "    return df, df_na_above_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "2A0YA0QX-xOV",
        "outputId": "dd55e0e8-5c0b-4365-e756-9d3575d193ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>percentual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [percentual]\n",
              "Index: []"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove colunas nulas acima do limite de 5%\n",
        "# Coluna considera importante para ser removida\n",
        "cols_to_ignore = [\"ICU\", \"INTUBED\"]\n",
        "_, df_na = remove_nan_cols_above_limit(covid_df, cols_to_ignore, limit=0.05)\n",
        "\n",
        "# Colunas removidas\n",
        "df_na"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAEhuFtlhJ7y",
        "outputId": "fefa1689-6f7e-47ec-a96e-da452154707f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1044821, 21)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwOm5PZDjTKS",
        "outputId": "70fca99c-c95e-4080-b5db-1904f921736a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "USMER                      0\n",
              "MEDICAL_UNIT               0\n",
              "SEX                        0\n",
              "PATIENT_TYPE               0\n",
              "INTUBED                 7167\n",
              "PNEUMONIA                  0\n",
              "AGE                        0\n",
              "PREGNANT                   0\n",
              "DIABETES                   0\n",
              "COPD                       0\n",
              "ASTHMA                     0\n",
              "INMSUPR                    0\n",
              "HIPERTENSION               0\n",
              "OTHER_DISEASE              0\n",
              "CARDIOVASCULAR             0\n",
              "OBESITY                    0\n",
              "RENAL_CHRONIC              0\n",
              "TOBACCO                    0\n",
              "CLASIFFICATION_FINAL       0\n",
              "ICU                     7328\n",
              "PASSED                     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s4k3YYYEM-k"
      },
      "source": [
        "### Removendo colunas desnecessárias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofIJYDIGZx98"
      },
      "source": [
        "* PREGNANT - Coluna constante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVg9zX-EZqep",
        "outputId": "67363131-9fc5-4e3e-bd3b-ffed83c1ddb4"
      },
      "outputs": [],
      "source": [
        "# Removendo colunas\n",
        "covid_df.drop(columns=[\"PREGNANT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove linhas com alguma coluna nula\n",
        "covid_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VRw-t6XKEQ8J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USMER :  0\n",
            "MEDICAL_UNIT :  0\n",
            "SEX :  0\n",
            "PATIENT_TYPE :  0\n",
            "INTUBED :  0\n",
            "PNEUMONIA :  10652\n",
            "AGE :  327\n",
            "DIABETES :  3133\n",
            "COPD :  2797\n",
            "ASTHMA :  2770\n",
            "INMSUPR :  3159\n",
            "HIPERTENSION :  2906\n",
            "OTHER_DISEASE :  4759\n",
            "CARDIOVASCULAR :  2865\n",
            "OBESITY :  2838\n",
            "RENAL_CHRONIC :  2804\n",
            "TOBACCO :  3018\n",
            "CLASIFFICATION_FINAL :  0\n",
            "ICU :  0\n",
            "PASSED :  0\n"
          ]
        }
      ],
      "source": [
        "# Nessa base valores como 97, 98 e 99 são nulos\n",
        "def check_columns():\n",
        "  for i in covid_df.columns:\n",
        "    temp_df = covid_df[(covid_df[i] == 99) | (covid_df[i] == 97) | (covid_df[i] == 98)]\n",
        "    print(i + \" : \",temp_df[i].count())\n",
        "\n",
        "check_columns()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USMER :  0\n",
            "MEDICAL_UNIT :  0\n",
            "SEX :  0\n",
            "PATIENT_TYPE :  0\n",
            "INTUBED :  0\n",
            "PNEUMONIA :  0\n",
            "AGE :  321\n",
            "DIABETES :  0\n",
            "COPD :  0\n",
            "ASTHMA :  0\n",
            "INMSUPR :  0\n",
            "HIPERTENSION :  0\n",
            "OTHER_DISEASE :  0\n",
            "CARDIOVASCULAR :  0\n",
            "OBESITY :  0\n",
            "RENAL_CHRONIC :  0\n",
            "TOBACCO :  0\n",
            "CLASIFFICATION_FINAL :  0\n",
            "ICU :  0\n",
            "PASSED :  0\n"
          ]
        }
      ],
      "source": [
        "columns_filter = ['PNEUMONIA', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR', 'HIPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO']\n",
        "for c in columns_filter:\n",
        "    covid_df = covid_df[(covid_df[c] == 1) | (covid_df[c] == 2)]\n",
        "\n",
        "check_columns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eq81Uvc2ht-"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIgxwNSL3YPh"
      },
      "source": [
        "## Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HeDjGzmV9T2j"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RkPNWEOgabFU"
      },
      "outputs": [],
      "source": [
        "covid_df[\"CLASIFFICATION_FINAL\"] = label_encoder.fit_transform(covid_df[\"CLASIFFICATION_FINAL\"])\n",
        "covid_df[\"USMER\"] = label_encoder.fit_transform(covid_df[\"USMER\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIYjQrQr3cIA"
      },
      "source": [
        "## One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "keuhwEdd3cXk"
      },
      "outputs": [],
      "source": [
        "# Define colunas a serem ignoradas\n",
        "ignore_columns = [\"CLASIFFICATION_FINAL\", \"AGE\", \"PASSED\", \"USMER\", ]\n",
        "onehot_encoder_cols = [col for col in covid_df.columns.tolist() if col not in ignore_columns]\n",
        "\n",
        "# Instancia o OneHotEnconder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG5C-muicP3h",
        "outputId": "8a5fb345-fda7-408c-e03f-1db06193245a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1019666, 43)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Realiza o fit-transform\n",
        "one_hot_result = one_hot_encoder.fit_transform(covid_df[onehot_encoder_cols])\n",
        "\n",
        "# Obtem os nomes das colunas\n",
        "one_hot_col_result = one_hot_encoder.get_feature_names_out(onehot_encoder_cols)\n",
        "\n",
        "# Armazena em um novo DF\n",
        "one_hot_col_df = pd.DataFrame(one_hot_result, columns=one_hot_col_result, index=covid_df.index)\n",
        "one_hot_col_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz5PNxsciru5",
        "outputId": "a80d540b-bc0a-4058-9f5c-de106f9a77a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['MEDICAL_UNIT_1', 'MEDICAL_UNIT_2', 'MEDICAL_UNIT_3',\n",
              "       'MEDICAL_UNIT_4', 'MEDICAL_UNIT_5', 'MEDICAL_UNIT_6',\n",
              "       'MEDICAL_UNIT_7', 'MEDICAL_UNIT_8', 'MEDICAL_UNIT_9',\n",
              "       'MEDICAL_UNIT_10', 'MEDICAL_UNIT_11', 'MEDICAL_UNIT_12',\n",
              "       'MEDICAL_UNIT_13', 'SEX_1', 'SEX_2', 'PATIENT_TYPE_1',\n",
              "       'PATIENT_TYPE_2', 'INTUBED_1.0', 'INTUBED_2.0', 'PNEUMONIA_1',\n",
              "       'PNEUMONIA_2', 'DIABETES_1', 'DIABETES_2', 'COPD_1', 'COPD_2',\n",
              "       'ASTHMA_1', 'ASTHMA_2', 'INMSUPR_1', 'INMSUPR_2', 'HIPERTENSION_1',\n",
              "       'HIPERTENSION_2', 'OTHER_DISEASE_1', 'OTHER_DISEASE_2',\n",
              "       'CARDIOVASCULAR_1', 'CARDIOVASCULAR_2', 'OBESITY_1', 'OBESITY_2',\n",
              "       'RENAL_CHRONIC_1', 'RENAL_CHRONIC_2', 'TOBACCO_1', 'TOBACCO_2',\n",
              "       'ICU_1.0', 'ICU_2.0'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot_col_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1019666, 47)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dropa colunas antigas e adiciona as novas\n",
        "covid_df = covid_df.drop(columns=onehot_encoder_cols).join(one_hot_col_df)\n",
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar memoria\n",
        "del one_hot_col_df\n",
        "del one_hot_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Estratificando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Nesse caso, é necessário reduzir de forma estratificada os dados, já que essa base\n",
        "possui aproximadamente 73 mil óbitos (classe minoritária). Ou seja,\n",
        "aplicar o RUS faria com que a base tivesse cerca de 73 mil óbitos e 73 mil sobreviventes\n",
        "o que gera mais de 140 mil dados para serem passados pela etapa de ajuste de hiperparâmetros,\n",
        "fazendo com que seja lento a busca pelos hiperparâmetros.\n",
        "* Com isso, reduzimos os dados em 15%. Aplicando o RUS cada classe é representada por\n",
        "aproximadamente 11 mil dados (total de 22 mil).\n",
        "* Cada paciente é um nó, logo a quantidade de aresta possíveis é n(n - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agrupa por PASSED e aplica o SAMPLE em cada grupo\n",
        "covid_df = covid_df.groupby(\"PASSED\", group_keys=False).apply(lambda g: g.sample(frac=0.15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzQLCJ66IORk"
      },
      "source": [
        "# Balanceando Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ersY3p4_IRK2"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(sampling_strategy='majority')\n",
        "X,y = rus.fit_resample(covid_df.drop(columns=[\"PASSED\"]), covid_df.PASSED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PASSED\n",
              "0    10996\n",
              "1    10996\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCDv3sReXpnf"
      },
      "source": [
        "# Transformando Dataset em estrutura para grafo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqJ9NGMG9WIs"
      },
      "source": [
        "## Determinado propriedades\n",
        "* Nodes -> Pessoas (cada linha da tabela)\n",
        "* Edges -> Similaridade das doenças de cada pessoa\n",
        "* Nodes features -> Comorbidades, etc.\n",
        "* Labels -> Se a pessoa pode morrer por covid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqJA_nxr9WIs"
      },
      "source": [
        "## Extraindo Node Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD6E-p4k9WIs",
        "outputId": "dd72ee25-2520-45cf-9f4e-d93a899f7142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['USMER', 'AGE', 'CLASIFFICATION_FINAL', 'MEDICAL_UNIT_1',\n",
              "       'MEDICAL_UNIT_2', 'MEDICAL_UNIT_3', 'MEDICAL_UNIT_4', 'MEDICAL_UNIT_5',\n",
              "       'MEDICAL_UNIT_6', 'MEDICAL_UNIT_7', 'MEDICAL_UNIT_8', 'MEDICAL_UNIT_9',\n",
              "       'MEDICAL_UNIT_10', 'MEDICAL_UNIT_11', 'MEDICAL_UNIT_12',\n",
              "       'MEDICAL_UNIT_13', 'SEX_1', 'SEX_2', 'PATIENT_TYPE_1', 'PATIENT_TYPE_2',\n",
              "       'INTUBED_1.0', 'INTUBED_2.0', 'PNEUMONIA_1', 'PNEUMONIA_2',\n",
              "       'DIABETES_1', 'DIABETES_2', 'COPD_1', 'COPD_2', 'ASTHMA_1', 'ASTHMA_2',\n",
              "       'INMSUPR_1', 'INMSUPR_2', 'HIPERTENSION_1', 'HIPERTENSION_2',\n",
              "       'OTHER_DISEASE_1', 'OTHER_DISEASE_2', 'CARDIOVASCULAR_1',\n",
              "       'CARDIOVASCULAR_2', 'OBESITY_1', 'OBESITY_2', 'RENAL_CHRONIC_1',\n",
              "       'RENAL_CHRONIC_2', 'TOBACCO_1', 'TOBACCO_2', 'ICU_1.0', 'ICU_2.0'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "sj4v61YkkbEA"
      },
      "outputs": [],
      "source": [
        "# Reseta o index\n",
        "covid_df = covid_df.reset_index(drop=True)\n",
        "X = X.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "04pg-dG-9WIt"
      },
      "outputs": [],
      "source": [
        "personal_info = ['SEX_1', 'SEX_2', 'AGE']\n",
        "\n",
        "clinicians = ['USMER', 'PATIENT_TYPE_1', 'PATIENT_TYPE_2', 'CLASIFFICATION_FINAL', \n",
        "              'ICU_1.0', 'ICU_2.0', 'INTUBED_1.0', 'INTUBED_2.0', 'MEDICAL_UNIT_1',\n",
        "       'MEDICAL_UNIT_2', 'MEDICAL_UNIT_3', 'MEDICAL_UNIT_4', 'MEDICAL_UNIT_5',\n",
        "       'MEDICAL_UNIT_6', 'MEDICAL_UNIT_7', 'MEDICAL_UNIT_8', 'MEDICAL_UNIT_9',\n",
        "       'MEDICAL_UNIT_10', 'MEDICAL_UNIT_11', 'MEDICAL_UNIT_12',\n",
        "       'MEDICAL_UNIT_13']\n",
        "\n",
        "comorbities = ['PNEUMONIA_1', 'PNEUMONIA_2', 'DIABETES_1', 'DIABETES_2', 'COPD_1', 'COPD_2', 'ASTHMA_1', 'ASTHMA_2',\n",
        "       'INMSUPR_1', 'INMSUPR_2', 'HIPERTENSION_1', 'HIPERTENSION_2',\n",
        "       'OTHER_DISEASE_1', 'OTHER_DISEASE_2', 'CARDIOVASCULAR_1',\n",
        "       'CARDIOVASCULAR_2', 'OBESITY_1', 'OBESITY_2', 'RENAL_CHRONIC_1',\n",
        "       'RENAL_CHRONIC_2', 'TOBACCO_1', 'TOBACCO_2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xW8FIQ9_m9j",
        "outputId": "e11d6f95-b74b-48e7-f76f-8b5c1946f761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.,  1., 26., ...,  0.,  1.,  0.],\n",
              "       [ 0.,  1., 23., ...,  0.,  1.,  0.],\n",
              "       [ 1.,  0., 35., ...,  0.,  1.,  0.],\n",
              "       ...,\n",
              "       [ 1.,  0., 58., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  1., 73., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  1., 72., ...,  0.,  0.,  0.]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = personal_info + comorbities + clinicians\n",
        "\n",
        "all_features = X[features].to_numpy()\n",
        "X.drop(columns=features, inplace=True)\n",
        "all_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORV6602Yaj64"
      },
      "source": [
        "## Definindo similaridade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "c7FqYFmsan9E"
      },
      "outputs": [],
      "source": [
        "# Calcula a similaridade do cosseno para os pacientes\n",
        "similarity = cosine_similarity(all_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "o2C5rR6yi-lT"
      },
      "outputs": [],
      "source": [
        "# Defini um limiar para existir uma relação entre os pacientes\n",
        "threshold = 0.999\n",
        "\n",
        "# Cria a lista de adjacencia\n",
        "adjacency_list = [[],[]]\n",
        "\n",
        "# O resultado de similarity, é uma matriz de paciente x pacientes\n",
        "# Onde cada elemento é o cosseno da similaridade\n",
        "# Assim, percorremos paciente x parciente\n",
        "for pac_i in range(len(similarity)):\n",
        "    for pac_j in range(pac_i + 1, len(similarity[pac_i])):\n",
        "        value = similarity[pac_i][pac_j]\n",
        "\n",
        "        # True, Se o paciente não for si mesmo (i!=j) e\n",
        "        #o cosseno da similiaridade for maior que o limiar\n",
        "\n",
        "        if(pac_i != pac_j and value >= threshold):\n",
        "            # Adiciona a->b e b->a\n",
        "            adjacency_list[0].append(pac_i)\n",
        "            adjacency_list[1].append(pac_j)\n",
        "\n",
        "            adjacency_list[0].append(pac_j)\n",
        "            adjacency_list[1].append(pac_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFFnhktMH9Lw",
        "outputId": "8681a404-a61b-42a7-87c2-4bfec1ee6b61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29205418"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(adjacency_list[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roqyBZCVvnEk"
      },
      "source": [
        "## Usando Pyg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Kc599nZczHCv"
      },
      "outputs": [],
      "source": [
        "# Define características e alvo\n",
        "X_features = torch.from_numpy(all_features).float()\n",
        "y_target = torch.from_numpy(y.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qdPLQrpZkOA",
        "outputId": "5d81828b-0fe6-4b2b-d837-ec814e91e5ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1., 26.,  ...,  0.,  1.,  0.],\n",
              "        [ 0.,  1., 23.,  ...,  0.,  1.,  0.],\n",
              "        [ 1.,  0., 35.,  ...,  0.,  1.,  0.],\n",
              "        ...,\n",
              "        [ 1.,  0., 58.,  ...,  0.,  0.,  0.],\n",
              "        [ 0.,  1., 73.,  ...,  0.,  0.,  0.],\n",
              "        [ 0.,  1., 72.,  ...,  0.,  0.,  0.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transforma valores para np.double\n",
        "torch.from_numpy(all_features.astype(np.double))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "rPJiCJMfs53M"
      },
      "outputs": [],
      "source": [
        "# Cria objeto tensor\n",
        "edge_index = torch.tensor(adjacency_list, dtype=torch.long)\n",
        "\n",
        "# Remove nós isolados\n",
        "edge_index,_,_ = remove_isolated_nodes(edge_index)\n",
        "\n",
        "data = Data(x=X_features, edge_index=edge_index, y=y_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar memória\n",
        "del adjacency_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUfpmRndLU6f",
        "outputId": "325b2955-0a7c-4715-a71c-ffac0681b880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 21992\n",
            "Number of edges: 29205418\n",
            "Average node degree: 1328.00\n",
            "Has isolated nodes: True\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "def show_data_info(data):\n",
        "    print(f'Number of nodes: {data.num_nodes}')\n",
        "    print(f'Number of edges: {data.num_edges}')\n",
        "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "    print(f'Has self-loops: {data.has_self_loops()}')\n",
        "    print(f'Is undirected: {data.is_undirected()}')\n",
        "\n",
        "show_data_info(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "7ci1ZAi7V4hq"
      },
      "outputs": [],
      "source": [
        "# Obtendo maior componente\n",
        "transform = LargestConnectedComponents()\n",
        "data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYl4MmsAbmC9",
        "outputId": "449ae33f-4224-4eb7-db20-bca805ad30f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 20961\n",
            "Number of edges: 29204768\n",
            "Average node degree: 1393.29\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "show_data_info(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_uJIrY-MFbZ"
      },
      "source": [
        "## Split dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "SRkGklaMMH7K"
      },
      "outputs": [],
      "source": [
        "def split_in_masks(data, test=0.3):\n",
        "    # resetting data split\n",
        "    split = T.RandomNodeSplit(num_test=test)\n",
        "    return split(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVQV7LXpU2ez"
      },
      "source": [
        "## GAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funções Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score, precision_score, recall_score, confusion_matrix\n",
        "from datetime import datetime\n",
        "\n",
        "def computes_metrics(target_labels, pred_labels):\n",
        "    accuracy = accuracy_score(target_labels, pred_labels)\n",
        "    f1 = f1_score(target_labels, pred_labels)\n",
        "    roc_auc = roc_auc_score(target_labels, pred_labels)\n",
        "    recall = recall_score(target_labels, pred_labels)\n",
        "    precision = precision_score(target_labels, pred_labels)\n",
        "    \n",
        "    return accuracy, precision, recall, f1, roc_auc\n",
        "\n",
        "def get_df_results(size, csv_name):\n",
        "    # Busca Df já escrito, caso não enconte, instancia um novo\n",
        "    df_results = None\n",
        "    try:\n",
        "        df_results = pd.read_csv(csv_name, sep=\",\", index_col=0)\n",
        "    except FileNotFoundError:\n",
        "        df_results = pd.DataFrame(data=np.zeros(size))\n",
        "    \n",
        "    return df_results\n",
        "\n",
        "def save_metrics(size, resultado, run):\n",
        "    # Mudar o nome para cada grupo de rn_runs\n",
        "    csv_name = \"./results/gnn_mx_runs\"\n",
        "\n",
        "    # Obtem Df results    \n",
        "    df_results = get_df_results(size, csv_name)\n",
        "\n",
        "    # Escreve as métricas na coluna run respectiva\n",
        "    df_results.iloc[:, run] = list(resultado)\n",
        "    \n",
        "    # Escreve df modificado\n",
        "    df_results.to_csv(csv_name)\n",
        "        \n",
        "def print_metrics(pred_labels, target_labels, loss, metrics_results, epoch):\n",
        "    print(f\"Pred: {pred_labels.sum()}, Actual: {target_labels.sum()}\")\n",
        "    print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}')\n",
        "    print(metrics_results)\n",
        "    print(\"-----------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "0uiNN_sgUTQX"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GATConv\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(num_node_features, 20)\n",
        "        self.conv2 = GATConv(20, num_classes)\n",
        "        \n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "BsVRH4_pVJNR"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def predict(model, data, mask):\n",
        "    out = model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "    \n",
        "    pred_labels = pred[mask]\n",
        "    target_labels = data.y[mask]\n",
        "\n",
        "    return pred_labels, target_labels\n",
        "\n",
        "def train_epochs(model, data, optimizer, criterion, run, n_epochs=200, n_runs=10):\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "\n",
        "    splited_data = split_in_masks(data)\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train(model, splited_data, optimizer, criterion)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            pred_labels, target_labels = predict(model, splited_data, splited_data.test_mask)\n",
        "\n",
        "            metrics_results = computes_metrics(target_labels, pred_labels)\n",
        "            print_metrics(pred_labels, target_labels, loss, metrics_results, epoch)\n",
        "                \n",
        "    # Salva as métricas ao fim do treinamento de cada run\n",
        "    pred_labels, target_labels = predict(model, splited_data, splited_data.test_mask)\n",
        "    save_metrics((len(metrics), n_runs), metrics_results, run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "A7R7I-0WU5Ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred: 5, Actual: 3008\n",
            "Epoch: 010, Train Loss: 0.799\n",
            "(0.5208333333333334, 0.0, 0.0, 0.0, 0.4992378048780488)\n",
            "-----------------------------------------------\n",
            "Pred: 6148, Actual: 3008\n",
            "Epoch: 020, Train Loss: 0.689\n",
            "(0.494910941475827, 0.4863370201691607, 0.9940159574468085, 0.6531236347750109, 0.515605539699014)\n",
            "-----------------------------------------------\n",
            "Pred: 2798, Actual: 3008\n",
            "Epoch: 030, Train Loss: 0.579\n",
            "(0.8311068702290076, 0.8477483917083631, 0.788563829787234, 0.8170857733379263, 0.8293428905033731)\n",
            "-----------------------------------------------\n",
            "Pred: 2721, Actual: 3008\n",
            "Epoch: 040, Train Loss: 0.451\n",
            "(0.8366730279898219, 0.8640205806688718, 0.7815824468085106, 0.8207366032466399, 0.8343887843798651)\n",
            "-----------------------------------------------\n",
            "Pred: 3146, Actual: 3008\n",
            "Epoch: 050, Train Loss: 0.363\n",
            "(0.8651399491094147, 0.8432930705657978, 0.8819813829787234, 0.8622034449138771, 0.8658382524649716)\n",
            "-----------------------------------------------\n",
            "Pred: 3304, Actual: 3008\n",
            "Epoch: 060, Train Loss: 0.328\n",
            "(0.8708651399491094, 0.8323244552058111, 0.9142287234042553, 0.8713561470215463, 0.8726631421899325)\n",
            "-----------------------------------------------\n",
            "Pred: 3309, Actual: 3008\n",
            "Epoch: 070, Train Loss: 0.313\n",
            "(0.8802480916030534, 0.8407373828951344, 0.9248670212765957, 0.8807978470793099, 0.8820981447846393)\n",
            "-----------------------------------------------\n",
            "Pred: 3316, Actual: 3008\n",
            "Epoch: 080, Train Loss: 0.306\n",
            "(0.8832697201017812, 0.8428829915560917, 0.929188829787234, 0.8839342188488298, 0.8851736831863)\n",
            "-----------------------------------------------\n",
            "Pred: 3308, Actual: 3008\n",
            "Epoch: 090, Train Loss: 0.301\n",
            "(0.8848600508905853, 0.845223700120919, 0.9295212765957447, 0.8853704876504116, 0.8867118578100674)\n",
            "-----------------------------------------------\n",
            "Pred: 3324, Actual: 3008\n",
            "Epoch: 100, Train Loss: 0.299\n",
            "(0.8839058524173028, 0.8426594464500602, 0.9311835106382979, 0.8847125710675932, 0.8858661455630514)\n",
            "-----------------------------------------------\n",
            "Pred: 3317, Actual: 3008\n",
            "Epoch: 110, Train Loss: 0.297\n",
            "(0.8847010178117048, 0.8441362677117877, 0.9308510638297872, 0.8853754940711461, 0.8866145563051376)\n",
            "-----------------------------------------------\n",
            "Pred: 3312, Actual: 3008\n",
            "Epoch: 120, Train Loss: 0.296\n",
            "(0.8848600508905853, 0.8448067632850241, 0.930186170212766, 0.8854430379746835, 0.8867394265697977)\n",
            "-----------------------------------------------\n",
            "Pred: 3302, Actual: 3008\n",
            "Epoch: 130, Train Loss: 0.295\n",
            "(0.8858142493638677, 0.8467595396729255, 0.9295212765957447, 0.8862123613312202, 0.887626491956409)\n",
            "-----------------------------------------------\n",
            "Pred: 3296, Actual: 3008\n",
            "Epoch: 140, Train Loss: 0.294\n",
            "(0.8858142493638677, 0.8473907766990292, 0.9285239361702128, 0.8861040609137055, 0.8875851388168137)\n",
            "-----------------------------------------------\n",
            "Pred: 3291, Actual: 3008\n",
            "Epoch: 150, Train Loss: 0.293\n",
            "(0.8859732824427481, 0.8480704952901853, 0.9278590425531915, 0.8861724083187807, 0.8877100090814738)\n",
            "-----------------------------------------------\n",
            "Pred: 3283, Actual: 3008\n",
            "Epoch: 160, Train Loss: 0.292\n",
            "(0.886291348600509, 0.8492232713981115, 0.9268617021276596, 0.886345573040852, 0.8879735339906591)\n",
            "-----------------------------------------------\n",
            "Pred: 3297, Actual: 3008\n",
            "Epoch: 170, Train Loss: 0.292\n",
            "(0.886291348600509, 0.8477403700333637, 0.929188829787234, 0.8865979381443299, 0.8880700246497145)\n",
            "-----------------------------------------------\n",
            "Pred: 3265, Actual: 3008\n",
            "Epoch: 180, Train Loss: 0.291\n",
            "(0.8869274809160306, 0.851761102603369, 0.9245345744680851, 0.8866571018651362, 0.8884867994291644)\n",
            "-----------------------------------------------\n",
            "Pred: 3297, Actual: 3008\n",
            "Epoch: 190, Train Loss: 0.290\n",
            "(0.8866094147582697, 0.8480436760691538, 0.9295212765957447, 0.8869151467089611, 0.8883886870783602)\n",
            "-----------------------------------------------\n",
            "Pred: 3278, Actual: 3008\n",
            "Epoch: 200, Train Loss: 0.290\n",
            "(0.8874045801526718, 0.850823672971324, 0.9271941489361702, 0.887368755965638, 0.8890543915412558)\n",
            "-----------------------------------------------\n",
            "Pred: 6288, Actual: 3079\n",
            "Epoch: 010, Train Loss: 1.123\n",
            "(0.48966284987277353, 0.48966284987277353, 1.0, 0.6574143268922814, 0.5)\n",
            "-----------------------------------------------\n",
            "Pred: 45, Actual: 3079\n",
            "Epoch: 020, Train Loss: 0.745\n",
            "(0.5162213740458015, 0.9111111111111111, 0.013316011692107827, 0.026248399487836107, 0.5060347587285718)\n",
            "-----------------------------------------------\n",
            "Pred: 3558, Actual: 3079\n",
            "Epoch: 030, Train Loss: 0.584\n",
            "(0.8532124681933843, 0.8029792017987634, 0.9278986683988308, 0.8609311435889709, 0.8547252768606807)\n",
            "-----------------------------------------------\n",
            "Pred: 3411, Actual: 3079\n",
            "Epoch: 040, Train Loss: 0.500\n",
            "(0.8358778625954199, 0.8000586338317209, 0.8863267294576161, 0.8409861325115562, 0.8368997311981131)\n",
            "-----------------------------------------------\n",
            "Pred: 3166, Actual: 3079\n",
            "Epoch: 050, Train Loss: 0.437\n",
            "(0.8376272264631043, 0.8250157927984839, 0.8483273790191621, 0.8365092073658928, 0.8378439637383127)\n",
            "-----------------------------------------------\n",
            "Pred: 3184, Actual: 3079\n",
            "Epoch: 060, Train Loss: 0.381\n",
            "(0.8471692111959288, 0.8326005025125628, 0.8609938291653134, 0.8465591569535367, 0.8474492361781694)\n",
            "-----------------------------------------------\n",
            "Pred: 3186, Actual: 3079\n",
            "Epoch: 070, Train Loss: 0.349\n",
            "(0.8541666666666666, 0.8392969240426867, 0.8684637869438129, 0.8536312849162011, 0.8544562624342)\n",
            "-----------------------------------------------\n",
            "Pred: 3227, Actual: 3079\n",
            "Epoch: 080, Train Loss: 0.333\n",
            "(0.8622773536895675, 0.8428881313913852, 0.8834037025008119, 0.8626704725658103, 0.862705279109552)\n",
            "-----------------------------------------------\n",
            "Pred: 3300, Actual: 3079\n",
            "Epoch: 090, Train Loss: 0.322\n",
            "(0.8694338422391857, 0.8421212121212122, 0.9025657681065281, 0.8712964414485029, 0.870104947001223)\n",
            "-----------------------------------------------\n",
            "Pred: 3311, Actual: 3079\n",
            "Epoch: 100, Train Loss: 0.315\n",
            "(0.871501272264631, 0.8429477499244941, 0.9064631373822669, 0.8735524256651016, 0.8722094434184628)\n",
            "-----------------------------------------------\n",
            "Pred: 3336, Actual: 3079\n",
            "Epoch: 110, Train Loss: 0.310\n",
            "(0.874204834605598, 0.842925659472422, 0.91328353361481, 0.8766952455183163, 0.8749963944172523)\n",
            "-----------------------------------------------\n",
            "Pred: 3337, Actual: 3079\n",
            "Epoch: 120, Train Loss: 0.305\n",
            "(0.8756361323155216, 0.8441714114474078, 0.9149074374797012, 0.8781172069825437, 0.87643159346718)\n",
            "-----------------------------------------------\n",
            "Pred: 3357, Actual: 3079\n",
            "Epoch: 130, Train Loss: 0.300\n",
            "(0.875, 0.8415251712838844, 0.9175056836635271, 0.8778744561839652, 0.8758609752066469)\n",
            "-----------------------------------------------\n",
            "Pred: 3374, Actual: 3079\n",
            "Epoch: 140, Train Loss: 0.296\n",
            "(0.8773854961832062, 0.8420272673384707, 0.922702176031179, 0.8805206880520688, 0.8783034096111022)\n",
            "-----------------------------------------------\n",
            "Pred: 3374, Actual: 3079\n",
            "Epoch: 150, Train Loss: 0.293\n",
            "(0.8789758269720102, 0.8435091879075282, 0.9243260798960702, 0.8820703548737022, 0.8798944204404004)\n",
            "-----------------------------------------------\n",
            "Pred: 3377, Actual: 3079\n",
            "Epoch: 160, Train Loss: 0.291\n",
            "(0.8797709923664122, 0.8439443292863489, 0.9256252029879831, 0.8828996282527881, 0.8806997937657273)\n",
            "-----------------------------------------------\n",
            "Pred: 3376, Actual: 3079\n",
            "Epoch: 170, Train Loss: 0.290\n",
            "(0.8802480916030534, 0.8444905213270142, 0.9259499837609614, 0.8833462432223083, 0.8811738077109574)\n",
            "-----------------------------------------------\n",
            "Pred: 3376, Actual: 3079\n",
            "Epoch: 180, Train Loss: 0.288\n",
            "(0.8812022900763359, 0.8453791469194313, 0.926924326079896, 0.8842757552285051, 0.8821284142085364)\n",
            "-----------------------------------------------\n",
            "Pred: 3371, Actual: 3079\n",
            "Epoch: 190, Train Loss: 0.287\n",
            "(0.8819974554707379, 0.846633046573717, 0.926924326079896, 0.8849612403100774, 0.882907473105389)\n",
            "-----------------------------------------------\n",
            "Pred: 3381, Actual: 3079\n",
            "Epoch: 200, Train Loss: 0.286\n",
            "(0.8813613231552163, 0.8450162673765158, 0.9278986683988308, 0.8845201238390094, 0.8823039618092627)\n",
            "-----------------------------------------------\n",
            "Pred: 6249, Actual: 3091\n",
            "Epoch: 010, Train Loss: 1.861\n",
            "(0.4977735368956743, 0.49463914226276207, 1.0, 0.6618843683083512, 0.5060994682514858)\n",
            "-----------------------------------------------\n",
            "Pred: 6094, Actual: 3091\n",
            "Epoch: 020, Train Loss: 0.607\n",
            "(0.5217875318066157, 0.5068920249425665, 0.9993529602070528, 0.6726183995645073, 0.5297046314954563)\n",
            "-----------------------------------------------\n",
            "Pred: 3250, Actual: 3091\n",
            "Epoch: 030, Train Loss: 0.412\n",
            "(0.8643447837150128, 0.8443076923076923, 0.8877385959236493, 0.8654786311307364, 0.8647326073143426)\n",
            "-----------------------------------------------\n",
            "Pred: 2997, Actual: 3091\n",
            "Epoch: 040, Train Loss: 0.350\n",
            "(0.8482824427480916, 0.8565231898565232, 0.8304755742478163, 0.8432982917214192, 0.8479872397357316)\n",
            "-----------------------------------------------\n",
            "Pred: 3543, Actual: 3091\n",
            "Epoch: 050, Train Loss: 0.330\n",
            "(0.8718193384223919, 0.8224668360146768, 0.9427369783241669, 0.8785046728971962, 0.8729950140291463)\n",
            "-----------------------------------------------\n",
            "Pred: 3507, Actual: 3091\n",
            "Epoch: 060, Train Loss: 0.311\n",
            "(0.8705470737913485, 0.8246364414029085, 0.935619540601747, 0.876629281600485, 0.8716258478735979)\n",
            "-----------------------------------------------\n",
            "Pred: 3392, Actual: 3091\n",
            "Epoch: 070, Train Loss: 0.306\n",
            "(0.8703880407124682, 0.8354952830188679, 0.9168553866062763, 0.8742865957118618, 0.8711583783203417)\n",
            "-----------------------------------------------\n",
            "Pred: 3380, Actual: 3091\n",
            "Epoch: 080, Train Loss: 0.303\n",
            "(0.8694338422391857, 0.8357988165680473, 0.9139437075380136, 0.8731262556019163, 0.8701717286517094)\n",
            "-----------------------------------------------\n",
            "Pred: 3405, Actual: 3091\n",
            "Epoch: 090, Train Loss: 0.301\n",
            "(0.8705470737913485, 0.8343612334801762, 0.9191200258815917, 0.874692118226601, 0.8713523182270017)\n",
            "-----------------------------------------------\n",
            "Pred: 3417, Actual: 3091\n",
            "Epoch: 100, Train Loss: 0.301\n",
            "(0.8711832061068703, 0.8337723148961077, 0.9217081850533808, 0.8755377996312232, 0.8720208113255644)\n",
            "-----------------------------------------------\n",
            "Pred: 3419, Actual: 3091\n",
            "Epoch: 110, Train Loss: 0.300\n",
            "(0.8711832061068703, 0.8335770693185142, 0.9220317049498544, 0.8755760368663595, 0.8720261746519682)\n",
            "-----------------------------------------------\n",
            "Pred: 3418, Actual: 3091\n",
            "Epoch: 120, Train Loss: 0.300\n",
            "(0.870706106870229, 0.8332358104154476, 0.9213846651569072, 0.8750960208941465, 0.8715462581336616)\n",
            "-----------------------------------------------\n",
            "Pred: 3418, Actual: 3091\n",
            "Epoch: 130, Train Loss: 0.300\n",
            "(0.870706106870229, 0.8332358104154476, 0.9213846651569072, 0.8750960208941465, 0.8715462581336616)\n",
            "-----------------------------------------------\n",
            "Pred: 3421, Actual: 3091\n",
            "Epoch: 140, Train Loss: 0.300\n",
            "(0.8711832061068703, 0.8333820520315697, 0.922355224846328, 0.8756142506142506, 0.872031537978372)\n",
            "-----------------------------------------------\n",
            "Pred: 3423, Actual: 3091\n",
            "Epoch: 150, Train Loss: 0.299\n",
            "(0.8711832061068703, 0.8331872626351154, 0.9226787447428016, 0.8756524408965305, 0.8720369013047757)\n",
            "-----------------------------------------------\n",
            "Pred: 3425, Actual: 3091\n",
            "Epoch: 160, Train Loss: 0.299\n",
            "(0.8711832061068703, 0.832992700729927, 0.9230022646392753, 0.8756906077348067, 0.8720422646311797)\n",
            "-----------------------------------------------\n",
            "Pred: 3424, Actual: 3091\n",
            "Epoch: 170, Train Loss: 0.299\n",
            "(0.8710241730279898, 0.8329439252336449, 0.9226787447428016, 0.8755180353031466, 0.8718805046829429)\n",
            "-----------------------------------------------\n",
            "Pred: 3426, Actual: 3091\n",
            "Epoch: 180, Train Loss: 0.299\n",
            "(0.870706106870229, 0.8324576765907764, 0.9226787447428016, 0.8752493478594444, 0.871567711439277)\n",
            "-----------------------------------------------\n",
            "Pred: 3428, Actual: 3091\n",
            "Epoch: 190, Train Loss: 0.299\n",
            "(0.8710241730279898, 0.8325554259043174, 0.923325784535749, 0.8755944163215218, 0.8718912313357506)\n",
            "-----------------------------------------------\n",
            "Pred: 3431, Actual: 3091\n",
            "Epoch: 200, Train Loss: 0.299\n",
            "(0.8708651399491094, 0.8321189157679977, 0.9236493044322226, 0.8754983134007973, 0.8717401980403215)\n",
            "-----------------------------------------------\n",
            "Pred: 218, Actual: 3056\n",
            "Epoch: 010, Train Loss: 0.738\n",
            "(0.5009541984732825, 0.3119266055045872, 0.02225130890052356, 0.041539401343921804, 0.48792020890570736)\n",
            "-----------------------------------------------\n",
            "Pred: 3538, Actual: 3056\n",
            "Epoch: 020, Train Loss: 0.587\n",
            "(0.830470737913486, 0.781232334652346, 0.9044502617801047, 0.8383378829238702, 0.8324850318801513)\n",
            "-----------------------------------------------\n",
            "Pred: 2996, Actual: 3056\n",
            "Epoch: 030, Train Loss: 0.468\n",
            "(0.8209287531806616, 0.8220961281708945, 0.805955497382199, 0.8139458030403173, 0.8205210655227826)\n",
            "-----------------------------------------------\n",
            "Pred: 2806, Actual: 3056\n",
            "Epoch: 040, Train Loss: 0.420\n",
            "(0.8215648854961832, 0.8446186742694227, 0.775523560209424, 0.8085977482088025, 0.820311285055207)\n",
            "-----------------------------------------------\n",
            "Pred: 3034, Actual: 3056\n",
            "Epoch: 050, Train Loss: 0.372\n",
            "(0.8466921119592875, 0.8447593935398814, 0.8386780104712042, 0.8417077175697866, 0.8464739062257011)\n",
            "-----------------------------------------------\n",
            "Pred: 3078, Actual: 3056\n",
            "Epoch: 060, Train Loss: 0.346\n",
            "(0.8610050890585241, 0.8544509421702404, 0.8606020942408377, 0.8575154874470166, 0.8609941164273496)\n",
            "-----------------------------------------------\n",
            "Pred: 3087, Actual: 3056\n",
            "Epoch: 070, Train Loss: 0.329\n",
            "(0.8668893129770993, 0.8594104308390023, 0.868128272251309, 0.863747354712681, 0.8669230470167436)\n",
            "-----------------------------------------------\n",
            "Pred: 3124, Actual: 3056\n",
            "Epoch: 080, Train Loss: 0.321\n",
            "(0.8695928753180662, 0.8578745198463509, 0.8769633507853403, 0.8673139158576052, 0.8697935565807889)\n",
            "-----------------------------------------------\n",
            "Pred: 3161, Actual: 3056\n",
            "Epoch: 090, Train Loss: 0.315\n",
            "(0.8732506361323156, 0.8573236317621006, 0.8867801047120419, 0.871803120476114, 0.8736190127520607)\n",
            "-----------------------------------------------\n",
            "Pred: 3180, Actual: 3056\n",
            "Epoch: 100, Train Loss: 0.311\n",
            "(0.8740458015267175, 0.8559748427672956, 0.8907068062827225, 0.8729955099422707, 0.8744994427453217)\n",
            "-----------------------------------------------\n",
            "Pred: 3185, Actual: 3056\n",
            "Epoch: 110, Train Loss: 0.307\n",
            "(0.8751590330788804, 0.8565149136577708, 0.8926701570680629, 0.8742188751802595, 0.8756358211082889)\n",
            "-----------------------------------------------\n",
            "Pred: 3197, Actual: 3056\n",
            "Epoch: 120, Train Loss: 0.305\n",
            "(0.8745229007633588, 0.8545511416953394, 0.893979057591623, 0.8738205661282584, 0.8750526476076926)\n",
            "-----------------------------------------------\n",
            "Pred: 3204, Actual: 3056\n",
            "Epoch: 130, Train Loss: 0.303\n",
            "(0.875, 0.8542446941323346, 0.8956151832460733, 0.87444089456869, 0.8755613044943238)\n",
            "-----------------------------------------------\n",
            "Pred: 3213, Actual: 3056\n",
            "Epoch: 140, Train Loss: 0.302\n",
            "(0.875795165394402, 0.8540305010893247, 0.8979057591623036, 0.875418727069708, 0.8763971865118448)\n",
            "-----------------------------------------------\n",
            "Pred: 3220, Actual: 3056\n",
            "Epoch: 150, Train Loss: 0.301\n",
            "(0.8769083969465649, 0.8543478260869565, 0.900196335078534, 0.8766730401529637, 0.87754247446996)\n",
            "-----------------------------------------------\n",
            "Pred: 3230, Actual: 3056\n",
            "Epoch: 160, Train Loss: 0.299\n",
            "(0.8781806615776081, 0.8544891640866873, 0.9031413612565445, 0.8781419026407891, 0.8788602845886684)\n",
            "-----------------------------------------------\n",
            "Pred: 3233, Actual: 3056\n",
            "Epoch: 170, Train Loss: 0.298\n",
            "(0.8783396946564885, 0.854314877822456, 0.9037958115183246, 0.87835903959294, 0.8790328067492612)\n",
            "-----------------------------------------------\n",
            "Pred: 3236, Actual: 3056\n",
            "Epoch: 180, Train Loss: 0.297\n",
            "(0.8791348600508906, 0.8547589616810878, 0.9051047120418848, 0.8792116973935156, 0.8798419599813384)\n",
            "-----------------------------------------------\n",
            "Pred: 3237, Actual: 3056\n",
            "Epoch: 190, Train Loss: 0.297\n",
            "(0.879293893129771, 0.8548038307074451, 0.9054319371727748, 0.8793897981884633, 0.8800055725467835)\n",
            "-----------------------------------------------\n",
            "Pred: 3242, Actual: 3056\n",
            "Epoch: 200, Train Loss: 0.296\n",
            "(0.8797709923664122, 0.8547193090684763, 0.9067408376963351, 0.8799618926643378, 0.8805053198382665)\n",
            "-----------------------------------------------\n",
            "Pred: 1927, Actual: 3058\n",
            "Epoch: 010, Train Loss: 0.710\n",
            "(0.6661895674300254, 0.7488323819408407, 0.47187704381948986, 0.5789368104312939, 0.6610159212905499)\n",
            "-----------------------------------------------\n",
            "Pred: 5183, Actual: 3058\n",
            "Epoch: 020, Train Loss: 0.624\n",
            "(0.6420165394402035, 0.5778506656376616, 0.9793982995421844, 0.7268535371920883, 0.6509994593686155)\n",
            "-----------------------------------------------\n",
            "Pred: 2877, Actual: 3058\n",
            "Epoch: 030, Train Loss: 0.521\n",
            "(0.8045483460559797, 0.8178658324643726, 0.7694571615434925, 0.7929233361415332, 0.8036140296881549)\n",
            "-----------------------------------------------\n",
            "Pred: 2751, Actual: 3058\n",
            "Epoch: 040, Train Loss: 0.459\n",
            "(0.8112277353689568, 0.8400581606688476, 0.7557226945716154, 0.7956619039421587, 0.8097498921774484)\n",
            "-----------------------------------------------\n",
            "Pred: 2957, Actual: 3058\n",
            "Epoch: 050, Train Loss: 0.401\n",
            "(0.8392175572519084, 0.8461278322624282, 0.8181818181818182, 0.831920199501247, 0.8386574725584014)\n",
            "-----------------------------------------------\n",
            "Pred: 3080, Actual: 3058\n",
            "Epoch: 060, Train Loss: 0.369\n",
            "(0.8581424936386769, 0.8516233766233766, 0.8577501635055592, 0.8546757901596612, 0.858132047697052)\n",
            "-----------------------------------------------\n",
            "Pred: 3086, Actual: 3058\n",
            "Epoch: 070, Train Loss: 0.347\n",
            "(0.8651399491094147, 0.8580686973428386, 0.8659254414650098, 0.8619791666666666, 0.8651608631473655)\n",
            "-----------------------------------------------\n",
            "Pred: 3199, Actual: 3058\n",
            "Epoch: 080, Train Loss: 0.335\n",
            "(0.8713422391857506, 0.851516098780869, 0.8907782864617397, 0.8707048106121144, 0.871859731466164)\n",
            "-----------------------------------------------\n",
            "Pred: 3178, Actual: 3058\n",
            "Epoch: 090, Train Loss: 0.328\n",
            "(0.8724554707379135, 0.854940213971051, 0.8884892086330936, 0.8713919178960874, 0.8728823752143796)\n",
            "-----------------------------------------------\n",
            "Pred: 3211, Actual: 3058\n",
            "Epoch: 100, Train Loss: 0.323\n",
            "(0.8748409669211196, 0.8536281532232949, 0.8963374754741661, 0.874461636624661, 0.8754133197804267)\n",
            "-----------------------------------------------\n",
            "Pred: 3226, Actual: 3058\n",
            "Epoch: 110, Train Loss: 0.319\n",
            "(0.8769083969465649, 0.8539987600743956, 0.9009156311314584, 0.8768300445576067, 0.877547598847463)\n",
            "-----------------------------------------------\n",
            "Pred: 3243, Actual: 3058\n",
            "Epoch: 120, Train Loss: 0.316\n",
            "(0.8783396946564885, 0.8535306814677768, 0.9051667756703728, 0.8785906998889065, 0.8790539760704805)\n",
            "-----------------------------------------------\n",
            "Pred: 3278, Actual: 3058\n",
            "Epoch: 130, Train Loss: 0.312\n",
            "(0.8781806615776081, 0.8496034167175107, 0.9107259646827992, 0.8791035353535352, 0.8790471928677153)\n",
            "-----------------------------------------------\n",
            "Pred: 3297, Actual: 3058\n",
            "Epoch: 140, Train Loss: 0.308\n",
            "(0.8786577608142494, 0.8480436760691538, 0.9143230869849575, 0.8799370574350905, 0.8796073639259152)\n",
            "-----------------------------------------------\n",
            "Pred: 3323, Actual: 3058\n",
            "Epoch: 150, Train Loss: 0.305\n",
            "(0.8821564885496184, 0.8486307553415589, 0.9221713538260301, 0.8838740009402914, 0.8832218998232316)\n",
            "-----------------------------------------------\n",
            "Pred: 3346, Actual: 3058\n",
            "Epoch: 160, Train Loss: 0.302\n",
            "(0.8845419847328244, 0.8484757919904363, 0.9283845650752126, 0.886633354153654, 0.8857093104013835)\n",
            "-----------------------------------------------\n",
            "Pred: 3358, Actual: 3058\n",
            "Epoch: 170, Train Loss: 0.300\n",
            "(0.8845419847328244, 0.8472304943418701, 0.9303466317854807, 0.886845386533666, 0.885761551186858)\n",
            "-----------------------------------------------\n",
            "Pred: 3358, Actual: 3058\n",
            "Epoch: 180, Train Loss: 0.299\n",
            "(0.885178117048346, 0.8478260869565217, 0.9310006540222368, 0.8874688279301747, 0.8863981598284558)\n",
            "-----------------------------------------------\n",
            "Pred: 3351, Actual: 3058\n",
            "Epoch: 190, Train Loss: 0.299\n",
            "(0.8859732824427481, 0.8492987168009549, 0.9306736429038587, 0.8881260727102511, 0.8871634468389262)\n",
            "-----------------------------------------------\n",
            "Pred: 3346, Actual: 3058\n",
            "Epoch: 200, Train Loss: 0.298\n",
            "(0.8858142493638677, 0.8496712492528392, 0.9296926095487247, 0.8878825733916302, 0.886982527684579)\n",
            "-----------------------------------------------\n",
            "Pred: 6270, Actual: 3084\n",
            "Epoch: 010, Train Loss: 0.743\n",
            "(0.4933206106870229, 0.49186602870813395, 1.0, 0.6593970493906349, 0.502808988764045)\n",
            "-----------------------------------------------\n",
            "Pred: 3465, Actual: 3084\n",
            "Epoch: 020, Train Loss: 0.639\n",
            "(0.7247137404580153, 0.6952380952380952, 0.7811284046692607, 0.7356848373797525, 0.7257701948439936)\n",
            "-----------------------------------------------\n",
            "Pred: 2908, Actual: 3084\n",
            "Epoch: 030, Train Loss: 0.524\n",
            "(0.75, 0.7599724896836314, 0.7166018158236057, 0.7376502002670228, 0.7493745658393934)\n",
            "-----------------------------------------------\n",
            "Pred: 2932, Actual: 3084\n",
            "Epoch: 040, Train Loss: 0.474\n",
            "(0.7643129770992366, 0.7731923601637107, 0.7350843060959793, 0.753656914893617, 0.7637656237096625)\n",
            "-----------------------------------------------\n",
            "Pred: 3425, Actual: 3084\n",
            "Epoch: 050, Train Loss: 0.417\n",
            "(0.8357188295165394, 0.7994160583941606, 0.8878080415045395, 0.8412966661545552, 0.8366942829245543)\n",
            "-----------------------------------------------\n",
            "Pred: 3487, Actual: 3084\n",
            "Epoch: 060, Train Loss: 0.379\n",
            "(0.8506679389312977, 0.807570977917981, 0.9130998702983139, 0.8570993760462638, 0.8518370762228148)\n",
            "-----------------------------------------------\n",
            "Pred: 3451, Actual: 3084\n",
            "Epoch: 070, Train Loss: 0.357\n",
            "(0.8633905852417303, 0.8223703274413213, 0.9202334630350194, 0.8685539403213466, 0.8644550586086458)\n",
            "-----------------------------------------------\n",
            "Pred: 3404, Actual: 3084\n",
            "Epoch: 080, Train Loss: 0.341\n",
            "(0.8746819338422391, 0.8372502937720329, 0.9241245136186771, 0.8785450061652281, 0.8756078248492886)\n",
            "-----------------------------------------------\n",
            "Pred: 3376, Actual: 3084\n",
            "Epoch: 090, Train Loss: 0.326\n",
            "(0.8813613231552163, 0.8462677725118484, 0.9263942931258107, 0.8845201238390094, 0.8822046371996094)\n",
            "-----------------------------------------------\n",
            "Pred: 3355, Actual: 3084\n",
            "Epoch: 100, Train Loss: 0.316\n",
            "(0.8859732824427481, 0.8527570789865871, 0.9276913099870299, 0.8886473054822177, 0.8867545189136148)\n",
            "-----------------------------------------------\n",
            "Pred: 3341, Actual: 3084\n",
            "Epoch: 110, Train Loss: 0.309\n",
            "(0.8881997455470738, 0.8563304399880275, 0.9276913099870299, 0.8905836575875486, 0.8889392879523165)\n",
            "-----------------------------------------------\n",
            "Pred: 3335, Actual: 3084\n",
            "Epoch: 120, Train Loss: 0.305\n",
            "(0.8894720101781171, 0.8581709145427286, 0.9280155642023347, 0.8917276834397881, 0.8901937995793197)\n",
            "-----------------------------------------------\n",
            "Pred: 3337, Actual: 3084\n",
            "Epoch: 130, Train Loss: 0.303\n",
            "(0.8913804071246819, 0.859754270302667, 0.9302853437094682, 0.8936302756579972, 0.8921089639895655)\n",
            "-----------------------------------------------\n",
            "Pred: 3342, Actual: 3084\n",
            "Epoch: 140, Train Loss: 0.301\n",
            "(0.8915394402035624, 0.8593656493117894, 0.9312581063553826, 0.893868658574541, 0.8922832354498511)\n",
            "-----------------------------------------------\n",
            "Pred: 3343, Actual: 3084\n",
            "Epoch: 150, Train Loss: 0.300\n",
            "(0.8926526717557252, 0.8603051151660186, 0.9325551232166018, 0.8949743270577253, 0.8933999086744682)\n",
            "-----------------------------------------------\n",
            "Pred: 3347, Actual: 3084\n",
            "Epoch: 160, Train Loss: 0.299\n",
            "(0.892970737913486, 0.8601732895129968, 0.9335278858625162, 0.8953506453117711, 0.8937302350660895)\n",
            "-----------------------------------------------\n",
            "Pred: 3346, Actual: 3084\n",
            "Epoch: 170, Train Loss: 0.299\n",
            "(0.8934478371501272, 0.8607292289300658, 0.933852140077821, 0.895800933125972, 0.8942044720364135)\n",
            "-----------------------------------------------\n",
            "Pred: 3348, Actual: 3084\n",
            "Epoch: 180, Train Loss: 0.298\n",
            "(0.8931297709923665, 0.8602150537634409, 0.933852140077821, 0.8955223880597015, 0.893892362173742)\n",
            "-----------------------------------------------\n",
            "Pred: 3350, Actual: 3084\n",
            "Epoch: 190, Train Loss: 0.298\n",
            "(0.8937659033078881, 0.8605970149253731, 0.9348249027237354, 0.8961765620142991, 0.8945347984280351)\n",
            "-----------------------------------------------\n",
            "Pred: 3351, Actual: 3084\n",
            "Epoch: 200, Train Loss: 0.297\n",
            "(0.8942430025445293, 0.8609370337212773, 0.935473411154345, 0.8966588966588966, 0.8950151075746756)\n",
            "-----------------------------------------------\n",
            "Pred: 4074, Actual: 3061\n",
            "Epoch: 010, Train Loss: 0.569\n",
            "(0.7698791348600509, 0.6980854197349042, 0.9291081345965371, 0.7971969166082692, 0.773974581707937)\n",
            "-----------------------------------------------\n",
            "Pred: 3021, Actual: 3061\n",
            "Epoch: 020, Train Loss: 0.508\n",
            "(0.7719465648854962, 0.7692816948030453, 0.7592290101274094, 0.7642222952975994, 0.7716194632291835)\n",
            "-----------------------------------------------\n",
            "Pred: 3238, Actual: 3061\n",
            "Epoch: 030, Train Loss: 0.459\n",
            "(0.8172709923664122, 0.7952439777640519, 0.8412283567461614, 0.8175900936656612, 0.8178871873597557)\n",
            "-----------------------------------------------\n",
            "Pred: 3405, Actual: 3061\n",
            "Epoch: 040, Train Loss: 0.404\n",
            "(0.8584605597964376, 0.8187958883994126, 0.910813459653708, 0.862356944014847, 0.8598071016892649)\n",
            "-----------------------------------------------\n",
            "Pred: 3395, Actual: 3061\n",
            "Epoch: 050, Train Loss: 0.370\n",
            "(0.8673664122137404, 0.8279823269513991, 0.9183273440052271, 0.870817843866171, 0.868677152015009)\n",
            "-----------------------------------------------\n",
            "Pred: 3343, Actual: 3061\n",
            "Epoch: 060, Train Loss: 0.347\n",
            "(0.8708651399491094, 0.836374513909662, 0.9134269846455406, 0.8732042473454091, 0.8719598511699967)\n",
            "-----------------------------------------------\n",
            "Pred: 3270, Actual: 3061\n",
            "Epoch: 070, Train Loss: 0.331\n",
            "(0.8767493638676844, 0.8495412844036697, 0.907546553413917, 0.8775864792291898, 0.8775414824708258)\n",
            "-----------------------------------------------\n",
            "Pred: 3271, Actual: 3061\n",
            "Epoch: 080, Train Loss: 0.319\n",
            "(0.8810432569974554, 0.8535616019565881, 0.9121202221496243, 0.8818698673404927, 0.881842571564431)\n",
            "-----------------------------------------------\n",
            "Pred: 3299, Actual: 3061\n",
            "Epoch: 090, Train Loss: 0.314\n",
            "(0.8826335877862596, 0.8520763867838739, 0.9183273440052271, 0.8839622641509434, 0.8835516484513275)\n",
            "-----------------------------------------------\n",
            "Pred: 3305, Actual: 3061\n",
            "Epoch: 100, Train Loss: 0.311\n",
            "(0.8832697201017812, 0.8520423600605144, 0.9199607971251225, 0.8846999685830977, 0.8842134323400636)\n",
            "-----------------------------------------------\n",
            "Pred: 3292, Actual: 3061\n",
            "Epoch: 110, Train Loss: 0.309\n",
            "(0.8840648854961832, 0.8541919805589308, 0.9186540346292061, 0.8852510624901622, 0.8849545351330104)\n",
            "-----------------------------------------------\n",
            "Pred: 3300, Actual: 3061\n",
            "Epoch: 120, Train Loss: 0.308\n",
            "(0.8847010178117048, 0.8539393939393939, 0.9206141783730807, 0.8860242100298695, 0.8856247216625242)\n",
            "-----------------------------------------------\n",
            "Pred: 3303, Actual: 3061\n",
            "Epoch: 130, Train Loss: 0.307\n",
            "(0.8848600508905853, 0.8537693006357856, 0.9212675596210389, 0.8862350722815839, 0.8857964696152917)\n",
            "-----------------------------------------------\n",
            "Pred: 3308, Actual: 3061\n",
            "Epoch: 140, Train Loss: 0.306\n",
            "(0.8847010178117048, 0.8530834340991535, 0.921920940868997, 0.8861673732140053, 0.8856583322256357)\n",
            "-----------------------------------------------\n",
            "Pred: 3306, Actual: 3061\n",
            "Epoch: 150, Train Loss: 0.305\n",
            "(0.8853371501272265, 0.8539019963702359, 0.9222476314929762, 0.8867598555049474, 0.8862865055512603)\n",
            "-----------------------------------------------\n",
            "Pred: 3307, Actual: 3061\n",
            "Epoch: 160, Train Loss: 0.305\n",
            "(0.8845419847328244, 0.8530390081644995, 0.921594250245018, 0.8859924623115577, 0.8854949869136461)\n",
            "-----------------------------------------------\n",
            "Pred: 3311, Actual: 3061\n",
            "Epoch: 170, Train Loss: 0.304\n",
            "(0.8848600508905853, 0.852914527333132, 0.9225743221169552, 0.8863779033270558, 0.8858300801784033)\n",
            "-----------------------------------------------\n",
            "Pred: 3316, Actual: 3061\n",
            "Epoch: 180, Train Loss: 0.303\n",
            "(0.8853371501272265, 0.8528347406513872, 0.9238810846128717, 0.8869374313940723, 0.8863285187551497)\n",
            "-----------------------------------------------\n",
            "Pred: 3322, Actual: 3061\n",
            "Epoch: 190, Train Loss: 0.303\n",
            "(0.8866094147582697, 0.8534015653220951, 0.9261679189807253, 0.8882970390098699, 0.8876268786102882)\n",
            "-----------------------------------------------\n",
            "Pred: 3323, Actual: 3061\n",
            "Epoch: 200, Train Loss: 0.302\n",
            "(0.8864503816793893, 0.8531447487210352, 0.9261679189807253, 0.888157894736842, 0.8874719359390766)\n",
            "-----------------------------------------------\n",
            "Pred: 234, Actual: 3107\n",
            "Epoch: 010, Train Loss: 0.858\n",
            "(0.4842557251908397, 0.2094017094017094, 0.015770840038622464, 0.02933253516911104, 0.47880651401491015)\n",
            "-----------------------------------------------\n",
            "Pred: 2500, Actual: 3107\n",
            "Epoch: 020, Train Loss: 0.681\n",
            "(0.7555661577608143, 0.814, 0.6549726424203411, 0.7258783663278044, 0.7543960980099191)\n",
            "-----------------------------------------------\n",
            "Pred: 3068, Actual: 3107\n",
            "Epoch: 030, Train Loss: 0.574\n",
            "(0.7635178117048346, 0.7640156453715776, 0.7544254908271645, 0.7591902834008096, 0.7634120538071691)\n",
            "-----------------------------------------------\n",
            "Pred: 2571, Actual: 3107\n",
            "Epoch: 040, Train Loss: 0.501\n",
            "(0.7792620865139949, 0.8343057176196033, 0.6903765690376569, 0.7555477280732653, 0.7782282090708561)\n",
            "-----------------------------------------------\n",
            "Pred: 2972, Actual: 3107\n",
            "Epoch: 050, Train Loss: 0.455\n",
            "(0.8191793893129771, 0.8314266487213997, 0.7953009333762472, 0.8129626583319626, 0.8189016455626913)\n",
            "-----------------------------------------------\n",
            "Pred: 2999, Actual: 3107\n",
            "Epoch: 060, Train Loss: 0.418\n",
            "(0.8396946564885496, 0.8499499833277759, 0.8204055358867074, 0.8349164755977727, 0.8394702938785942)\n",
            "-----------------------------------------------\n",
            "Pred: 2967, Actual: 3107\n",
            "Epoch: 070, Train Loss: 0.388\n",
            "(0.8501908396946565, 0.8648466464442197, 0.8258770518184744, 0.8449127428383273, 0.8499080323537516)\n",
            "-----------------------------------------------\n",
            "Pred: 3040, Actual: 3107\n",
            "Epoch: 080, Train Loss: 0.364\n",
            "(0.8640267175572519, 0.8703947368421052, 0.8516253620856131, 0.8609077598828696, 0.8638824704172171)\n",
            "-----------------------------------------------\n",
            "Pred: 3093, Actual: 3107\n",
            "Epoch: 090, Train Loss: 0.346\n",
            "(0.8740458015267175, 0.8742321370837375, 0.8702928870292888, 0.8722580645161291, 0.8740021492675523)\n",
            "-----------------------------------------------\n",
            "Pred: 3124, Actual: 3107\n",
            "Epoch: 100, Train Loss: 0.335\n",
            "(0.8773854961832062, 0.8738796414852753, 0.8786610878661087, 0.876263842079923, 0.8774003333074649)\n",
            "-----------------------------------------------\n",
            "Pred: 3143, Actual: 3107\n",
            "Epoch: 110, Train Loss: 0.328\n",
            "(0.8781806615776081, 0.8724148902322622, 0.8825233344061796, 0.87744, 0.8782311736476041)\n",
            "-----------------------------------------------\n",
            "Pred: 3175, Actual: 3107\n",
            "Epoch: 120, Train Loss: 0.323\n",
            "(0.8794529262086515, 0.8699212598425197, 0.8889604119729643, 0.8793377905125757, 0.8795635131226028)\n",
            "-----------------------------------------------\n",
            "Pred: 3196, Actual: 3107\n",
            "Epoch: 130, Train Loss: 0.320\n",
            "(0.8824745547073791, 0.8704630788485607, 0.895397489539749, 0.8827542440107885, 0.8826248686302958)\n",
            "-----------------------------------------------\n",
            "Pred: 3216, Actual: 3107\n",
            "Epoch: 140, Train Loss: 0.318\n",
            "(0.8837468193384224, 0.8694029850746269, 0.8999034438364982, 0.8843903210501344, 0.8839347461244738)\n",
            "-----------------------------------------------\n",
            "Pred: 3231, Actual: 3107\n",
            "Epoch: 150, Train Loss: 0.315\n",
            "(0.8858142493638677, 0.8696997833488084, 0.9044093981332475, 0.886715052066898, 0.8860305399971488)\n",
            "-----------------------------------------------\n",
            "Pred: 3239, Actual: 3107\n",
            "Epoch: 160, Train Loss: 0.314\n",
            "(0.8870865139949109, 0.8700216116085211, 0.9069842291599614, 0.8881184998424204, 0.8873179555105057)\n",
            "-----------------------------------------------\n",
            "Pred: 3249, Actual: 3107\n",
            "Epoch: 170, Train Loss: 0.312\n",
            "(0.8877226463104325, 0.8694983071714374, 0.909237206308336, 0.8889238514789175, 0.8879728942575946)\n",
            "-----------------------------------------------\n",
            "Pred: 3260, Actual: 3107\n",
            "Epoch: 180, Train Loss: 0.310\n",
            "(0.8881997455470738, 0.8687116564417178, 0.9114901834567106, 0.8895869326213286, 0.888470649728984)\n",
            "-----------------------------------------------\n",
            "Pred: 3274, Actual: 3107\n",
            "Epoch: 190, Train Loss: 0.309\n",
            "(0.8891539440203562, 0.8680513133781307, 0.914708722240103, 0.8907694718696129, 0.8894511860178823)\n",
            "-----------------------------------------------\n",
            "Pred: 3270, Actual: 3107\n",
            "Epoch: 200, Train Loss: 0.308\n",
            "(0.8894720101781171, 0.8688073394495412, 0.9143868683617637, 0.8910145836600282, 0.8897618089058111)\n",
            "-----------------------------------------------\n",
            "Pred: 35, Actual: 3049\n",
            "Epoch: 010, Train Loss: 0.720\n",
            "(0.5200381679389313, 0.9428571428571428, 0.010823220728107576, 0.021400778210116732, 0.505102873099466)\n",
            "-----------------------------------------------\n",
            "Pred: 2876, Actual: 3049\n",
            "Epoch: 020, Train Loss: 0.485\n",
            "(0.8503498727735369, 0.866481223922114, 0.8173171531649721, 0.8411814345991561, 0.8493810217816216)\n",
            "-----------------------------------------------\n",
            "Pred: 3109, Actual: 3049\n",
            "Epoch: 030, Train Loss: 0.345\n",
            "(0.8743638676844784, 0.8633000964940495, 0.8802886192194163, 0.8717115946735954, 0.874537640884793)\n",
            "-----------------------------------------------\n",
            "Pred: 3207, Actual: 3049\n",
            "Epoch: 040, Train Loss: 0.309\n",
            "(0.8797709923664122, 0.8574992204552542, 0.9019350606756313, 0.8791560102301791, 0.8804210653794952)\n",
            "-----------------------------------------------\n",
            "Pred: 3320, Actual: 3049\n",
            "Epoch: 050, Train Loss: 0.306\n",
            "(0.8799300254452926, 0.8454819277108434, 0.9206297146605444, 0.8814570576228608, 0.8811237489634922)\n",
            "-----------------------------------------------\n",
            "Pred: 3317, Actual: 3049\n",
            "Epoch: 060, Train Loss: 0.304\n",
            "(0.8807251908396947, 0.8465480856195358, 0.9209576910462447, 0.882186616399623, 0.8819052116855182)\n",
            "-----------------------------------------------\n",
            "Pred: 3325, Actual: 3049\n",
            "Epoch: 070, Train Loss: 0.303\n",
            "(0.8813613231552163, 0.8463157894736842, 0.922925549360446, 0.8829620332601193, 0.8825804035780309)\n",
            "-----------------------------------------------\n",
            "Pred: 3324, Actual: 3049\n",
            "Epoch: 080, Train Loss: 0.301\n",
            "(0.8821564885496184, 0.8471720818291215, 0.9235815021318465, 0.8837282284638317, 0.883371485860613)\n",
            "-----------------------------------------------\n",
            "Pred: 3343, Actual: 3049\n",
            "Epoch: 090, Train Loss: 0.298\n",
            "(0.8864503816793893, 0.8492372120849536, 0.9311249590029518, 0.8882978723404256, 0.8877606888253413)\n",
            "-----------------------------------------------\n",
            "Pred: 3328, Actual: 3049\n",
            "Epoch: 100, Train Loss: 0.296\n",
            "(0.886291348600509, 0.8506610576923077, 0.92850114791735, 0.8878783126862161, 0.8875293637085978)\n",
            "-----------------------------------------------\n",
            "Pred: 3340, Actual: 3049\n",
            "Epoch: 110, Train Loss: 0.295\n",
            "(0.887881679389313, 0.8508982035928143, 0.9321088881600524, 0.8896540929722963, 0.8891788651976551)\n",
            "-----------------------------------------------\n",
            "Pred: 3370, Actual: 3049\n",
            "Epoch: 120, Train Loss: 0.293\n",
            "(0.8872455470737913, 0.8471810089020771, 0.9363725811741554, 0.8895466583579997, 0.88868644495571)\n",
            "-----------------------------------------------\n",
            "Pred: 3358, Actual: 3049\n",
            "Epoch: 130, Train Loss: 0.292\n",
            "(0.8891539440203562, 0.8502084574151281, 0.9363725811741554, 0.8912127360699235, 0.890538868543237)\n",
            "-----------------------------------------------\n",
            "Pred: 3387, Actual: 3049\n",
            "Epoch: 140, Train Loss: 0.291\n",
            "(0.8883587786259542, 0.8464718039563035, 0.9403082978025582, 0.8909260410192666, 0.8898824601084417)\n",
            "-----------------------------------------------\n",
            "Pred: 3311, Actual: 3049\n",
            "Epoch: 150, Train Loss: 0.291\n",
            "(0.8915394402035624, 0.8574448807006947, 0.9311249590029518, 0.8927672955974844, 0.8927004850587467)\n",
            "-----------------------------------------------\n",
            "Pred: 3276, Actual: 3049\n",
            "Epoch: 160, Train Loss: 0.290\n",
            "(0.8916984732824428, 0.8614163614163615, 0.9255493604460479, 0.8923320158102767, 0.8926913211615852)\n",
            "-----------------------------------------------\n",
            "Pred: 3272, Actual: 3049\n",
            "Epoch: 170, Train Loss: 0.290\n",
            "(0.8926526717557252, 0.8627750611246944, 0.9258773368317481, 0.8932130991931657, 0.8936271525159049)\n",
            "-----------------------------------------------\n",
            "Pred: 3288, Actual: 3049\n",
            "Epoch: 180, Train Loss: 0.288\n",
            "(0.8926526717557252, 0.8610097323600974, 0.92850114791735, 0.8934827205302194, 0.8937041090003546)\n",
            "-----------------------------------------------\n",
            "Pred: 3392, Actual: 3049\n",
            "Epoch: 190, Train Loss: 0.288\n",
            "(0.8885178117048346, 0.8461084905660378, 0.9412922269596589, 0.8911659680173887, 0.8900656874224043)\n",
            "-----------------------------------------------\n",
            "Pred: 3374, Actual: 3049\n",
            "Epoch: 200, Train Loss: 0.286\n",
            "(0.8907442748091603, 0.8500296384113811, 0.9406362741882585, 0.8930406352171882, 0.8922076091534068)\n",
            "-----------------------------------------------\n",
            "Pred: 4846, Actual: 3093\n",
            "Epoch: 010, Train Loss: 0.984\n",
            "(0.7164440203562341, 0.6351630210482873, 0.9951503394762367, 0.7754125204685728, 0.7208928536191825)\n",
            "-----------------------------------------------\n",
            "Pred: 4155, Actual: 3093\n",
            "Epoch: 020, Train Loss: 0.493\n",
            "(0.8177480916030534, 0.7342960288808664, 0.9864209505334627, 0.8418874172185431, 0.8204405222150881)\n",
            "-----------------------------------------------\n",
            "Pred: 3248, Actual: 3093\n",
            "Epoch: 030, Train Loss: 0.353\n",
            "(0.8799300254452926, 0.8599137931034483, 0.9030067895247332, 0.8809336066866424, 0.8802983869376404)\n",
            "-----------------------------------------------\n",
            "Pred: 2968, Actual: 3093\n",
            "Epoch: 040, Train Loss: 0.355\n",
            "(0.86720737913486, 0.8803908355795148, 0.8448108632395732, 0.8622339547929384, 0.866849876064231)\n",
            "-----------------------------------------------\n",
            "Pred: 3024, Actual: 3093\n",
            "Epoch: 050, Train Loss: 0.334\n",
            "(0.8703880407124682, 0.8766534391534392, 0.8570966698997737, 0.8667647539643617, 0.8701758779858806)\n",
            "-----------------------------------------------\n",
            "Pred: 3149, Actual: 3093\n",
            "Epoch: 060, Train Loss: 0.320\n",
            "(0.8762722646310432, 0.8675770085741505, 0.8832848367280957, 0.8753604613905799, 0.8763842024016065)\n",
            "-----------------------------------------------\n",
            "Pred: 3225, Actual: 3093\n",
            "Epoch: 070, Train Loss: 0.315\n",
            "(0.8800890585241731, 0.8626356589147287, 0.8994503718073068, 0.8806584362139918, 0.8803981123512278)\n",
            "-----------------------------------------------\n",
            "Pred: 3261, Actual: 3093\n",
            "Epoch: 080, Train Loss: 0.314\n",
            "(0.8826335877862596, 0.8610855565777369, 0.9078564500484966, 0.8838526912181303, 0.8830362062449055)\n",
            "-----------------------------------------------\n",
            "Pred: 3271, Actual: 3093\n",
            "Epoch: 090, Train Loss: 0.313\n",
            "(0.8832697201017812, 0.8605930907979211, 0.9101196249595862, 0.8846637335009429, 0.8836983101323752)\n",
            "-----------------------------------------------\n",
            "Pred: 3271, Actual: 3093\n",
            "Epoch: 100, Train Loss: 0.312\n",
            "(0.8835877862595419, 0.860898807704066, 0.9104429356611704, 0.8849780012570709, 0.884016460005859)\n",
            "-----------------------------------------------\n",
            "Pred: 3273, Actual: 3093\n",
            "Epoch: 110, Train Loss: 0.311\n",
            "(0.8839058524173028, 0.8609838069049801, 0.9110895570643388, 0.8853283066289664, 0.8843397707074432)\n",
            "-----------------------------------------------\n",
            "Pred: 3273, Actual: 3093\n",
            "Epoch: 120, Train Loss: 0.311\n",
            "(0.8842239185750637, 0.8612893369996945, 0.911412867765923, 0.8856424756519007, 0.8846579205809271)\n",
            "-----------------------------------------------\n",
            "Pred: 3281, Actual: 3093\n",
            "Epoch: 130, Train Loss: 0.310\n",
            "(0.8839058524173028, 0.8601036269430051, 0.9123827998706757, 0.8854722309381864, 0.8843604140198449)\n",
            "-----------------------------------------------\n",
            "Pred: 3285, Actual: 3093\n",
            "Epoch: 140, Train Loss: 0.310\n",
            "(0.8835877862595419, 0.8593607305936073, 0.9127061105722599, 0.8852304797742238, 0.8840525858025619)\n",
            "-----------------------------------------------\n",
            "Pred: 3288, Actual: 3093\n",
            "Epoch: 150, Train Loss: 0.309\n",
            "(0.8834287531806616, 0.8588807785888077, 0.9130294212738441, 0.8851277229274408, 0.8839012521079705)\n",
            "-----------------------------------------------\n",
            "Pred: 3298, Actual: 3093\n",
            "Epoch: 160, Train Loss: 0.309\n",
            "(0.8837468193384224, 0.8580958156458459, 0.9149692854833495, 0.8856204036926928, 0.8842452061219563)\n",
            "-----------------------------------------------\n",
            "Pred: 3300, Actual: 3093\n",
            "Epoch: 170, Train Loss: 0.309\n",
            "(0.8840648854961832, 0.8581818181818182, 0.915615906886518, 0.8859690286250587, 0.8845685168235407)\n",
            "-----------------------------------------------\n",
            "Pred: 3305, Actual: 3093\n",
            "Epoch: 180, Train Loss: 0.309\n",
            "(0.8839058524173028, 0.8574886535552194, 0.9162625282896864, 0.885901844326352, 0.8844223439570498)\n",
            "-----------------------------------------------\n",
            "Pred: 3313, Actual: 3093\n",
            "Epoch: 190, Train Loss: 0.308\n",
            "(0.8835877862595419, 0.8563235738001811, 0.9172324603944391, 0.8857321261317515, 0.8841248373959676)\n",
            "-----------------------------------------------\n",
            "Pred: 3320, Actual: 3093\n",
            "Epoch: 200, Train Loss: 0.308\n",
            "(0.8837468193384224, 0.855722891566265, 0.918525703200776, 0.8860127865273663, 0.8843019752310609)\n",
            "-----------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Definindo dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def monte_carlo_train(device, data, n_runs=10):\n",
        "    # Extraindo quantidade de características e classes\n",
        "    num_node_features = data.x.size(1)\n",
        "    num_classes =  len(np.unique(data.y))\n",
        "    \n",
        "    for run in range(n_runs):\n",
        "        # Instancia o modelo GAT\n",
        "        gat = GAT(num_node_features, num_classes).to(device)\n",
        "\n",
        "        # Roda o otimizador Adam\n",
        "        optimizer_gcn = torch.optim.Adam(gat.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "        # Função custo\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Treina classificador\n",
        "        train_epochs(gat, data, optimizer_gcn, criterion, run, n_epochs=200, n_runs=10)\n",
        "   \n",
        "\n",
        "monte_carlo_train(device, data)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2N7dQsvSiaGU",
        "t_xBt_dKYlp4",
        "pEa71c636bhX"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.13 64-bit ('covid_es_gnn')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d18b4791e17a610633c3d6efe63d64f7bc6305f70aa7d49f5484cee67bbe0521"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
