{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQKflKlwU-Da"
      },
      "source": [
        "#Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G1QX8Qm1v2gG"
      },
      "outputs": [],
      "source": [
        "#!pip -q install torch torchvision torchaudio\n",
        "#!pip -q install torch_geometric\n",
        "#!pip -q install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cpu.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FgmvE0mpVD3B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Tratar dados\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "\n",
        "import re\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Importando CSV\n",
        "#from google.colab import drive\n",
        "\n",
        "# PyG\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import remove_isolated_nodes\n",
        "from torch_geometric.utils import contains_isolated_nodes\n",
        "from torch_geometric.transforms import LargestConnectedComponents\n",
        "import torch_geometric.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y8rcZmOVmsm"
      },
      "source": [
        "### Lendo CSV do Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OXOAEvgVl9t",
        "outputId": "7c8cc1be-90bd-4b35-bc00-e4b3498e35af"
      },
      "outputs": [],
      "source": [
        "filename = \"./data/covid_mexico.csv\"\n",
        "covid_df = pd.read_csv(filename, sep=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXbrGCOlb1Lo",
        "outputId": "88269849-51b3-42e6-a12a-94eca34beb99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1048575, 21)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "qCqczYx-wduO",
        "outputId": "f67f3027-98af-4956-bdab-0b9abb7742a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USMER</th>\n",
              "      <th>MEDICAL_UNIT</th>\n",
              "      <th>SEX</th>\n",
              "      <th>PATIENT_TYPE</th>\n",
              "      <th>DATE_DIED</th>\n",
              "      <th>INTUBED</th>\n",
              "      <th>PNEUMONIA</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PREGNANT</th>\n",
              "      <th>DIABETES</th>\n",
              "      <th>...</th>\n",
              "      <th>ASTHMA</th>\n",
              "      <th>INMSUPR</th>\n",
              "      <th>HIPERTENSION</th>\n",
              "      <th>OTHER_DISEASE</th>\n",
              "      <th>CARDIOVASCULAR</th>\n",
              "      <th>OBESITY</th>\n",
              "      <th>RENAL_CHRONIC</th>\n",
              "      <th>TOBACCO</th>\n",
              "      <th>CLASIFFICATION_FINAL</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>03/05/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>03/06/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>97</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>09/06/2020</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12/06/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>21/06/2020</td>\n",
              "      <td>97</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
              "0      2             1    1             1  03/05/2020       97          1   \n",
              "1      2             1    2             1  03/06/2020       97          1   \n",
              "2      2             1    2             2  09/06/2020        1          2   \n",
              "3      2             1    1             1  12/06/2020       97          2   \n",
              "4      2             1    2             1  21/06/2020       97          2   \n",
              "\n",
              "   AGE  PREGNANT  DIABETES  ...  ASTHMA  INMSUPR  HIPERTENSION  OTHER_DISEASE  \\\n",
              "0   65         2         2  ...       2        2             1              2   \n",
              "1   72        97         2  ...       2        2             1              2   \n",
              "2   55        97         1  ...       2        2             2              2   \n",
              "3   53         2         2  ...       2        2             2              2   \n",
              "4   68        97         1  ...       2        2             1              2   \n",
              "\n",
              "   CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  CLASIFFICATION_FINAL  ICU  \n",
              "0               2        2              2        2                     3   97  \n",
              "1               2        1              1        2                     5   97  \n",
              "2               2        2              2        2                     3    2  \n",
              "3               2        2              2        2                     7   97  \n",
              "4               2        2              2        2                     3   97  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "XwfEwtrYbzl-",
        "outputId": "303a06ef-0969-498a-8218-70d6bd46c413"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USMER</th>\n",
              "      <th>MEDICAL_UNIT</th>\n",
              "      <th>SEX</th>\n",
              "      <th>PATIENT_TYPE</th>\n",
              "      <th>INTUBED</th>\n",
              "      <th>PNEUMONIA</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PREGNANT</th>\n",
              "      <th>DIABETES</th>\n",
              "      <th>COPD</th>\n",
              "      <th>ASTHMA</th>\n",
              "      <th>INMSUPR</th>\n",
              "      <th>HIPERTENSION</th>\n",
              "      <th>OTHER_DISEASE</th>\n",
              "      <th>CARDIOVASCULAR</th>\n",
              "      <th>OBESITY</th>\n",
              "      <th>RENAL_CHRONIC</th>\n",
              "      <th>TOBACCO</th>\n",
              "      <th>CLASIFFICATION_FINAL</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "      <td>1.048575e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.632194e+00</td>\n",
              "      <td>8.980565e+00</td>\n",
              "      <td>1.499259e+00</td>\n",
              "      <td>1.190765e+00</td>\n",
              "      <td>7.952288e+01</td>\n",
              "      <td>3.346831e+00</td>\n",
              "      <td>4.179410e+01</td>\n",
              "      <td>4.976558e+01</td>\n",
              "      <td>2.186404e+00</td>\n",
              "      <td>2.260569e+00</td>\n",
              "      <td>2.242626e+00</td>\n",
              "      <td>2.298132e+00</td>\n",
              "      <td>2.128989e+00</td>\n",
              "      <td>2.435143e+00</td>\n",
              "      <td>2.261810e+00</td>\n",
              "      <td>2.125176e+00</td>\n",
              "      <td>2.257180e+00</td>\n",
              "      <td>2.214333e+00</td>\n",
              "      <td>5.305653e+00</td>\n",
              "      <td>7.955397e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.822084e-01</td>\n",
              "      <td>3.723278e+00</td>\n",
              "      <td>4.999997e-01</td>\n",
              "      <td>3.929041e-01</td>\n",
              "      <td>3.686889e+01</td>\n",
              "      <td>1.191288e+01</td>\n",
              "      <td>1.690739e+01</td>\n",
              "      <td>4.751073e+01</td>\n",
              "      <td>5.424242e+00</td>\n",
              "      <td>5.132258e+00</td>\n",
              "      <td>5.114089e+00</td>\n",
              "      <td>5.462843e+00</td>\n",
              "      <td>5.236397e+00</td>\n",
              "      <td>6.646676e+00</td>\n",
              "      <td>5.194850e+00</td>\n",
              "      <td>5.175445e+00</td>\n",
              "      <td>5.135354e+00</td>\n",
              "      <td>5.323097e+00</td>\n",
              "      <td>1.881165e+00</td>\n",
              "      <td>3.682307e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>3.000000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>5.300000e+01</td>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>9.700000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.300000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>9.900000e+01</td>\n",
              "      <td>9.900000e+01</td>\n",
              "      <td>1.210000e+02</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>9.800000e+01</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>9.900000e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              USMER  MEDICAL_UNIT           SEX  PATIENT_TYPE       INTUBED  \\\n",
              "count  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06   \n",
              "mean   1.632194e+00  8.980565e+00  1.499259e+00  1.190765e+00  7.952288e+01   \n",
              "std    4.822084e-01  3.723278e+00  4.999997e-01  3.929041e-01  3.686889e+01   \n",
              "min    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
              "25%    1.000000e+00  4.000000e+00  1.000000e+00  1.000000e+00  9.700000e+01   \n",
              "50%    2.000000e+00  1.200000e+01  1.000000e+00  1.000000e+00  9.700000e+01   \n",
              "75%    2.000000e+00  1.200000e+01  2.000000e+00  1.000000e+00  9.700000e+01   \n",
              "max    2.000000e+00  1.300000e+01  2.000000e+00  2.000000e+00  9.900000e+01   \n",
              "\n",
              "          PNEUMONIA           AGE      PREGNANT      DIABETES          COPD  \\\n",
              "count  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06   \n",
              "mean   3.346831e+00  4.179410e+01  4.976558e+01  2.186404e+00  2.260569e+00   \n",
              "std    1.191288e+01  1.690739e+01  4.751073e+01  5.424242e+00  5.132258e+00   \n",
              "min    1.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
              "25%    2.000000e+00  3.000000e+01  2.000000e+00  2.000000e+00  2.000000e+00   \n",
              "50%    2.000000e+00  4.000000e+01  9.700000e+01  2.000000e+00  2.000000e+00   \n",
              "75%    2.000000e+00  5.300000e+01  9.700000e+01  2.000000e+00  2.000000e+00   \n",
              "max    9.900000e+01  1.210000e+02  9.800000e+01  9.800000e+01  9.800000e+01   \n",
              "\n",
              "             ASTHMA       INMSUPR  HIPERTENSION  OTHER_DISEASE  \\\n",
              "count  1.048575e+06  1.048575e+06  1.048575e+06   1.048575e+06   \n",
              "mean   2.242626e+00  2.298132e+00  2.128989e+00   2.435143e+00   \n",
              "std    5.114089e+00  5.462843e+00  5.236397e+00   6.646676e+00   \n",
              "min    1.000000e+00  1.000000e+00  1.000000e+00   1.000000e+00   \n",
              "25%    2.000000e+00  2.000000e+00  2.000000e+00   2.000000e+00   \n",
              "50%    2.000000e+00  2.000000e+00  2.000000e+00   2.000000e+00   \n",
              "75%    2.000000e+00  2.000000e+00  2.000000e+00   2.000000e+00   \n",
              "max    9.800000e+01  9.800000e+01  9.800000e+01   9.800000e+01   \n",
              "\n",
              "       CARDIOVASCULAR       OBESITY  RENAL_CHRONIC       TOBACCO  \\\n",
              "count    1.048575e+06  1.048575e+06   1.048575e+06  1.048575e+06   \n",
              "mean     2.261810e+00  2.125176e+00   2.257180e+00  2.214333e+00   \n",
              "std      5.194850e+00  5.175445e+00   5.135354e+00  5.323097e+00   \n",
              "min      1.000000e+00  1.000000e+00   1.000000e+00  1.000000e+00   \n",
              "25%      2.000000e+00  2.000000e+00   2.000000e+00  2.000000e+00   \n",
              "50%      2.000000e+00  2.000000e+00   2.000000e+00  2.000000e+00   \n",
              "75%      2.000000e+00  2.000000e+00   2.000000e+00  2.000000e+00   \n",
              "max      9.800000e+01  9.800000e+01   9.800000e+01  9.800000e+01   \n",
              "\n",
              "       CLASIFFICATION_FINAL           ICU  \n",
              "count          1.048575e+06  1.048575e+06  \n",
              "mean           5.305653e+00  7.955397e+01  \n",
              "std            1.881165e+00  3.682307e+01  \n",
              "min            1.000000e+00  1.000000e+00  \n",
              "25%            3.000000e+00  9.700000e+01  \n",
              "50%            6.000000e+00  9.700000e+01  \n",
              "75%            7.000000e+00  9.700000e+01  \n",
              "max            7.000000e+00  9.900000e+01  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IasZkO-CwgZs",
        "outputId": "91daf048-98ab-4c54-c4eb-b8703f51b02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count    Dtype \n",
            "---  ------                --------------    ----- \n",
            " 0   USMER                 1048575 non-null  int64 \n",
            " 1   MEDICAL_UNIT          1048575 non-null  int64 \n",
            " 2   SEX                   1048575 non-null  int64 \n",
            " 3   PATIENT_TYPE          1048575 non-null  int64 \n",
            " 4   DATE_DIED             1048575 non-null  object\n",
            " 5   INTUBED               1048575 non-null  int64 \n",
            " 6   PNEUMONIA             1048575 non-null  int64 \n",
            " 7   AGE                   1048575 non-null  int64 \n",
            " 8   PREGNANT              1048575 non-null  int64 \n",
            " 9   DIABETES              1048575 non-null  int64 \n",
            " 10  COPD                  1048575 non-null  int64 \n",
            " 11  ASTHMA                1048575 non-null  int64 \n",
            " 12  INMSUPR               1048575 non-null  int64 \n",
            " 13  HIPERTENSION          1048575 non-null  int64 \n",
            " 14  OTHER_DISEASE         1048575 non-null  int64 \n",
            " 15  CARDIOVASCULAR        1048575 non-null  int64 \n",
            " 16  OBESITY               1048575 non-null  int64 \n",
            " 17  RENAL_CHRONIC         1048575 non-null  int64 \n",
            " 18  TOBACCO               1048575 non-null  int64 \n",
            " 19  CLASIFFICATION_FINAL  1048575 non-null  int64 \n",
            " 20  ICU                   1048575 non-null  int64 \n",
            "dtypes: int64(20), object(1)\n",
            "memory usage: 168.0+ MB\n"
          ]
        }
      ],
      "source": [
        "covid_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-38SUv5pV67F"
      },
      "source": [
        "# Pré Tratamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysi62eEJWKHa"
      },
      "source": [
        "### Tratando DATE_DIED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dKoX0lNWoM3",
        "outputId": "087a5361-2bc7-4ce8-e5e7-a4ce6c4db881"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DATE_DIED\n",
              "9999-99-99    971633\n",
              "06/07/2020      1000\n",
              "07/07/2020       996\n",
              "13/07/2020       990\n",
              "16/06/2020       979\n",
              "               ...  \n",
              "24/11/2020         1\n",
              "17/12/2020         1\n",
              "08/12/2020         1\n",
              "16/03/2021         1\n",
              "22/04/2021         1\n",
              "Name: count, Length: 401, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#A Data \"9999-99-99\" significa que o paciente sobreviveu\n",
        "covid_df['DATE_DIED'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ee83IqFWlWJ",
        "outputId": "db8e56ce-29e4-47df-eb76-0a9ac38154a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PASSED\n",
              "0    971633\n",
              "1     76942\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Cria nova coluna binaria e preenche com os valores baseando na coluna DATE_DIED\n",
        "covid_df['PASSED'] = [0 if l == '9999-99-99' else 1 for l in covid_df.DATE_DIED]\n",
        "\n",
        "#Remove coluna denecessária\n",
        "covid_df.drop(columns=[\"DATE_DIED\"], inplace=True)\n",
        "\n",
        "covid_df.PASSED.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtOrU68QVzLE"
      },
      "source": [
        "# Explorando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBojdC--V9m4"
      },
      "source": [
        "### Descrevendo dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USMER -----> 2\n",
            "MEDICAL_UNIT -----> 13\n",
            "SEX -----> 2\n",
            "PATIENT_TYPE -----> 2\n",
            "INTUBED -----> 4\n",
            "PNEUMONIA -----> 3\n",
            "AGE -----> 121\n",
            "PREGNANT -----> 4\n",
            "DIABETES -----> 3\n",
            "COPD -----> 3\n",
            "ASTHMA -----> 3\n",
            "INMSUPR -----> 3\n",
            "HIPERTENSION -----> 3\n",
            "OTHER_DISEASE -----> 3\n",
            "CARDIOVASCULAR -----> 3\n",
            "OBESITY -----> 3\n",
            "RENAL_CHRONIC -----> 3\n",
            "TOBACCO -----> 3\n",
            "CLASIFFICATION_FINAL -----> 7\n",
            "ICU -----> 4\n",
            "PASSED -----> 2\n"
          ]
        }
      ],
      "source": [
        "for i in covid_df.columns:\n",
        "    print(i,\"----->\", len(covid_df[i].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Percentual de mortes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6p14IJJo3jNr"
      },
      "outputs": [],
      "source": [
        "def plot_percentual_deads(df):\n",
        "    percentual_deads = round(df.PASSED.mean() * 100, 2)\n",
        "    print(f\"Percentural of deads {percentual_deads}]\\n\")\n",
        "\n",
        "    ax = df.PASSED.value_counts(dropna=False).plot(kind=\"bar\", title=f\"Pacientes x Óbitos -> ({percentual_deads}%)\", color=[\"blue\", \"red\"], ylabel=\"Qtd. Pacientes\")\n",
        "\n",
        "    container = ax.containers[0]\n",
        "    ax.bar_label(container)\n",
        "    ax.set_xticklabels([\"Recuperados\", \"Óbitos\"], rotation=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentural of deads 7.34]\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_percentual_deads(covid_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvK8ds_UuR4E",
        "outputId": "a2da688e-e74e-44e4-a4f6-87060814929c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1048575, 21)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th5dFn3rV5iq"
      },
      "source": [
        "# Tratando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N7dQsvSiaGU"
      },
      "source": [
        "### Coluna PREGNANT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rzrtly8idui",
        "outputId": "7ed9e956-64aa-4279-a31d-50815cbb94aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PREGNANT\n",
              "97    523511\n",
              "2     513179\n",
              "1       8131\n",
              "98      3754\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df['PREGNANT'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwzVvlkDX8tS",
        "outputId": "ddef3c44-3e4c-4938-db99-4ff52e3c51e1"
      },
      "outputs": [],
      "source": [
        "#Altera os valores para Homens, para sem gravidez\n",
        "covid_df['PREGNANT'] = covid_df['PREGNANT'].replace(97, 2)\n",
        "\n",
        "#Remove linhas com valores ausentes\n",
        "covid_df = covid_df.drop(covid_df[covid_df.PREGNANT == 98].index)\n",
        "covid_df = covid_df[(covid_df.PREGNANT == 1) | (covid_df.PREGNANT == 2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PREGNANT\n",
              "2    1036690\n",
              "1       8131\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Resultado apos tratamento\n",
        "# Como há poucas linhas com mulheres grávidas,\n",
        "# essa coluna se torna uma constante, com isso, não necessita deste atributo\n",
        "# e será removido mais a frente.\n",
        "covid_df.PREGNANT.value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlF5JmB1_9gs"
      },
      "source": [
        "### Coluna INTUBED\n",
        "Para casos em que INTUBED é nulo e o paciente hospitalizado, receberá o valor NaN. De outra forma, recebe 2 [Não], quando o paciente foi para casa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VctLlemQtz7r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "INTUBED\n",
              "97.0    845277\n",
              "2.0     158768\n",
              "1.0      33609\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [2] hospitalizado\n",
        "filter_intubed_1 = (covid_df[\"INTUBED\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 2)\n",
        "covid_df.loc[filter_intubed_1, \"INTUBED\"] = np.nan\n",
        "covid_df[\"INTUBED\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvzUomVlW3GD",
        "outputId": "3344cba5-1374-4465-8745-a7ee55027f56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "INTUBED\n",
              "2.0    1004045\n",
              "1.0      33609\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [1] para casa\n",
        "filter_intubed_2 = (covid_df[\"INTUBED\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 1)\n",
        "covid_df.loc[filter_intubed_2, \"INTUBED\"] = 2\n",
        "covid_df[\"INTUBED\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEa71c636bhX"
      },
      "source": [
        "### Coluna ICU\n",
        "Se ICU nulo e foi hospitalizado, então recebe NaN. Se não, recebe 2 [Não]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae76vj7v6e18",
        "outputId": "d55adbfa-c1b2-4fc7-b1c1-133cb0a9db22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ICU\n",
              "97.0    845277\n",
              "2.0     175386\n",
              "1.0      16830\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [2] hospitalizado\n",
        "filter_icu_1 = (covid_df[\"ICU\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 2)\n",
        "covid_df.loc[filter_icu_1, \"ICU\"] = np.nan\n",
        "covid_df[\"ICU\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9ylD_Ae932rt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ICU\n",
              "2.0    1020663\n",
              "1.0      16830\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paciente [1] para casa\n",
        "filter_icu_2 = (covid_df[\"ICU\"] >= 97) & (covid_df[\"PATIENT_TYPE\"] == 1)\n",
        "covid_df.loc[filter_icu_2, \"ICU\"] = 2\n",
        "covid_df[\"ICU\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX-oviAT5nZe",
        "outputId": "92d742c1-2453-4d89-cb8f-3af617dd4426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "USMER                      0\n",
              "MEDICAL_UNIT               0\n",
              "SEX                        0\n",
              "PATIENT_TYPE               0\n",
              "INTUBED                 7167\n",
              "PNEUMONIA                  0\n",
              "AGE                        0\n",
              "PREGNANT                   0\n",
              "DIABETES                   0\n",
              "COPD                       0\n",
              "ASTHMA                     0\n",
              "INMSUPR                    0\n",
              "HIPERTENSION               0\n",
              "OTHER_DISEASE              0\n",
              "CARDIOVASCULAR             0\n",
              "OBESITY                    0\n",
              "RENAL_CHRONIC              0\n",
              "TOBACCO                    0\n",
              "CLASIFFICATION_FINAL       0\n",
              "ICU                     7328\n",
              "PASSED                     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QksaAzLyXhSn"
      },
      "source": [
        "### Colunas NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ywAVj9KuvI13"
      },
      "outputs": [],
      "source": [
        "def verify_num_cols(df):\n",
        "    # Média ordenada e colunas com valor vazio\n",
        "    mean_na = df.isna().mean().sort_values(ascending=False)\n",
        "\n",
        "    # Cria DF de colunas nulas\n",
        "    df_na = pd.DataFrame({\"percentual\": mean_na})\n",
        "\n",
        "    return df_na\n",
        "\n",
        "def remove_nan_cols_above_limit(df, cols_to_ignore, limit=0.30):\n",
        "    # Obtém colunas nulas e seu percentual\n",
        "    df_na = verify_num_cols(df)\n",
        "\n",
        "    # Ignora colunas\n",
        "    df_na.drop(cols_to_ignore, inplace=True)\n",
        "\n",
        "    # Filtra colunas pelo limite\n",
        "    df_na_above_limit = df_na[df_na.percentual >= limit]\n",
        "\n",
        "    # Obtém as colunas a serem dropadas\n",
        "    columns_to_drop = df_na_above_limit.index\n",
        "\n",
        "    # Dropa colunas\n",
        "    df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "    return df, df_na_above_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "2A0YA0QX-xOV",
        "outputId": "dd55e0e8-5c0b-4365-e756-9d3575d193ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>percentual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [percentual]\n",
              "Index: []"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove colunas nulas acima do limite de 5%\n",
        "# Coluna considera importante para ser removida\n",
        "cols_to_ignore = [\"ICU\", \"INTUBED\"]\n",
        "_, df_na = remove_nan_cols_above_limit(covid_df, cols_to_ignore, limit=0.05)\n",
        "\n",
        "# Colunas removidas\n",
        "df_na"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAEhuFtlhJ7y",
        "outputId": "fefa1689-6f7e-47ec-a96e-da452154707f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1044821, 21)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwOm5PZDjTKS",
        "outputId": "70fca99c-c95e-4080-b5db-1904f921736a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "USMER                      0\n",
              "MEDICAL_UNIT               0\n",
              "SEX                        0\n",
              "PATIENT_TYPE               0\n",
              "INTUBED                 7167\n",
              "PNEUMONIA                  0\n",
              "AGE                        0\n",
              "PREGNANT                   0\n",
              "DIABETES                   0\n",
              "COPD                       0\n",
              "ASTHMA                     0\n",
              "INMSUPR                    0\n",
              "HIPERTENSION               0\n",
              "OTHER_DISEASE              0\n",
              "CARDIOVASCULAR             0\n",
              "OBESITY                    0\n",
              "RENAL_CHRONIC              0\n",
              "TOBACCO                    0\n",
              "CLASIFFICATION_FINAL       0\n",
              "ICU                     7328\n",
              "PASSED                     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s4k3YYYEM-k"
      },
      "source": [
        "### Removendo colunas desnecessárias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofIJYDIGZx98"
      },
      "source": [
        "* PREGNANT - Coluna constante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVg9zX-EZqep",
        "outputId": "67363131-9fc5-4e3e-bd3b-ffed83c1ddb4"
      },
      "outputs": [],
      "source": [
        "# Removendo colunas\n",
        "covid_df.drop(columns=[\"PREGNANT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove linhas com alguma coluna nula\n",
        "covid_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VRw-t6XKEQ8J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USMER :  0\n",
            "MEDICAL_UNIT :  0\n",
            "SEX :  0\n",
            "PATIENT_TYPE :  0\n",
            "INTUBED :  0\n",
            "PNEUMONIA :  10652\n",
            "AGE :  327\n",
            "DIABETES :  3133\n",
            "COPD :  2797\n",
            "ASTHMA :  2770\n",
            "INMSUPR :  3159\n",
            "HIPERTENSION :  2906\n",
            "OTHER_DISEASE :  4759\n",
            "CARDIOVASCULAR :  2865\n",
            "OBESITY :  2838\n",
            "RENAL_CHRONIC :  2804\n",
            "TOBACCO :  3018\n",
            "CLASIFFICATION_FINAL :  0\n",
            "ICU :  0\n",
            "PASSED :  0\n"
          ]
        }
      ],
      "source": [
        "# Nessa base valores como 97, 98 e 99 são nulos\n",
        "def check_columns():\n",
        "  for i in covid_df.columns:\n",
        "    temp_df = covid_df[(covid_df[i] == 99) | (covid_df[i] == 97) | (covid_df[i] == 98)]\n",
        "    print(i + \" : \",temp_df[i].count())\n",
        "\n",
        "check_columns()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USMER :  0\n",
            "MEDICAL_UNIT :  0\n",
            "SEX :  0\n",
            "PATIENT_TYPE :  0\n",
            "INTUBED :  0\n",
            "PNEUMONIA :  0\n",
            "AGE :  321\n",
            "DIABETES :  0\n",
            "COPD :  0\n",
            "ASTHMA :  0\n",
            "INMSUPR :  0\n",
            "HIPERTENSION :  0\n",
            "OTHER_DISEASE :  0\n",
            "CARDIOVASCULAR :  0\n",
            "OBESITY :  0\n",
            "RENAL_CHRONIC :  0\n",
            "TOBACCO :  0\n",
            "CLASIFFICATION_FINAL :  0\n",
            "ICU :  0\n",
            "PASSED :  0\n"
          ]
        }
      ],
      "source": [
        "columns_filter = ['PNEUMONIA', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR', 'HIPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO']\n",
        "for c in columns_filter:\n",
        "    covid_df = covid_df[(covid_df[c] == 1) | (covid_df[c] == 2)]\n",
        "\n",
        "check_columns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eq81Uvc2ht-"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIgxwNSL3YPh"
      },
      "source": [
        "## Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HeDjGzmV9T2j"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RkPNWEOgabFU"
      },
      "outputs": [],
      "source": [
        "covid_df[\"CLASIFFICATION_FINAL\"] = label_encoder.fit_transform(covid_df[\"CLASIFFICATION_FINAL\"])\n",
        "covid_df[\"USMER\"] = label_encoder.fit_transform(covid_df[\"USMER\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIYjQrQr3cIA"
      },
      "source": [
        "## One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "keuhwEdd3cXk"
      },
      "outputs": [],
      "source": [
        "# Define colunas a serem ignoradas\n",
        "ignore_columns = [\"CLASIFFICATION_FINAL\", \"AGE\", \"PASSED\", \"USMER\", ]\n",
        "onehot_encoder_cols = [col for col in covid_df.columns.tolist() if col not in ignore_columns]\n",
        "\n",
        "# Instancia o OneHotEnconder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG5C-muicP3h",
        "outputId": "8a5fb345-fda7-408c-e03f-1db06193245a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1019666, 43)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Realiza o fit-transform\n",
        "one_hot_result = one_hot_encoder.fit_transform(covid_df[onehot_encoder_cols])\n",
        "\n",
        "# Obtem os nomes das colunas\n",
        "one_hot_col_result = one_hot_encoder.get_feature_names_out(onehot_encoder_cols)\n",
        "\n",
        "# Armazena em um novo DF\n",
        "one_hot_col_df = pd.DataFrame(one_hot_result, columns=one_hot_col_result, index=covid_df.index)\n",
        "one_hot_col_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz5PNxsciru5",
        "outputId": "a80d540b-bc0a-4058-9f5c-de106f9a77a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['MEDICAL_UNIT_1', 'MEDICAL_UNIT_2', 'MEDICAL_UNIT_3',\n",
              "       'MEDICAL_UNIT_4', 'MEDICAL_UNIT_5', 'MEDICAL_UNIT_6',\n",
              "       'MEDICAL_UNIT_7', 'MEDICAL_UNIT_8', 'MEDICAL_UNIT_9',\n",
              "       'MEDICAL_UNIT_10', 'MEDICAL_UNIT_11', 'MEDICAL_UNIT_12',\n",
              "       'MEDICAL_UNIT_13', 'SEX_1', 'SEX_2', 'PATIENT_TYPE_1',\n",
              "       'PATIENT_TYPE_2', 'INTUBED_1.0', 'INTUBED_2.0', 'PNEUMONIA_1',\n",
              "       'PNEUMONIA_2', 'DIABETES_1', 'DIABETES_2', 'COPD_1', 'COPD_2',\n",
              "       'ASTHMA_1', 'ASTHMA_2', 'INMSUPR_1', 'INMSUPR_2', 'HIPERTENSION_1',\n",
              "       'HIPERTENSION_2', 'OTHER_DISEASE_1', 'OTHER_DISEASE_2',\n",
              "       'CARDIOVASCULAR_1', 'CARDIOVASCULAR_2', 'OBESITY_1', 'OBESITY_2',\n",
              "       'RENAL_CHRONIC_1', 'RENAL_CHRONIC_2', 'TOBACCO_1', 'TOBACCO_2',\n",
              "       'ICU_1.0', 'ICU_2.0'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot_col_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1019666, 47)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dropa colunas antigas e adiciona as novas\n",
        "covid_df = covid_df.drop(columns=onehot_encoder_cols).join(one_hot_col_df)\n",
        "covid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar memoria\n",
        "del one_hot_col_df\n",
        "del one_hot_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Estratificando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Nesse caso, é necessário reduzir de forma estratificada os dados, já que essa base\n",
        "possui aproximadamente 73 mil óbitos (classe minoritária). Ou seja,\n",
        "aplicar o RUS faria com que a base tivesse cerca de 73 mil óbitos e 73 mil sobreviventes\n",
        "o que gera mais de 140 mil dados para serem passados pela etapa de ajuste de hiperparâmetros,\n",
        "fazendo com que seja lento a busca pelos hiperparâmetros.\n",
        "* Com isso, reduzimos os dados em 20% (200 mil linhas). Aplicando o RUS cada classe é representada por\n",
        "aproximadamente 14 mil dados (total de 28 mil).\n",
        "* Cada paciente é um nó, logo a quantidade de aresta possíveis é n(n - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agrupa por PASSED e aplica o SAMPLE em cada grupo\n",
        "covid_df = covid_df.groupby(\"PASSED\", group_keys=False).apply(lambda g: g.sample(frac=0.15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzQLCJ66IORk"
      },
      "source": [
        "# Balanceando Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ersY3p4_IRK2"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(sampling_strategy='majority')\n",
        "X,y = rus.fit_resample(covid_df.drop(columns=[\"PASSED\"]), covid_df.PASSED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PASSED\n",
              "0    10996\n",
              "1    10996\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCDv3sReXpnf"
      },
      "source": [
        "# Transformando Dataset em estrutura para grafo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqJ9NGMG9WIs"
      },
      "source": [
        "## Determinado propriedades\n",
        "* Nodes -> Pessoas (cada linha da tabela)\n",
        "* Edges -> Similaridade das doenças de cada pessoa\n",
        "* Nodes features -> Comorbidades, etc.\n",
        "* Labels -> Se a pessoa pode morrer por covid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqJA_nxr9WIs"
      },
      "source": [
        "## Extraindo Node Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD6E-p4k9WIs",
        "outputId": "dd72ee25-2520-45cf-9f4e-d93a899f7142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['USMER', 'AGE', 'CLASIFFICATION_FINAL', 'MEDICAL_UNIT_1',\n",
              "       'MEDICAL_UNIT_2', 'MEDICAL_UNIT_3', 'MEDICAL_UNIT_4', 'MEDICAL_UNIT_5',\n",
              "       'MEDICAL_UNIT_6', 'MEDICAL_UNIT_7', 'MEDICAL_UNIT_8', 'MEDICAL_UNIT_9',\n",
              "       'MEDICAL_UNIT_10', 'MEDICAL_UNIT_11', 'MEDICAL_UNIT_12',\n",
              "       'MEDICAL_UNIT_13', 'SEX_1', 'SEX_2', 'PATIENT_TYPE_1', 'PATIENT_TYPE_2',\n",
              "       'INTUBED_1.0', 'INTUBED_2.0', 'PNEUMONIA_1', 'PNEUMONIA_2',\n",
              "       'DIABETES_1', 'DIABETES_2', 'COPD_1', 'COPD_2', 'ASTHMA_1', 'ASTHMA_2',\n",
              "       'INMSUPR_1', 'INMSUPR_2', 'HIPERTENSION_1', 'HIPERTENSION_2',\n",
              "       'OTHER_DISEASE_1', 'OTHER_DISEASE_2', 'CARDIOVASCULAR_1',\n",
              "       'CARDIOVASCULAR_2', 'OBESITY_1', 'OBESITY_2', 'RENAL_CHRONIC_1',\n",
              "       'RENAL_CHRONIC_2', 'TOBACCO_1', 'TOBACCO_2', 'ICU_1.0', 'ICU_2.0'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "sj4v61YkkbEA"
      },
      "outputs": [],
      "source": [
        "# Reseta o index\n",
        "covid_df = covid_df.reset_index(drop=True)\n",
        "X = X.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "04pg-dG-9WIt"
      },
      "outputs": [],
      "source": [
        "personal_info = ['SEX_1', 'SEX_2', 'AGE']\n",
        "\n",
        "clinicians = ['USMER', 'PATIENT_TYPE_1', 'PATIENT_TYPE_2', 'CLASIFFICATION_FINAL', \n",
        "              'ICU_1.0', 'ICU_2.0', 'INTUBED_1.0', 'INTUBED_2.0', 'MEDICAL_UNIT_1',\n",
        "       'MEDICAL_UNIT_2', 'MEDICAL_UNIT_3', 'MEDICAL_UNIT_4', 'MEDICAL_UNIT_5',\n",
        "       'MEDICAL_UNIT_6', 'MEDICAL_UNIT_7', 'MEDICAL_UNIT_8', 'MEDICAL_UNIT_9',\n",
        "       'MEDICAL_UNIT_10', 'MEDICAL_UNIT_11', 'MEDICAL_UNIT_12',\n",
        "       'MEDICAL_UNIT_13']\n",
        "\n",
        "comorbities = ['PNEUMONIA_1', 'PNEUMONIA_2', 'DIABETES_1', 'DIABETES_2', 'COPD_1', 'COPD_2', 'ASTHMA_1', 'ASTHMA_2',\n",
        "       'INMSUPR_1', 'INMSUPR_2', 'HIPERTENSION_1', 'HIPERTENSION_2',\n",
        "       'OTHER_DISEASE_1', 'OTHER_DISEASE_2', 'CARDIOVASCULAR_1',\n",
        "       'CARDIOVASCULAR_2', 'OBESITY_1', 'OBESITY_2', 'RENAL_CHRONIC_1',\n",
        "       'RENAL_CHRONIC_2', 'TOBACCO_1', 'TOBACCO_2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xW8FIQ9_m9j",
        "outputId": "e11d6f95-b74b-48e7-f76f-8b5c1946f761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.,  1., 24., ...,  0.,  0.,  0.],\n",
              "       [ 1.,  0., 45., ...,  0.,  1.,  0.],\n",
              "       [ 1.,  0., 55., ...,  0.,  1.,  0.],\n",
              "       ...,\n",
              "       [ 1.,  0., 67., ...,  0.,  1.,  0.],\n",
              "       [ 0.,  1., 32., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  1., 60., ...,  0.,  0.,  0.]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = personal_info + comorbities + clinicians\n",
        "\n",
        "all_features = X[features].to_numpy()\n",
        "X.drop(columns=features, inplace=True)\n",
        "all_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORV6602Yaj64"
      },
      "source": [
        "## Definindo similaridade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "2y7_bWf8ZyOS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "from torch_geometric.utils import remove_isolated_nodes\n",
        "from torch_geometric.utils import contains_isolated_nodes\n",
        "from random import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "c7FqYFmsan9E"
      },
      "outputs": [],
      "source": [
        "# Calcula a similaridade do cosseno para os pacientes\n",
        "similarity = cosine_similarity(all_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "o2C5rR6yi-lT"
      },
      "outputs": [],
      "source": [
        "# Defini um limiar para existir uma relação entre os pacientes\n",
        "threshold = 0.999\n",
        "\n",
        "# Cria a lista de adjacencia\n",
        "adjacency_list = [[],[]]\n",
        "\n",
        "# O resultado de similarity, é uma matriz de paciente x pacientes\n",
        "# Onde cada elemento é o cosseno da similaridade\n",
        "# Assim, percorremos paciente x parciente\n",
        "for pac_i in range(len(similarity)):\n",
        "    for pac_j in range(pac_i + 1, len(similarity[pac_i])):\n",
        "        value = similarity[pac_i][pac_j]\n",
        "\n",
        "        # True, Se o paciente não for si mesmo (i!=j) e\n",
        "        #o cosseno da similiaridade for maior que o limiar\n",
        "\n",
        "        if(pac_i != pac_j and value >= threshold):\n",
        "            # Adiciona a->b e b->a\n",
        "            adjacency_list[0].append(pac_i)\n",
        "            adjacency_list[1].append(pac_j)\n",
        "\n",
        "            adjacency_list[0].append(pac_j)\n",
        "            adjacency_list[1].append(pac_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFFnhktMH9Lw",
        "outputId": "8681a404-a61b-42a7-87c2-4bfec1ee6b61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29176476"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(adjacency_list[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roqyBZCVvnEk"
      },
      "source": [
        "## Usando Pyg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Kc599nZczHCv"
      },
      "outputs": [],
      "source": [
        "X_features = torch.from_numpy(all_features).float()\n",
        "y_target = torch.from_numpy(y.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qdPLQrpZkOA",
        "outputId": "5d81828b-0fe6-4b2b-d837-ec814e91e5ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1., 24.,  ...,  0.,  0.,  0.],\n",
              "        [ 1.,  0., 45.,  ...,  0.,  1.,  0.],\n",
              "        [ 1.,  0., 55.,  ...,  0.,  1.,  0.],\n",
              "        ...,\n",
              "        [ 1.,  0., 67.,  ...,  0.,  1.,  0.],\n",
              "        [ 0.,  1., 32.,  ...,  0.,  0.,  0.],\n",
              "        [ 0.,  1., 60.,  ...,  0.,  0.,  0.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.from_numpy(all_features.astype(np.double))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "rPJiCJMfs53M"
      },
      "outputs": [],
      "source": [
        "edge_index = torch.tensor(adjacency_list, dtype=torch.long)\n",
        "edge_index,_,_ = remove_isolated_nodes(edge_index)\n",
        "\n",
        "data = Data(x=X_features, edge_index=edge_index, y=y_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar memória\n",
        "del adjacency_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUfpmRndLU6f",
        "outputId": "325b2955-0a7c-4715-a71c-ffac0681b880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 21992\n",
            "Number of edges: 29176476\n",
            "Average node degree: 1326.69\n",
            "Has isolated nodes: True\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "def show_data_info(data):\n",
        "    print(f'Number of nodes: {data.num_nodes}')\n",
        "    print(f'Number of edges: {data.num_edges}')\n",
        "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "    print(f'Has self-loops: {data.has_self_loops()}')\n",
        "    print(f'Is undirected: {data.is_undirected()}')\n",
        "\n",
        "show_data_info(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SCU63MBvRc--"
      },
      "outputs": [],
      "source": [
        "# Obtendo maior componente\n",
        "from torch_geometric.transforms import LargestConnectedComponents\n",
        "import torch_geometric.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "7ci1ZAi7V4hq"
      },
      "outputs": [],
      "source": [
        "transform = LargestConnectedComponents()\n",
        "data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYl4MmsAbmC9",
        "outputId": "449ae33f-4224-4eb7-db20-bca805ad30f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 20905\n",
            "Number of edges: 29175810\n",
            "Average node degree: 1395.64\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "show_data_info(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_uJIrY-MFbZ"
      },
      "source": [
        "## Split dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "SRkGklaMMH7K"
      },
      "outputs": [],
      "source": [
        "def split_in_masks(data, test=0.3):\n",
        "    # resetting data split\n",
        "    split = T.RandomNodeSplit(num_test=test)\n",
        "    return split(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVQV7LXpU2ez"
      },
      "source": [
        "## GCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funções Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score, precision_score, recall_score, confusion_matrix\n",
        "from datetime import datetime\n",
        "\n",
        "def computes_metrics(target_labels, pred_labels):\n",
        "    accuracy = accuracy_score(target_labels, pred_labels)\n",
        "    f1 = f1_score(target_labels, pred_labels)\n",
        "    roc_auc = roc_auc_score(target_labels, pred_labels)\n",
        "    recall = recall_score(target_labels, pred_labels)\n",
        "    precision = precision_score(target_labels, pred_labels)\n",
        "    \n",
        "    return accuracy, precision, recall, f1, roc_auc\n",
        "\n",
        "def get_df_results(size, csv_name):\n",
        "    # Busca Df já escrito, caso não enconte, instancia um novo\n",
        "    df_results = None\n",
        "    try:\n",
        "        df_results = pd.read_csv(csv_name, sep=\",\", index_col=0)\n",
        "    except FileNotFoundError:\n",
        "        df_results = pd.DataFrame(data=np.zeros(size))\n",
        "    \n",
        "    return df_results\n",
        "\n",
        "def save_metrics(size, resultado, run):\n",
        "    # Mudar o nome para cada grupo de rn_runs\n",
        "    csv_name = \"./results/gcn_mx_runs\"\n",
        "\n",
        "    # Obtem Df results    \n",
        "    df_results = get_df_results(size, csv_name)\n",
        "\n",
        "    # Escreve as métricas na coluna run respectiva\n",
        "    df_results.iloc[:, run] = list(resultado)\n",
        "    \n",
        "    # Escreve df modificado\n",
        "    df_results.to_csv(csv_name)\n",
        "        \n",
        "def print_metrics(pred_labels, target_labels, loss, metrics_results, epoch):\n",
        "    print(f\"Pred: {pred_labels.sum()}, Actual: {target_labels.sum()}\")\n",
        "    print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}')\n",
        "    print(metrics_results)\n",
        "    print(\"-----------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "0uiNN_sgUTQX"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, 20)\n",
        "        self.conv2 = GCNConv(20, num_classes)\n",
        "        \n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "BsVRH4_pVJNR"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def predict(model, data, mask):\n",
        "    out = model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "    \n",
        "    pred_labels = pred[mask]\n",
        "    target_labels = data.y[mask]\n",
        "\n",
        "    return pred_labels, target_labels\n",
        "\n",
        "def train_epochs(model, data, optimizer, criterion, run, n_epochs=200, n_runs=10):\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "\n",
        "    splited_data = split_in_masks(data)\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train(model, splited_data, optimizer, criterion)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            pred_labels, target_labels = predict(model, splited_data, splited_data.test_mask)\n",
        "\n",
        "            metrics_results = computes_metrics(target_labels, pred_labels)\n",
        "            print_metrics(pred_labels, target_labels, loss, metrics_results, epoch)\n",
        "                \n",
        "    # Salva as métricas ao fim do treinamento de cada run\n",
        "    pred_labels, target_labels = predict(model, splited_data, splited_data.test_mask)\n",
        "    save_metrics((len(metrics), n_runs), metrics_results, run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "A7R7I-0WU5Ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred: 2380, Actual: 3040\n",
            "Epoch: 010, Train Loss: 0.483\n",
            "(0.810905612244898, 0.8894957983193277, 0.6963815789473684, 0.781180811808118, 0.8075039082855654)\n",
            "-----------------------------------------------\n",
            "Pred: 3655, Actual: 3040\n",
            "Epoch: 020, Train Loss: 0.368\n",
            "(0.8700573979591837, 0.8043775649794802, 0.9671052631578947, 0.8782673637042568, 0.8729400078165711)\n",
            "-----------------------------------------------\n",
            "Pred: 3509, Actual: 3040\n",
            "Epoch: 030, Train Loss: 0.333\n",
            "(0.8773915816326531, 0.8235964662296951, 0.9506578947368421, 0.8825774927469844, 0.8795678087545596)\n",
            "-----------------------------------------------\n",
            "Pred: 3342, Actual: 3040\n",
            "Epoch: 040, Train Loss: 0.314\n",
            "(0.8804209183673469, 0.8426092160383004, 0.9263157894736842, 0.8824819805703542, 0.8817841323606045)\n",
            "-----------------------------------------------\n",
            "Pred: 3399, Actual: 3040\n",
            "Epoch: 050, Train Loss: 0.310\n",
            "(0.8799426020408163, 0.8364224771991762, 0.9351973684210526, 0.8830563752135425, 0.8815838327253778)\n",
            "-----------------------------------------------\n",
            "Pred: 3361, Actual: 3040\n",
            "Epoch: 060, Train Loss: 0.309\n",
            "(0.8802614795918368, 0.8405236536745017, 0.9292763157894737, 0.8826745820965475, 0.8817173658155288)\n",
            "-----------------------------------------------\n",
            "Pred: 3382, Actual: 3040\n",
            "Epoch: 070, Train Loss: 0.308\n",
            "(0.8810586734693877, 0.8391484328799527, 0.9335526315789474, 0.883836810962317, 0.8826178999478895)\n",
            "-----------------------------------------------\n",
            "Pred: 3394, Actual: 3040\n",
            "Epoch: 080, Train Loss: 0.308\n",
            "(0.8816964285714286, 0.8385385975250442, 0.9361842105263158, 0.8846751631955238, 0.8833148775403856)\n",
            "-----------------------------------------------\n",
            "Pred: 3400, Actual: 3040\n",
            "Epoch: 090, Train Loss: 0.307\n",
            "(0.8820153061224489, 0.8382352941176471, 0.9375, 0.8850931677018633, 0.8836633663366337)\n",
            "-----------------------------------------------\n",
            "Pred: 3411, Actual: 3040\n",
            "Epoch: 100, Train Loss: 0.307\n",
            "(0.8818558673469388, 0.8369979478158898, 0.9391447368421053, 0.8851340877383351, 0.8835575169359041)\n",
            "-----------------------------------------------\n",
            "Pred: 3416, Actual: 3040\n",
            "Epoch: 110, Train Loss: 0.306\n",
            "(0.8820153061224489, 0.8366510538641686, 0.9401315789473684, 0.8853779429987608, 0.8837415320479416)\n",
            "-----------------------------------------------\n",
            "Pred: 3403, Actual: 3040\n",
            "Epoch: 120, Train Loss: 0.306\n",
            "(0.8818558673469388, 0.837790185130767, 0.937828947368421, 0.8849914636039112, 0.8835184340802501)\n",
            "-----------------------------------------------\n",
            "Pred: 3425, Actual: 3040\n",
            "Epoch: 130, Train Loss: 0.305\n",
            "(0.8828125, 0.8364963503649635, 0.9424342105263158, 0.8863109048723898, 0.8845834418968215)\n",
            "-----------------------------------------------\n",
            "Pred: 3420, Actual: 3040\n",
            "Epoch: 140, Train Loss: 0.305\n",
            "(0.8826530612244898, 0.8368421052631579, 0.9414473684210526, 0.8860681114551083, 0.8843994267847837)\n",
            "-----------------------------------------------\n",
            "Pred: 3460, Actual: 3040\n",
            "Epoch: 150, Train Loss: 0.304\n",
            "(0.8816964285714286, 0.8320809248554913, 0.9470394736842105, 0.8858461538461538, 0.8836373110995309)\n",
            "-----------------------------------------------\n",
            "Pred: 3451, Actual: 3040\n",
            "Epoch: 160, Train Loss: 0.304\n",
            "(0.8815369897959183, 0.8328020863517821, 0.9453947368421053, 0.8855338160529965, 0.8834337545596666)\n",
            "-----------------------------------------------\n",
            "Pred: 3432, Actual: 3040\n",
            "Epoch: 170, Train Loss: 0.304\n",
            "(0.8816964285714286, 0.8347902097902098, 0.9424342105263158, 0.885352286773795, 0.8835005211047422)\n",
            "-----------------------------------------------\n",
            "Pred: 3433, Actual: 3040\n",
            "Epoch: 180, Train Loss: 0.304\n",
            "(0.8815369897959183, 0.834547043402272, 0.9424342105263158, 0.8852155105824193, 0.8833458181344451)\n",
            "-----------------------------------------------\n",
            "Pred: 3458, Actual: 3040\n",
            "Epoch: 190, Train Loss: 0.303\n",
            "(0.8820153061224489, 0.8325621746674379, 0.9470394736842105, 0.8861188057863959, 0.8839467170401252)\n",
            "-----------------------------------------------\n",
            "Pred: 3436, Actual: 3040\n",
            "Epoch: 200, Train Loss: 0.303\n",
            "(0.8820153061224489, 0.8346915017462165, 0.9434210526315789, 0.8857319332921557, 0.8838392391870766)\n",
            "-----------------------------------------------\n",
            "Pred: 3718, Actual: 3139\n",
            "Epoch: 010, Train Loss: 0.518\n",
            "(0.8751594387755102, 0.8168370091447015, 0.967505575023893, 0.8858101210441884, 0.8750710128550682)\n",
            "-----------------------------------------------\n",
            "Pred: 3766, Actual: 3139\n",
            "Epoch: 020, Train Loss: 0.403\n",
            "(0.8713329081632653, 0.8096123207647371, 0.9713284485504938, 0.8831281679942071, 0.8712371575660225)\n",
            "-----------------------------------------------\n",
            "Pred: 3568, Actual: 3139\n",
            "Epoch: 030, Train Loss: 0.349\n",
            "(0.8847257653061225, 0.8385650224215246, 0.9531697992991398, 0.8922021768301776, 0.8846602268120339)\n",
            "-----------------------------------------------\n",
            "Pred: 3435, Actual: 3139\n",
            "Epoch: 040, Train Loss: 0.322\n",
            "(0.8874362244897959, 0.8541484716157205, 0.9346925772539025, 0.8926072406449649, 0.8873909742318029)\n",
            "-----------------------------------------------\n",
            "Pred: 3384, Actual: 3139\n",
            "Epoch: 050, Train Loss: 0.314\n",
            "(0.8891900510204082, 0.8611111111111112, 0.9283211213762345, 0.893453932239767, 0.8891525811158223)\n",
            "-----------------------------------------------\n",
            "Pred: 3384, Actual: 3139\n",
            "Epoch: 060, Train Loss: 0.313\n",
            "(0.8895089285714286, 0.8614066193853428, 0.9286396941701178, 0.8937605396290051, 0.8894714589586625)\n",
            "-----------------------------------------------\n",
            "Pred: 3382, Actual: 3139\n",
            "Epoch: 070, Train Loss: 0.313\n",
            "(0.8891900510204082, 0.861324659964518, 0.9280025485823511, 0.893421254408833, 0.889152886164779)\n",
            "-----------------------------------------------\n",
            "Pred: 3389, Actual: 3139\n",
            "Epoch: 080, Train Loss: 0.312\n",
            "(0.8887117346938775, 0.8601357332546474, 0.9286396941701178, 0.893075980392157, 0.8886735017291699)\n",
            "-----------------------------------------------\n",
            "Pred: 3405, Actual: 3139\n",
            "Epoch: 090, Train Loss: 0.311\n",
            "(0.8887117346938775, 0.8584434654919236, 0.9311882765211851, 0.8933374083129585, 0.8886710613375157)\n",
            "-----------------------------------------------\n",
            "Pred: 3413, Actual: 3139\n",
            "Epoch: 100, Train Loss: 0.311\n",
            "(0.8887117346938775, 0.8576032815704658, 0.9324625676967186, 0.8934676434676435, 0.8886698411416883)\n",
            "-----------------------------------------------\n",
            "Pred: 3416, Actual: 3139\n",
            "Epoch: 110, Train Loss: 0.310\n",
            "(0.8888711734693877, 0.8574355971896955, 0.9330997132844855, 0.893668954996186, 0.8888288224896733)\n",
            "-----------------------------------------------\n",
            "Pred: 3394, Actual: 3139\n",
            "Epoch: 120, Train Loss: 0.310\n",
            "(0.8891900510204082, 0.8600471420153212, 0.9299139853456515, 0.8936170212765958, 0.8891510558710383)\n",
            "-----------------------------------------------\n",
            "Pred: 3432, Actual: 3139\n",
            "Epoch: 130, Train Loss: 0.309\n",
            "(0.8895089285714286, 0.8563519813519813, 0.9362854412233196, 0.8945366002130574, 0.8894641377836994)\n",
            "-----------------------------------------------\n",
            "Pred: 3418, Actual: 3139\n",
            "Epoch: 140, Train Loss: 0.308\n",
            "(0.8895089285714286, 0.8578115857226448, 0.9340554316661357, 0.8943114229068171, 0.8894662731263969)\n",
            "-----------------------------------------------\n",
            "Pred: 3475, Actual: 3139\n",
            "Epoch: 150, Train Loss: 0.308\n",
            "(0.8877551020408163, 0.8503597122302158, 0.941382605925454, 0.8935591170244934, 0.8877037510955071)\n",
            "-----------------------------------------------\n",
            "Pred: 3467, Actual: 3139\n",
            "Epoch: 160, Train Loss: 0.307\n",
            "(0.8877551020408163, 0.8511681569079896, 0.9401083147499204, 0.8934302149561006, 0.8877049712913342)\n",
            "-----------------------------------------------\n",
            "Pred: 3445, Actual: 3139\n",
            "Epoch: 170, Train Loss: 0.307\n",
            "(0.889030612244898, 0.8545718432510885, 0.9378783051927365, 0.8942891859052248, 0.8889838382012198)\n",
            "-----------------------------------------------\n",
            "Pred: 3452, Actual: 3139\n",
            "Epoch: 180, Train Loss: 0.306\n",
            "(0.8888711734693877, 0.8537079953650057, 0.9388340235743867, 0.8942497344864209, 0.8888233316084511)\n",
            "-----------------------------------------------\n",
            "Pred: 3464, Actual: 3139\n",
            "Epoch: 190, Train Loss: 0.306\n",
            "(0.8888711734693877, 0.8524826789838337, 0.9407454603376871, 0.8944419203392396, 0.8888215013147102)\n",
            "-----------------------------------------------\n",
            "Pred: 3419, Actual: 3139\n",
            "Epoch: 200, Train Loss: 0.306\n",
            "(0.8880739795918368, 0.8563907575314419, 0.9327811404906021, 0.8929551692589204, 0.8880311703091377)\n",
            "-----------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "i:\\Anaconda\\envs\\covid_es_gnn\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred: 0, Actual: 3072\n",
            "Epoch: 010, Train Loss: 1.241\n",
            "(0.5102040816326531, 0.0, 0.0, 0.0, 0.5)\n",
            "-----------------------------------------------\n",
            "Pred: 10, Actual: 3072\n",
            "Epoch: 020, Train Loss: 0.604\n",
            "(0.5117984693877551, 1.0, 0.0032552083333333335, 0.006489292667099287, 0.5016276041666666)\n",
            "-----------------------------------------------\n",
            "Pred: 3557, Actual: 3072\n",
            "Epoch: 030, Train Loss: 0.492\n",
            "(0.8805803571428571, 0.8265392184425078, 0.95703125, 0.8870116156283, 0.882109375)\n",
            "-----------------------------------------------\n",
            "Pred: 3422, Actual: 3072\n",
            "Epoch: 040, Train Loss: 0.408\n",
            "(0.8887117346938775, 0.8468731735827002, 0.943359375, 0.8925161687711735, 0.8898046874999999)\n",
            "-----------------------------------------------\n",
            "Pred: 3420, Actual: 3072\n",
            "Epoch: 050, Train Loss: 0.361\n",
            "(0.889030612244898, 0.8473684210526315, 0.943359375, 0.8927911275415896, 0.8901171875)\n",
            "-----------------------------------------------\n",
            "Pred: 3406, Actual: 3072\n",
            "Epoch: 060, Train Loss: 0.333\n",
            "(0.8887117346938775, 0.8485026423957722, 0.9407552083333334, 0.8922506946588454, 0.8897526041666668)\n",
            "-----------------------------------------------\n",
            "Pred: 3415, Actual: 3072\n",
            "Epoch: 070, Train Loss: 0.321\n",
            "(0.8885522959183674, 0.8474377745241581, 0.9420572916666666, 0.8922460305225837, 0.8896223958333332)\n",
            "-----------------------------------------------\n",
            "Pred: 3418, Actual: 3072\n",
            "Epoch: 080, Train Loss: 0.316\n",
            "(0.8880739795918368, 0.8466939730836747, 0.9420572916666666, 0.891833590138675, 0.8891536458333332)\n",
            "-----------------------------------------------\n",
            "Pred: 3388, Actual: 3072\n",
            "Epoch: 090, Train Loss: 0.315\n",
            "(0.8899872448979592, 0.851534828807556, 0.9391276041666666, 0.8931888544891641, 0.8909700520833332)\n",
            "-----------------------------------------------\n",
            "Pred: 3396, Actual: 3072\n",
            "Epoch: 100, Train Loss: 0.314\n",
            "(0.8896683673469388, 0.850412249705536, 0.9401041666666666, 0.8930117501546073, 0.8906770833333333)\n",
            "-----------------------------------------------\n",
            "Pred: 3389, Actual: 3072\n",
            "Epoch: 110, Train Loss: 0.313\n",
            "(0.8901466836734694, 0.8515786367660076, 0.939453125, 0.8933601609657947, 0.8911328125)\n",
            "-----------------------------------------------\n",
            "Pred: 3394, Actual: 3072\n",
            "Epoch: 120, Train Loss: 0.313\n",
            "(0.8903061224489796, 0.8512080141426046, 0.9404296875, 0.8935972780699041, 0.89130859375)\n",
            "-----------------------------------------------\n",
            "Pred: 3400, Actual: 3072\n",
            "Epoch: 130, Train Loss: 0.313\n",
            "(0.8903061224489796, 0.8505882352941176, 0.94140625, 0.8936959208899877, 0.8913281250000001)\n",
            "-----------------------------------------------\n",
            "Pred: 3409, Actual: 3072\n",
            "Epoch: 140, Train Loss: 0.312\n",
            "(0.8904655612244898, 0.8498093282487533, 0.9430338541666666, 0.8939978398395309, 0.8915169270833332)\n",
            "-----------------------------------------------\n",
            "Pred: 3415, Actual: 3072\n",
            "Epoch: 150, Train Loss: 0.312\n",
            "(0.8901466836734694, 0.8489019033674964, 0.9436848958333334, 0.8937875751503006, 0.8912174479166667)\n",
            "-----------------------------------------------\n",
            "Pred: 3426, Actual: 3072\n",
            "Epoch: 160, Train Loss: 0.312\n",
            "(0.8896683673469388, 0.847343841214244, 0.9449869791666666, 0.8935056940597107, 0.8907747395833333)\n",
            "-----------------------------------------------\n",
            "Pred: 3425, Actual: 3072\n",
            "Epoch: 170, Train Loss: 0.311\n",
            "(0.8898278061224489, 0.8475912408759124, 0.9449869791666666, 0.8936432199476682, 0.8909309895833333)\n",
            "-----------------------------------------------\n",
            "Pred: 3408, Actual: 3072\n",
            "Epoch: 180, Train Loss: 0.311\n",
            "(0.8896683673469388, 0.8491784037558685, 0.9420572916666666, 0.8932098765432098, 0.8907161458333333)\n",
            "-----------------------------------------------\n",
            "Pred: 3430, Actual: 3072\n",
            "Epoch: 190, Train Loss: 0.310\n",
            "(0.8899872448979592, 0.8472303206997085, 0.9459635416666666, 0.8938788065210703, 0.8911067708333332)\n",
            "-----------------------------------------------\n",
            "Pred: 3429, Actual: 3072\n",
            "Epoch: 200, Train Loss: 0.310\n",
            "(0.8898278061224489, 0.847185768445611, 0.9456380208333334, 0.8937086602061223, 0.8909440104166666)\n",
            "-----------------------------------------------\n",
            "Pred: 6259, Actual: 3044\n",
            "Epoch: 010, Train Loss: 0.834\n",
            "(0.48740433673469385, 0.48633967087394153, 1.0, 0.6544125550897559, 0.5020136307311028)\n",
            "-----------------------------------------------\n",
            "Pred: 4050, Actual: 3044\n",
            "Epoch: 020, Train Loss: 0.541\n",
            "(0.8246173469387755, 0.74, 0.9845597897503285, 0.8449393853961095, 0.8291758056558335)\n",
            "-----------------------------------------------\n",
            "Pred: 3703, Actual: 3044\n",
            "Epoch: 030, Train Loss: 0.426\n",
            "(0.865593112244898, 0.7971914663786119, 0.9697766097240473, 0.8750555802578924, 0.8685624064729283)\n",
            "-----------------------------------------------\n",
            "Pred: 3541, Actual: 3044\n",
            "Epoch: 040, Train Loss: 0.365\n",
            "(0.8773915816326531, 0.8212369387178763, 0.9553219448094612, 0.8832194381169324, 0.8796126452671841)\n",
            "-----------------------------------------------\n",
            "Pred: 3460, Actual: 3044\n",
            "Epoch: 050, Train Loss: 0.335\n",
            "(0.8820153061224489, 0.8329479768786127, 0.9467805519053877, 0.8862238622386224, 0.8838611557544286)\n",
            "-----------------------------------------------\n",
            "Pred: 3409, Actual: 3044\n",
            "Epoch: 060, Train Loss: 0.321\n",
            "(0.8828125, 0.8386623643297154, 0.9392247043363995, 0.8860994886099489, 0.8844202827753869)\n",
            "-----------------------------------------------\n",
            "Pred: 3378, Actual: 3044\n",
            "Epoch: 070, Train Loss: 0.315\n",
            "(0.8848852040816326, 0.8436944937833037, 0.9362680683311432, 0.8875739644970414, 0.8863496475484712)\n",
            "-----------------------------------------------\n",
            "Pred: 3353, Actual: 3044\n",
            "Epoch: 080, Train Loss: 0.312\n",
            "(0.8847257653061225, 0.8461079630181927, 0.9319973718791065, 0.8869782710645615, 0.8860730353819325)\n",
            "-----------------------------------------------\n",
            "Pred: 3351, Actual: 3044\n",
            "Epoch: 090, Train Loss: 0.311\n",
            "(0.884406887755102, 0.8460161145926589, 0.9313403416557161, 0.8866301798279906, 0.8857445202702372)\n",
            "-----------------------------------------------\n",
            "Pred: 3352, Actual: 3044\n",
            "Epoch: 100, Train Loss: 0.310\n",
            "(0.8845663265306123, 0.8460620525059666, 0.9316688567674113, 0.8868042526579111, 0.8859087778260849)\n",
            "-----------------------------------------------\n",
            "Pred: 3355, Actual: 3044\n",
            "Epoch: 110, Train Loss: 0.310\n",
            "(0.884406887755102, 0.8456035767511177, 0.9319973718791065, 0.8867010470385998, 0.8857632460386858)\n",
            "-----------------------------------------------\n",
            "Pred: 3357, Actual: 3044\n",
            "Epoch: 120, Train Loss: 0.309\n",
            "(0.8837691326530612, 0.8448019064641048, 0.9316688567674113, 0.8861115450710826, 0.8851343044679683)\n",
            "-----------------------------------------------\n",
            "Pred: 3360, Actual: 3044\n",
            "Epoch: 130, Train Loss: 0.309\n",
            "(0.8839285714285714, 0.8446428571428571, 0.9323258869908015, 0.8863210493441599, 0.8853079249080402)\n",
            "-----------------------------------------------\n",
            "Pred: 3365, Actual: 3044\n",
            "Epoch: 140, Train Loss: 0.309\n",
            "(0.884406887755102, 0.8445765230312036, 0.9336399474375822, 0.8868778280542986, 0.8858100604598071)\n",
            "-----------------------------------------------\n",
            "Pred: 3373, Actual: 3044\n",
            "Epoch: 150, Train Loss: 0.308\n",
            "(0.8840880102040817, 0.8434627927660836, 0.9346254927726675, 0.8867071840423874, 0.8855283597692335)\n",
            "-----------------------------------------------\n",
            "Pred: 3382, Actual: 3044\n",
            "Epoch: 160, Train Loss: 0.308\n",
            "(0.8848852040816326, 0.8432879952690716, 0.9369250985545335, 0.8876439464674759, 0.8863683733169198)\n",
            "-----------------------------------------------\n",
            "Pred: 3383, Actual: 3044\n",
            "Epoch: 170, Train Loss: 0.308\n",
            "(0.8850446428571429, 0.843334318652084, 0.9372536136662286, 0.8878170219386962, 0.8865326308727673)\n",
            "-----------------------------------------------\n",
            "Pred: 3387, Actual: 3044\n",
            "Epoch: 180, Train Loss: 0.307\n",
            "(0.884406887755102, 0.8423383525243578, 0.9372536136662286, 0.887264811071373, 0.8859130521862741)\n",
            "-----------------------------------------------\n",
            "Pred: 3388, Actual: 3044\n",
            "Epoch: 190, Train Loss: 0.307\n",
            "(0.8845663265306123, 0.8423848878394333, 0.9375821287779238, 0.8874378109452736, 0.8860773097421216)\n",
            "-----------------------------------------------\n",
            "Pred: 3390, Actual: 3044\n",
            "Epoch: 200, Train Loss: 0.307\n",
            "(0.8845663265306123, 0.8421828908554573, 0.937910643889619, 0.8874728007460367, 0.886086672626346)\n",
            "-----------------------------------------------\n",
            "Pred: 38, Actual: 3055\n",
            "Epoch: 010, Train Loss: 0.625\n",
            "(0.5186543367346939, 0.9736842105263158, 0.012111292962356792, 0.023924991917232463, 0.5059002221728166)\n",
            "-----------------------------------------------\n",
            "Pred: 3467, Actual: 3055\n",
            "Epoch: 020, Train Loss: 0.438\n",
            "(0.8778698979591837, 0.8301124891837324, 0.9420621931260229, 0.8825513646120822, 0.8794861789378948)\n",
            "-----------------------------------------------\n",
            "Pred: 3497, Actual: 3055\n",
            "Epoch: 030, Train Loss: 0.367\n",
            "(0.8794642857142857, 0.828710323134115, 0.9486088379705401, 0.8846153846153846, 0.8812052582765353)\n",
            "-----------------------------------------------\n",
            "Pred: 3502, Actual: 3055\n",
            "Epoch: 040, Train Loss: 0.335\n",
            "(0.8793048469387755, 0.8280982295830954, 0.9492635024549918, 0.8845508616745462, 0.8810663175936756)\n",
            "-----------------------------------------------\n",
            "Pred: 3368, Actual: 3055\n",
            "Epoch: 050, Train Loss: 0.320\n",
            "(0.8821747448979592, 0.8438242280285035, 0.930278232405892, 0.8849447298770046, 0.8833859300046246)\n",
            "-----------------------------------------------\n",
            "Pred: 3332, Actual: 3055\n",
            "Epoch: 060, Train Loss: 0.315\n",
            "(0.8828125, 0.8481392557022809, 0.9250409165302782, 0.8849224988257398, 0.8838757582340542)\n",
            "-----------------------------------------------\n",
            "Pred: 3339, Actual: 3055\n",
            "Epoch: 070, Train Loss: 0.314\n",
            "(0.8823341836734694, 0.8469601677148847, 0.9256955810147299, 0.8845792930872692, 0.8834259689344709)\n",
            "-----------------------------------------------\n",
            "Pred: 3341, Actual: 3055\n",
            "Epoch: 080, Train Loss: 0.313\n",
            "(0.8829719387755102, 0.8473510924872792, 0.9266775777414076, 0.885240775484678, 0.8840723916061717)\n",
            "-----------------------------------------------\n",
            "Pred: 3325, Actual: 3055\n",
            "Epoch: 090, Train Loss: 0.312\n",
            "(0.8816964285714286, 0.8478195488721805, 0.9227495908346972, 0.8836990595611286, 0.8827300953862638)\n",
            "-----------------------------------------------\n",
            "Pred: 3343, Actual: 3055\n",
            "Epoch: 100, Train Loss: 0.312\n",
            "(0.8826530612244898, 0.846844151959318, 0.9266775777414076, 0.8849640512660206, 0.8837615429894481)\n",
            "-----------------------------------------------\n",
            "Pred: 3356, Actual: 3055\n",
            "Epoch: 110, Train Loss: 0.311\n",
            "(0.8834502551020408, 0.8462455303933254, 0.9296235679214403, 0.8859772266417095, 0.884612840846017)\n",
            "-----------------------------------------------\n",
            "Pred: 3360, Actual: 3055\n",
            "Epoch: 120, Train Loss: 0.311\n",
            "(0.8831313775510204, 0.8455357142857143, 0.9299509001636661, 0.8857365549493375, 0.8843102340420445)\n",
            "-----------------------------------------------\n",
            "Pred: 3365, Actual: 3055\n",
            "Epoch: 130, Train Loss: 0.310\n",
            "(0.8832908163265306, 0.8451708766716196, 0.9309328968903438, 0.885981308411215, 0.8844903837886595)\n",
            "-----------------------------------------------\n",
            "Pred: 3368, Actual: 3055\n",
            "Epoch: 140, Train Loss: 0.310\n",
            "(0.8837691326530612, 0.8453087885985748, 0.9319148936170213, 0.8865016347501168, 0.8849813821519982)\n",
            "-----------------------------------------------\n",
            "Pred: 3371, Actual: 3055\n",
            "Epoch: 150, Train Loss: 0.310\n",
            "(0.8842474489795918, 0.8454464550578463, 0.9328968903436988, 0.8870214752567693, 0.885472380515337)\n",
            "-----------------------------------------------\n",
            "Pred: 3371, Actual: 3055\n",
            "Epoch: 160, Train Loss: 0.309\n",
            "(0.8842474489795918, 0.8454464550578463, 0.9328968903436988, 0.8870214752567693, 0.885472380515337)\n",
            "-----------------------------------------------\n",
            "Pred: 3373, Actual: 3055\n",
            "Epoch: 170, Train Loss: 0.309\n",
            "(0.8839285714285714, 0.8449451526830715, 0.9328968903436988, 0.8867454884878656, 0.8851615318986135)\n",
            "-----------------------------------------------\n",
            "Pred: 3379, Actual: 3055\n",
            "Epoch: 180, Train Loss: 0.309\n",
            "(0.8842474489795918, 0.8446285883397455, 0.9342062193126023, 0.887161952129313, 0.8855053477663416)\n",
            "-----------------------------------------------\n",
            "Pred: 3383, Actual: 3055\n",
            "Epoch: 190, Train Loss: 0.308\n",
            "(0.8842474489795918, 0.8442211055276382, 0.934860883797054, 0.8872320596458527, 0.8855218313918438)\n",
            "-----------------------------------------------\n",
            "Pred: 3388, Actual: 3055\n",
            "Epoch: 200, Train Loss: 0.308\n",
            "(0.884406887755102, 0.8438606847697757, 0.9358428805237315, 0.8874747788297378, 0.8857019811384589)\n",
            "-----------------------------------------------\n",
            "Pred: 6272, Actual: 3065\n",
            "Epoch: 010, Train Loss: 1.788\n",
            "(0.48867984693877553, 0.48867984693877553, 1.0, 0.6565277926528864, 0.5)\n",
            "-----------------------------------------------\n",
            "Pred: 57, Actual: 3065\n",
            "Epoch: 020, Train Loss: 0.794\n",
            "(0.5181760204081632, 0.8771929824561403, 0.01631321370309951, 0.032030749519538756, 0.5070652442073339)\n",
            "-----------------------------------------------\n",
            "Pred: 12, Actual: 3065\n",
            "Epoch: 030, Train Loss: 0.616\n",
            "(0.5132334183673469, 1.0, 0.003915171288743882, 0.007799805004874877, 0.501957585644372)\n",
            "-----------------------------------------------\n",
            "Pred: 3261, Actual: 3065\n",
            "Epoch: 040, Train Loss: 0.476\n",
            "(0.8899872448979592, 0.8641521005826434, 0.9194127243066884, 0.8909263357571926, 0.8906386976694028)\n",
            "-----------------------------------------------\n",
            "Pred: 3486, Actual: 3065\n",
            "Epoch: 050, Train Loss: 0.394\n",
            "(0.8860012755102041, 0.8370625358577166, 0.9520391517128874, 0.8908563578079683, 0.887463292725792)\n",
            "-----------------------------------------------\n",
            "Pred: 3367, Actual: 3065\n",
            "Epoch: 060, Train Loss: 0.337\n",
            "(0.8903061224489796, 0.8529848529848529, 0.9370309951060359, 0.8930348258706466, 0.8913405677120451)\n",
            "-----------------------------------------------\n",
            "Pred: 3356, Actual: 3065\n",
            "Epoch: 070, Train Loss: 0.318\n",
            "(0.8904655612244898, 0.8542908224076281, 0.935399673735726, 0.8930073197321289, 0.8914603607219321)\n",
            "-----------------------------------------------\n",
            "Pred: 3319, Actual: 3065\n",
            "Epoch: 080, Train Loss: 0.317\n",
            "(0.890625, 0.8583910816510997, 0.9295269168026101, 0.8925438596491228, 0.8914862522896743)\n",
            "-----------------------------------------------\n",
            "Pred: 3309, Actual: 3065\n",
            "Epoch: 090, Train Loss: 0.317\n",
            "(0.8909438775510204, 0.8597763674826231, 0.9282218597063622, 0.8926890492626294, 0.8917691774365925)\n",
            "-----------------------------------------------\n",
            "Pred: 3312, Actual: 3065\n",
            "Epoch: 100, Train Loss: 0.316\n",
            "(0.8911033163265306, 0.8596014492753623, 0.9288743882544861, 0.8928963462443155, 0.8919395327614806)\n",
            "-----------------------------------------------\n",
            "Pred: 3314, Actual: 3065\n",
            "Epoch: 110, Train Loss: 0.316\n",
            "(0.8914221938775511, 0.8596861798430899, 0.9295269168026101, 0.8932434550870043, 0.8922657970355427)\n",
            "-----------------------------------------------\n",
            "Pred: 3318, Actual: 3065\n",
            "Epoch: 120, Train Loss: 0.315\n",
            "(0.8914221938775511, 0.8592525617842074, 0.930179445350734, 0.8933103556321479, 0.8922802434112572)\n",
            "-----------------------------------------------\n",
            "Pred: 3324, Actual: 3065\n",
            "Epoch: 130, Train Loss: 0.315\n",
            "(0.8917410714285714, 0.8589049338146811, 0.9314845024469821, 0.893723587415871, 0.8926209540610338)\n",
            "-----------------------------------------------\n",
            "Pred: 3327, Actual: 3065\n",
            "Epoch: 140, Train Loss: 0.315\n",
            "(0.8915816326530612, 0.8584310189359784, 0.931810766721044, 0.8936170212765957, 0.8924722682997175)\n",
            "-----------------------------------------------\n",
            "Pred: 3327, Actual: 3065\n",
            "Epoch: 150, Train Loss: 0.314\n",
            "(0.8912627551020408, 0.8581304478509167, 0.9314845024469821, 0.8933041301627034, 0.8921532272135129)\n",
            "-----------------------------------------------\n",
            "Pred: 3327, Actual: 3065\n",
            "Epoch: 160, Train Loss: 0.314\n",
            "(0.8915816326530612, 0.8584310189359784, 0.931810766721044, 0.8936170212765957, 0.8924722682997175)\n",
            "-----------------------------------------------\n",
            "Pred: 3331, Actual: 3065\n",
            "Epoch: 170, Train Loss: 0.314\n",
            "(0.892219387755102, 0.8586010207145002, 0.933115823817292, 0.8943089430894309, 0.8931247968478414)\n",
            "-----------------------------------------------\n",
            "Pred: 3330, Actual: 3065\n",
            "Epoch: 180, Train Loss: 0.314\n",
            "(0.8917410714285714, 0.8582582582582583, 0.932463295269168, 0.8938232994526975, 0.8926426236246059)\n",
            "-----------------------------------------------\n",
            "Pred: 3330, Actual: 3065\n",
            "Epoch: 190, Train Loss: 0.313\n",
            "(0.8914221938775511, 0.8579579579579579, 0.932137030995106, 0.8935105551211885, 0.8923235825384012)\n",
            "-----------------------------------------------\n",
            "Pred: 3329, Actual: 3065\n",
            "Epoch: 200, Train Loss: 0.313\n",
            "(0.8915816326530612, 0.8582156803844998, 0.932137030995106, 0.8936502971535815, 0.8924794914875749)\n",
            "-----------------------------------------------\n",
            "Pred: 6272, Actual: 3116\n",
            "Epoch: 010, Train Loss: 1.533\n",
            "(0.4968112244897959, 0.4968112244897959, 1.0, 0.663826161056668, 0.5)\n",
            "-----------------------------------------------\n",
            "Pred: 3954, Actual: 3116\n",
            "Epoch: 020, Train Loss: 0.709\n",
            "(0.8485331632653061, 0.7738998482549317, 0.982028241335045, 0.8656294200848657, 0.8493791396789292)\n",
            "-----------------------------------------------\n",
            "Pred: 17, Actual: 3116\n",
            "Epoch: 030, Train Loss: 0.629\n",
            "(0.5058992346938775, 1.0, 0.0054557124518613605, 0.01085221832109799, 0.5027278562259306)\n",
            "-----------------------------------------------\n",
            "Pred: 3477, Actual: 3116\n",
            "Epoch: 040, Train Loss: 0.490\n",
            "(0.8898278061224489, 0.8487201610583837, 0.9470474967907574, 0.8951918701653269, 0.8901904150620454)\n",
            "-----------------------------------------------\n",
            "Pred: 3685, Actual: 3116\n",
            "Epoch: 050, Train Loss: 0.432\n",
            "(0.8805803571428571, 0.8211668928086838, 0.9711168164313222, 0.8898691368916336, 0.8811540989634431)\n",
            "-----------------------------------------------\n",
            "Pred: 3580, Actual: 3116\n",
            "Epoch: 060, Train Loss: 0.375\n",
            "(0.8858418367346939, 0.835195530726257, 0.959563543003851, 0.8930704898446833, 0.8863090211850688)\n",
            "-----------------------------------------------\n",
            "Pred: 3495, Actual: 3116\n",
            "Epoch: 070, Train Loss: 0.341\n",
            "(0.8885522959183674, 0.8457796852646638, 0.9486521181001284, 0.8942671305400091, 0.8889331566419526)\n",
            "-----------------------------------------------\n",
            "Pred: 3439, Actual: 3116\n",
            "Epoch: 080, Train Loss: 0.324\n",
            "(0.8888711734693877, 0.8517010758941552, 0.939987163029525, 0.8936689549961861, 0.8891951024273099)\n",
            "-----------------------------------------------\n",
            "Pred: 3368, Actual: 3116\n",
            "Epoch: 090, Train Loss: 0.317\n",
            "(0.8893494897959183, 0.8595605700712589, 0.9290757381258024, 0.8929673041332512, 0.8896012404190482)\n",
            "-----------------------------------------------\n",
            "Pred: 3360, Actual: 3116\n",
            "Epoch: 100, Train Loss: 0.314\n",
            "(0.8880739795918368, 0.8592261904761904, 0.9265083440308087, 0.8915997529339098, 0.8883175433715514)\n",
            "-----------------------------------------------\n",
            "Pred: 3351, Actual: 3116\n",
            "Epoch: 110, Train Loss: 0.313\n",
            "(0.8875956632653061, 0.8597433601909877, 0.9245827984595636, 0.890985000773156, 0.8878300557570316)\n",
            "-----------------------------------------------\n",
            "Pred: 3368, Actual: 3116\n",
            "Epoch: 120, Train Loss: 0.312\n",
            "(0.8887117346938775, 0.8589667458432304, 0.9284338896020539, 0.892350400987045, 0.8889634593764388)\n",
            "-----------------------------------------------\n",
            "Pred: 3371, Actual: 3116\n",
            "Epoch: 130, Train Loss: 0.311\n",
            "(0.8891900510204082, 0.8590922574903589, 0.9293966623876765, 0.8928626483736705, 0.8894448457692501)\n",
            "-----------------------------------------------\n",
            "Pred: 3382, Actual: 3116\n",
            "Epoch: 140, Train Loss: 0.311\n",
            "(0.8899872448979592, 0.8586635127143702, 0.9319640564826701, 0.8938134810710988, 0.8902532576456443)\n",
            "-----------------------------------------------\n",
            "Pred: 3396, Actual: 3116\n",
            "Epoch: 150, Train Loss: 0.310\n",
            "(0.890625, 0.857773851590106, 0.9348523748395379, 0.8946560196560197, 0.8909052748722404)\n",
            "-----------------------------------------------\n",
            "Pred: 3371, Actual: 3116\n",
            "Epoch: 160, Train Loss: 0.309\n",
            "(0.8898278061224489, 0.8596855532482943, 0.9300385109114249, 0.8934792662247573, 0.8900826268118593)\n",
            "-----------------------------------------------\n",
            "Pred: 3382, Actual: 3116\n",
            "Epoch: 170, Train Loss: 0.308\n",
            "(0.8903061224489796, 0.8589591957421644, 0.9322849807445442, 0.8941212680824868, 0.8905721481669489)\n",
            "-----------------------------------------------\n",
            "Pred: 3389, Actual: 3116\n",
            "Epoch: 180, Train Loss: 0.307\n",
            "(0.8911033163265306, 0.8589554440838005, 0.9342105263157895, 0.8950038431975402, 0.891376492562204)\n",
            "-----------------------------------------------\n",
            "Pred: 3413, Actual: 3116\n",
            "Epoch: 190, Train Loss: 0.307\n",
            "(0.8914221938775511, 0.8567242894813947, 0.938382541720154, 0.8956961249808547, 0.8917197879703431)\n",
            "-----------------------------------------------\n",
            "Pred: 3410, Actual: 3116\n",
            "Epoch: 200, Train Loss: 0.306\n",
            "(0.8912627551020408, 0.8568914956011731, 0.9377406931964056, 0.8954949433037082, 0.8915572920988364)\n",
            "-----------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "i:\\Anaconda\\envs\\covid_es_gnn\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred: 0, Actual: 3053\n",
            "Epoch: 010, Train Loss: 2.379\n",
            "(0.5132334183673469, 0.0, 0.0, 0.0, 0.5)\n",
            "-----------------------------------------------\n",
            "Pred: 6236, Actual: 3053\n",
            "Epoch: 020, Train Loss: 1.080\n",
            "(0.4921875, 0.4894162924951892, 0.9996724533245988, 0.6571213262999246, 0.5052726976160117)\n",
            "-----------------------------------------------\n",
            "Pred: 3648, Actual: 3053\n",
            "Epoch: 030, Train Loss: 0.392\n",
            "(0.8665497448979592, 0.8037280701754386, 0.9603668522764494, 0.8750932696612446, 0.8689687631994238)\n",
            "-----------------------------------------------\n",
            "Pred: 3190, Actual: 3053\n",
            "Epoch: 040, Train Loss: 0.381\n",
            "(0.8706951530612245, 0.8514106583072101, 0.8896167703897806, 0.8700945058465482, 0.8711830357074719)\n",
            "-----------------------------------------------\n",
            "Pred: 3309, Actual: 3053\n",
            "Epoch: 050, Train Loss: 0.361\n",
            "(0.8791454081632653, 0.8467815049864007, 0.9177857844742876, 0.8808550770198051, 0.8801417272790824)\n",
            "-----------------------------------------------\n",
            "Pred: 3368, Actual: 3053\n",
            "Epoch: 060, Train Loss: 0.343\n",
            "(0.8815369897959183, 0.8429334916864608, 0.9299050114641336, 0.8842859367699736, 0.8827841304602433)\n",
            "-----------------------------------------------\n",
            "Pred: 3389, Actual: 3053\n",
            "Epoch: 070, Train Loss: 0.329\n",
            "(0.8807397959183674, 0.8400708173502508, 0.9325253848673436, 0.8838869916175102, 0.8820750565218979)\n",
            "-----------------------------------------------\n",
            "Pred: 3384, Actual: 3053\n",
            "Epoch: 080, Train Loss: 0.320\n",
            "(0.881218112244898, 0.8410165484633569, 0.9321978381919424, 0.8842628553674072, 0.8825325941503359)\n",
            "-----------------------------------------------\n",
            "Pred: 3337, Actual: 3053\n",
            "Epoch: 090, Train Loss: 0.316\n",
            "(0.8826530612244898, 0.8471681150734193, 0.9259744513593187, 0.8848200312989045, 0.8837700774969939)\n",
            "-----------------------------------------------\n",
            "Pred: 3343, Actual: 3053\n",
            "Epoch: 100, Train Loss: 0.315\n",
            "(0.8823341836734694, 0.846245886927909, 0.9266295447101212, 0.8846153846153846, 0.8834763132062566)\n",
            "-----------------------------------------------\n",
            "Pred: 3329, Actual: 3053\n",
            "Epoch: 110, Train Loss: 0.314\n",
            "(0.8823341836734694, 0.8477020126164013, 0.9243367179823124, 0.8843622688812285, 0.8834171940330948)\n",
            "-----------------------------------------------\n",
            "Pred: 3339, Actual: 3053\n",
            "Epoch: 120, Train Loss: 0.314\n",
            "(0.8816964285714286, 0.8460616951182989, 0.9253193580085162, 0.8839173967459323, 0.8828212198554541)\n",
            "-----------------------------------------------\n",
            "Pred: 3338, Actual: 3053\n",
            "Epoch: 130, Train Loss: 0.313\n",
            "(0.8818558673469388, 0.8463151587777112, 0.9253193580085162, 0.8840557033328118, 0.8829765475969886)\n",
            "-----------------------------------------------\n",
            "Pred: 3335, Actual: 3053\n",
            "Epoch: 140, Train Loss: 0.313\n",
            "(0.8820153061224489, 0.846776611694153, 0.9249918113331149, 0.8841577958672511, 0.8831234297423574)\n",
            "-----------------------------------------------\n",
            "Pred: 3336, Actual: 3053\n",
            "Epoch: 150, Train Loss: 0.312\n",
            "(0.8821747448979592, 0.8468225419664268, 0.9253193580085162, 0.8843324463922366, 0.883287203080058)\n",
            "-----------------------------------------------\n",
            "Pred: 3334, Actual: 3053\n",
            "Epoch: 160, Train Loss: 0.312\n",
            "(0.8818558673469388, 0.8467306538692262, 0.9246642646577137, 0.8839830906528887, 0.8829596564046568)\n",
            "-----------------------------------------------\n",
            "Pred: 3338, Actual: 3053\n",
            "Epoch: 170, Train Loss: 0.312\n",
            "(0.8818558673469388, 0.8463151587777112, 0.9253193580085162, 0.8840557033328118, 0.8829765475969886)\n",
            "-----------------------------------------------\n",
            "Pred: 3362, Actual: 3053\n",
            "Epoch: 180, Train Loss: 0.311\n",
            "(0.8824936224489796, 0.8444378346222486, 0.9299050114641336, 0.8851130163678879, 0.8837160969094511)\n",
            "-----------------------------------------------\n",
            "Pred: 3333, Actual: 3053\n",
            "Epoch: 190, Train Loss: 0.311\n",
            "(0.8820153061224489, 0.846984698469847, 0.9246642646577137, 0.8841215158158472, 0.8831149841461914)\n",
            "-----------------------------------------------\n",
            "Pred: 3348, Actual: 3053\n",
            "Epoch: 200, Train Loss: 0.311\n",
            "(0.8821747448979592, 0.8455794504181601, 0.9272846380609236, 0.8845492891735665, 0.883337876657054)\n",
            "-----------------------------------------------\n",
            "Pred: 1317, Actual: 3099\n",
            "Epoch: 010, Train Loss: 1.082\n",
            "(0.29783163265306123, 0.004555808656036446, 0.001936108422071636, 0.002717391304347826, 0.29438122786373044)\n",
            "-----------------------------------------------\n",
            "Pred: 33, Actual: 3099\n",
            "Epoch: 020, Train Loss: 0.741\n",
            "(0.5022321428571429, 0.15151515151515152, 0.0016134236850596966, 0.003192848020434227, 0.4963944836673014)\n",
            "-----------------------------------------------\n",
            "Pred: 3042, Actual: 3099\n",
            "Epoch: 030, Train Loss: 0.540\n",
            "(0.8719706632653061, 0.8773833004602235, 0.8612455630848661, 0.8692395375346035, 0.871845599065282)\n",
            "-----------------------------------------------\n",
            "Pred: 3447, Actual: 3099\n",
            "Epoch: 040, Train Loss: 0.411\n",
            "(0.8887117346938775, 0.8482738613286916, 0.9435301710229106, 0.893369996944699, 0.8893509663812945)\n",
            "-----------------------------------------------\n",
            "Pred: 3420, Actual: 3099\n",
            "Epoch: 050, Train Loss: 0.337\n",
            "(0.8911033163265306, 0.8532163742690059, 0.941594062600839, 0.8952293296517871, 0.8916920833016801)\n",
            "-----------------------------------------------\n",
            "Pred: 3358, Actual: 3099\n",
            "Epoch: 060, Train Loss: 0.320\n",
            "(0.8895089285714286, 0.8582489577129243, 0.9299774120684091, 0.8926746166950597, 0.8899808270553203)\n",
            "-----------------------------------------------\n",
            "Pred: 3342, Actual: 3099\n",
            "Epoch: 070, Train Loss: 0.321\n",
            "(0.8891900510204082, 0.8596648713345302, 0.9270732494353017, 0.8920975003881385, 0.8896318027825737)\n",
            "-----------------------------------------------\n",
            "Pred: 3363, Actual: 3099\n",
            "Epoch: 080, Train Loss: 0.319\n",
            "(0.8919005102040817, 0.8599464763603925, 0.9332042594385286, 0.8950789229340761, 0.8923821486288135)\n",
            "-----------------------------------------------\n",
            "Pred: 3402, Actual: 3099\n",
            "Epoch: 090, Train Loss: 0.319\n",
            "(0.8930165816326531, 0.8568489124044679, 0.9406260083898031, 0.8967851099830795, 0.8935717498614631)\n",
            "-----------------------------------------------\n",
            "Pred: 3397, Actual: 3099\n",
            "Epoch: 100, Train Loss: 0.318\n",
            "(0.892219387755102, 0.8566382101854577, 0.9390125847047435, 0.895935960591133, 0.8927650380189334)\n",
            "-----------------------------------------------\n",
            "Pred: 3428, Actual: 3099\n",
            "Epoch: 110, Train Loss: 0.317\n",
            "(0.8926977040816326, 0.8538506417736289, 0.9444982252339464, 0.8968898421939635, 0.8933017441959206)\n",
            "-----------------------------------------------\n",
            "Pred: 3429, Actual: 3099\n",
            "Epoch: 120, Train Loss: 0.316\n",
            "(0.8931760204081632, 0.8541848935549723, 0.9451435947079703, 0.8973651960784313, 0.8937820085106192)\n",
            "-----------------------------------------------\n",
            "Pred: 3410, Actual: 3099\n",
            "Epoch: 130, Train Loss: 0.319\n",
            "(0.8926977040816326, 0.8557184750733138, 0.941594062600839, 0.8966047011829774, 0.8932678790785473)\n",
            "-----------------------------------------------\n",
            "Pred: 3475, Actual: 3099\n",
            "Epoch: 140, Train Loss: 0.316\n",
            "(0.8950892857142857, 0.8512230215827338, 0.9545014520813165, 0.8999087313659873, 0.8957820843766179)\n",
            "-----------------------------------------------\n",
            "Pred: 3462, Actual: 3099\n",
            "Epoch: 150, Train Loss: 0.315\n",
            "(0.8952487244897959, 0.8526863084922011, 0.952565343659245, 0.8998628257887518, 0.8959170872093892)\n",
            "-----------------------------------------------\n",
            "Pred: 3409, Actual: 3099\n",
            "Epoch: 160, Train Loss: 0.313\n",
            "(0.8938137755102041, 0.856849515987093, 0.9425621168118749, 0.8976644130301168, 0.8943822244948123)\n",
            "-----------------------------------------------\n",
            "Pred: 3421, Actual: 3099\n",
            "Epoch: 170, Train Loss: 0.313\n",
            "(0.8944515306122449, 0.8561824028061971, 0.9451435947079703, 0.8984662576687117, 0.8950426451321131)\n",
            "-----------------------------------------------\n",
            "Pred: 3450, Actual: 3099\n",
            "Epoch: 180, Train Loss: 0.312\n",
            "(0.8949298469387755, 0.8536231884057971, 0.9503065505001613, 0.8993739502214079, 0.8955755885182812)\n",
            "-----------------------------------------------\n",
            "Pred: 3448, Actual: 3099\n",
            "Epoch: 190, Train Loss: 0.312\n",
            "(0.8949298469387755, 0.8538283062645011, 0.9499838657631494, 0.8993432106308232, 0.8955718257274619)\n",
            "-----------------------------------------------\n",
            "Pred: 3453, Actual: 3099\n",
            "Epoch: 200, Train Loss: 0.311\n",
            "(0.8950892857142857, 0.8534607587604981, 0.9509519199741853, 0.8995726495726497, 0.8957406936776063)\n",
            "-----------------------------------------------\n",
            "Pred: 6272, Actual: 3106\n",
            "Epoch: 010, Train Loss: 1.088\n",
            "(0.49521683673469385, 0.49521683673469385, 1.0, 0.6624013648965664, 0.5)\n",
            "-----------------------------------------------\n",
            "Pred: 4468, Actual: 3106\n",
            "Epoch: 020, Train Loss: 0.492\n",
            "(0.7777423469387755, 0.6915846016114593, 0.9948486799742434, 0.8159493002376551, 0.779799576879099)\n",
            "-----------------------------------------------\n",
            "Pred: 3329, Actual: 3106\n",
            "Epoch: 030, Train Loss: 0.443\n",
            "(0.8805803571428571, 0.8540102132772605, 0.9153251770766259, 0.8836052836052836, 0.8809095879066011)\n",
            "-----------------------------------------------\n",
            "Pred: 3155, Actual: 3106\n",
            "Epoch: 040, Train Loss: 0.380\n",
            "(0.8757971938775511, 0.8687797147385103, 0.8824855119124275, 0.8755789809934515, 0.8758605702329036)\n",
            "-----------------------------------------------\n",
            "Pred: 3412, Actual: 3106\n",
            "Epoch: 050, Train Loss: 0.343\n",
            "(0.8852040816326531, 0.8496483001172332, 0.9333547971667739, 0.8895366676894753, 0.8856603423610243)\n",
            "-----------------------------------------------\n",
            "Pred: 3497, Actual: 3106\n",
            "Epoch: 060, Train Loss: 0.332\n",
            "(0.8837691326530612, 0.8398627394909923, 0.9455891822279459, 0.8895956383462063, 0.8843549196041814)\n",
            "-----------------------------------------------\n",
            "Pred: 3485, Actual: 3106\n",
            "Epoch: 070, Train Loss: 0.324\n",
            "(0.884406887755102, 0.8416068866571018, 0.9443013522215068, 0.8900015172204523, 0.8849744284796732)\n",
            "-----------------------------------------------\n",
            "Pred: 3448, Actual: 3106\n",
            "Epoch: 080, Train Loss: 0.319\n",
            "(0.8855229591836735, 0.8462877030162413, 0.9394719896973599, 0.8904485810192249, 0.8860341628840558)\n",
            "-----------------------------------------------\n",
            "Pred: 3428, Actual: 3106\n",
            "Epoch: 090, Train Loss: 0.317\n",
            "(0.8858418367346939, 0.8485997666277713, 0.9365743721828719, 0.8904193449647996, 0.8863225619600398)\n",
            "-----------------------------------------------\n",
            "Pred: 3416, Actual: 3106\n",
            "Epoch: 100, Train Loss: 0.316\n",
            "(0.8855229591836735, 0.8495316159250585, 0.9343206696716033, 0.8899110702238577, 0.8859853506286002)\n",
            "-----------------------------------------------\n",
            "Pred: 3411, Actual: 3106\n",
            "Epoch: 110, Train Loss: 0.315\n",
            "(0.8860012755102041, 0.8504837291116975, 0.9339987121699935, 0.8902869418444069, 0.8864560838171509)\n",
            "-----------------------------------------------\n",
            "Pred: 3410, Actual: 3106\n",
            "Epoch: 120, Train Loss: 0.314\n",
            "(0.8858418367346939, 0.8504398826979472, 0.9336767546683837, 0.8901166359729896, 0.886295105066346)\n",
            "-----------------------------------------------\n",
            "Pred: 3411, Actual: 3106\n",
            "Epoch: 130, Train Loss: 0.313\n",
            "(0.8863201530612245, 0.850776898270302, 0.9343206696716033, 0.8905938315175694, 0.8867749905527947)\n",
            "-----------------------------------------------\n",
            "Pred: 3416, Actual: 3106\n",
            "Epoch: 140, Train Loss: 0.313\n",
            "(0.8861607142857143, 0.8501170960187353, 0.9349645846748229, 0.8905243790248389, 0.8866231640998878)\n",
            "-----------------------------------------------\n",
            "Pred: 3417, Actual: 3106\n",
            "Epoch: 150, Train Loss: 0.313\n",
            "(0.8860012755102041, 0.8498683055311677, 0.9349645846748229, 0.8903878583473862, 0.8864652361150489)\n",
            "-----------------------------------------------\n",
            "Pred: 3418, Actual: 3106\n",
            "Epoch: 160, Train Loss: 0.312\n",
            "(0.8861607142857143, 0.8499122293739029, 0.9352865421764327, 0.8905579399141631, 0.8866262148658537)\n",
            "-----------------------------------------------\n",
            "Pred: 3422, Actual: 3106\n",
            "Epoch: 170, Train Loss: 0.312\n",
            "(0.8861607142857143, 0.8495032144944477, 0.9359304571796523, 0.8906249999999999, 0.8866323163977857)\n",
            "-----------------------------------------------\n",
            "Pred: 3424, Actual: 3106\n",
            "Epoch: 180, Train Loss: 0.312\n",
            "(0.8867984693877551, 0.8498831775700935, 0.9368963296844817, 0.891271056661562, 0.8872731806350393)\n",
            "-----------------------------------------------\n",
            "Pred: 3427, Actual: 3106\n",
            "Epoch: 190, Train Loss: 0.311\n",
            "(0.8866390306122449, 0.8494309892033849, 0.9372182871860915, 0.8911679167304454, 0.8871183034161664)\n",
            "-----------------------------------------------\n",
            "Pred: 3431, Actual: 3106\n",
            "Epoch: 200, Train Loss: 0.311\n",
            "(0.8872767857142857, 0.8496065287088312, 0.9385061171925306, 0.8918464127275509, 0.887762218419386)\n",
            "-----------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Definindo dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def monte_carlo_train(device, data, n_runs=10):\n",
        "    # Extraindo quantidade de características e classes\n",
        "    num_node_features = data.x.size(1)\n",
        "    num_classes =  len(np.unique(data.y))\n",
        "    \n",
        "    for run in range(n_runs):\n",
        "        # Instancia o modelo GCN\n",
        "        gcn = GCN(num_node_features, num_classes).to(device)\n",
        "\n",
        "        # Roda o otimizador Adam\n",
        "        optimizer_gcn = torch.optim.Adam(gcn.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "        # Função custo\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Treina classificador\n",
        "        train_epochs(gcn, data, optimizer_gcn, criterion, run, n_epochs=200, n_runs=10)\n",
        "   \n",
        "\n",
        "monte_carlo_train(device, data)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2N7dQsvSiaGU",
        "t_xBt_dKYlp4",
        "pEa71c636bhX"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.13 64-bit ('covid_es_gnn')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d18b4791e17a610633c3d6efe63d64f7bc6305f70aa7d49f5484cee67bbe0521"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
